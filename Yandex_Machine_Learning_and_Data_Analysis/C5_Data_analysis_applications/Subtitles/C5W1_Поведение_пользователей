[БЕЗ_ЗВУКА] [БЕЗ_ЗВУКА] Привет! Этот урок посвящен анализу поведения пользователей. Прежде всего, анализ поведения пользователей подразумевает работу с пользовательскими данными, поэтому давайте определим, что же именно мы будем понимать под пользовательскими данными. В первую очередь нас будут интересовать данные о том, как пользователь работает с сервисом: как он его изучает, как он решает или не решает с его помощью свои задачи. Здесь речь может идти как об онлайн-сервисах, например, о том, как пользователь взаимодействует с поисковой системой: как он вводит запросы, анализирует выдачу, на какие страницы переходит. В случае интернет-магазина нас будет интересовать то, как пользователь просматривает каталог, в какие разделы он заходит, какие товары изучает, что в результате заказывает. На самом деле такой анализ актуален не только для сервисов в Интернете. Мы также можем применять его и для оффлайн-сервисов. В частности, мы можем анализировать клиентов банка: анализировать, какими операциями они пользуются, какие услуги им нужны, также мы можем анализировать загруженность отделений, или в случае оффлайн-магазина мы можем анализировать чеки и тоже делать довольно интересные выводы. Соответственно, под пользовательскими данными мы понимаем в первую очередь не персональные данные пользователей, то есть не их фамилии и имена, контактные телефоны или адреса, а данные о том, как они взаимодействуют с нашим сервисом или услугой. Теперь давайте обсудим, зачем нам эти данные собирать и анализировать. Прежде всего, анализ пользовательских данных позволяет нам понять, как именно пользователь взаимодействует с сервисом, что ему нравится, что ему не нравится, с какими проблемами он сталкивается и как именно он их решает. Ну, например, с помощью анализа пользовательских данных мы можем понять, как быстро человек может найти ответ на свой запрос с помощью поисковой системы, или сколько времени требуется для того, чтобы заказать такси с помощью соответствующего сервиса. Помимо вот такого понимания, нам интересно оценивать различные ключевые показатели, связанные с аудиторией наших приложений. Например, нам очень интересно уметь оценивать объем аудитории, количество новых пользователей, считать различные конверсии. Об этом мы обязательно поговорим на следующих видео. Ну и помимо того, что нам хочется уметь такие показатели оценивать, нам, конечно же, важно на них влиять. Нам важно увеличивать рост увлеченности пользователей в работе с сервисом, растить аудиторию и многое другое. Теперь давайте сформулируем перечень наиболее крупных прикладных задач, с которыми мы сталкиваемся в процессе работы над приложением. И первая задача, о которой пойдет речь — это описание целевой аудитории. Нам очень важно понимать тот сегмент людей, для которых мы разрабатываем сервис или приложение. После того, как мы описали целевую аудиторию, нам нужно ее привлечь. То есть нам нужно рассказать пользователям о том, что существует наш сервис или наша услуга. После того как мы привлекли пользователей, они пришли и начали пользоваться сервисом, нам нужно вовлекаться в работу с пользователями. Нам нужно оценивать их опыт, нужно растить их увлеченность и влиять на различные показатели, в частности и на финансовые показатели. Также после того как мы начали работать с пользователями, и они уже на нашем сервисе как-то живут, нам нужно понимать, кто из них удовлетворен, кто доволен, кто, скорее всего, в дальнейшем войдет в ядро аудитории, станет нашим постоянным клиентом, а кто склонен отказаться от использования сервиса, отказаться от такой услуги вовсе или, скажем, уйти к конкуренту. Такие задачи решаются в рамках прогнозирования оттока. Ну и если мы научимся отток прогнозировать, конечно же, нам хочется не только знать о том, что какие-то пользователи от нас откажутся, нам хочется на это влиять. В частности, нам важно уметь удерживать пользователей. И первая задача, о которой пойдет речь — это описание целевой аудитории. В рамках этой задачи нам важно очень точно самим для себя ответить на вопрос, кто же наши пользователи. Нам важно понимать, какого они возраста, какие у них интересы, чем они занимаются в свободное время, в какой области они работают, какое у них образование, на каких ресурсах в Интернете они бывают. Конкретный перечень вопросов очень сильно зависит от предметной области, в которой разрабатывается сервис. Также нам важно понимать структуру целевой аудитории, на какие сегменты она делится, выделять размер ядра аудитории. После того как мы определились с целевой аудиторией, важно суметь привлечь пользователей. Для этого нам нужно проанализировать, какие способы привлечения пользователей может предложить наш сервис, какие каналы взаимодействия с пользователем мы можем использовать. Это могут быть e-mail-рассылки, смс-рассылки, телефонные звонки, непосредственное общение с людьми. Нам нужно уметь донести до пользователей информацию о нашем сервисе, и для этого нам нужно рассмотреть то, какие пути решения этого у нас есть — это способы привлечения пользователей и каналы для взаимодействия с пользователями. Также нам важно уметь оценивать их эффективность, это важно для того, чтобы оптимизировать процесс привлечения пользователей. И также после того как мы пользователей привлечем, нам очень важно понять, кого именно мы смогли привлечь с помощью различных активностей по привлечению, различных каналов. Нам интересно проследить дальнейшую судьбу пользователей, привлеченных разными способами. Это важно для того, чтобы весь процесс целиком оптимизировать. Казалось бы, на привлечении пользователей можно остановиться, ведь мы уже их привлекли, и теперь они стали нашими клиентами. На самом деле это не так, на привлечении пользователей работа с ними только начинается. Нам очень важно проанализировать поведение пользователей на сервисе и понять, что же им нравится, а что не нравится, что удобно, а что неудобно, получается ли у них достигать поставленных перед ними целей. В частности, если мы говорим об интернет-магазине, нам интересно, как много пользователей научились выбирать интересные им категории, кто из них умеет просматривать товары и добавлять их в корзину, кто доходит до оплаты. Конечно же, нам интересно мотивировать пользователей и достигать тех целей, которые мы перед ними ставим. И все эти задачи решаются в рамках работы с аудиторией. После того как мы проанализировали основные сценарии поведения пользователей на нашем сервисе, провели сегментацию и рассмотрели различные срезы аудитории, нам важно понять, кто из пользователей удовлетворен работой нашего сервиса, а кому сервис не понравился. Это важно для того, чтобы мы понимали, кто из пользователей становится нашими постоянными клиентами, а кого нам нужно удерживать. Соответственно, для того чтобы понять, кто из пользователей хочет от нас уйти, нам важно уметь строить прогнозные модели. Чтобы строить прогнозные модели, нужно уметь формализовать понятие «отток». Ведь не всегда пользователь в явном виде сообщает нам о том, что он больше не хочет пользоваться нашим сервисом. С другой стороны, помимо того, что прогнозные модели нужно уметь строить, нужно уметь оценивать их адекватность и их качество. Все эти задачи решаются в рамках одной большой задачи — прогнозирования оттока. Когда мы научились строить прогнозные модели и выделять пользователей, склонных к уходу, нам, конечно же, хочется не просто об этом знать, а как-то на это влиять. Вот это влияние решается в рамках задачи по удержанию пользователей. В рамках таких задач разрабатываются методики удержания пользователей, основанные на том, по каким причинам пользователи хотят от нас уйти. Нам важно разрабатывать не только методики удержания пользователей, но и также кампании по удержанию, а также оценивать эффективность этих кампаний. Ведь нам важно предлагать пользователю такие условия, чтобы, с одной стороны, его удержать, а с другой стороны, чтобы предложение этих условий, тем не менее, оставляло пользователей экономически выгодным для нас. Итак, мы поняли, что важно анализировать поведение пользователя, начиная с момента его первого визита и заканчивая моментом, когда он становится нашим постоянным клиентом либо отказывается от использования сервиса. Давайте отдельно опишем те задачи, которых в нашем курсе не будет. Они исключены не из-за того, что они неинтересные или слишком сложные, или простые, а исключительно из-за того, что они, скорее, относятся к тематике рекламы и маркетинга и в меньшей степени относятся непосредственно к анализу данных. Соответственно, мы с вами не будем рассматривать методики привлечения пользователей, не будем рассматривать продвижение, оптимизацию сайтов или SEO-оптимизацию, а также не будем рассматривать вопросы рекламы и маркетинга. Мы же с вами сфокусируемся на непосредственно анализе пользовательских данных и будем работать с описанием и сегментацией аудитории, очень много будем говорить про аудиторные показатели — так называемые аудиторные метрики, и потренируемся решать задачи прогнозирования оттока. Давайте подведем итог. В этом видео мы рассмотрели, зачем нужен анализ поведения пользователей и почему это очень актуальная задача. В следующих видео мы с вами сфокусируемся на применении методов машинного обучения для анализа данных и работы с пользовательскими данными.

В этом видео мы начнем рассматривать аудиторные показатели, и первые метрики, с которыми мы познакомимся — это метрики, связанные с привлечением пользователей. В рамках этой задачи мы рассмотрим следующие группы метрик — это количественные метрики, конверсионные, метрики, связанные со стоимостью привлечения и с общей эффективностью инвестиций, И начинаем мы с количественных метрик. Это наиболее простые метрики, характеризующие успешность нашего сервиса. Первая метрика — это общее количество пользователей, ее совсем просто посчитать. Нам нужно проанализировать все существующие записи за все время существования сервиса, посчитать количество уникальных пользователей, и таким образом мы оценим общее количество пользователей. Эту метрику интересно рассматривать как за все время жизни сервиса в целом, так и в динамике: смотреть, как общее количество пользователей менялось. С другой стороны, помимо общего количества пользователей, нам важно оценить количество новых пользователей, то есть количество пользователей, которые пришли к нам в первый раз. Это можно делать за фиксированную дату: скажем, зафиксировать некоторый день и посчитать, как много пользователей, которых мы ранее не видели, мы в этот день получили. Необязательно это делать за один день, можно рассматривать эту метрику за периоды разной длины, скажем, за неделю или за месяц. Ее также важно оценивать в динамике. Эта метрика позволит понять, как изменения нашего сервиса влияют на количество новых пользователей. Скажем, как влияют изменения в дизайне, как влияет рекламная кампания или даже какие-то внешние события. Теперь давайте поговорим о конверсиях. Нам критически важно понимать, как складывается жизнь пользователей после того, как они начинают пользоваться нашим сервисом. Нам важно понимать, какие этапы они проходят, сколько времени на это требуется. После каких этапов пользователи становятся нашими лояльными клиентами, а после каких — решают, возможно, отказаться от использования сервиса вовсе. Для этого хорошо подходят конверсионные метрики. Мы можем рассматривать конверсию первого дня — это процент или доля новых пользователей, вернувшихся на сервис хотя бы один раз после дня регистрации. Необязательно рассматривать конверсию одного дня, мы можем рассматривать также конверсию первой недели или первого месяца. Они рассчитываются аналогично — это доля пользователей, вернувшихся на сервис хотя бы один раз через 7 или через 28 дней после дня первого захода или после дня регистрации. Вообще говоря, конверсии можно считать между чем угодно, необязательно считать их в привязке к временным периодам. В частности, мы можем считать конверсии между любыми этапами использования нашего сервиса. Например, если речь идет об онлайн-игре, мы можем считать конверсии игроков N-го уровня в игроки (N + 1) или (N + k) уровня, то есть какая доля среди игроков N-го уровня впоследствии дошла до (N + k) уровня. Если мы говорим о интернет-магазине, мы можем считать конверсию зарегистрированных пользователей в покупателей, то есть оценивать долю зарегистрированных пользователей, которые впоследствии совершали покупки. Помимо конверсии, нам важно оценивать стоимость привлечения пользователей. Классическая метрика в этой области — это CPA, или cost per acquisition, стоимость привлечения одного пользователя. Эта метрика позволяет оценить, как много денег мы потратили на привлечение одного пользователя. Причем она применима не только в онлайн-сфере, ее можно также рассчитывать для оффлайн-приложений. Считается она очень просто. Мы всегда понимаем, какой объем средств мы затратили на привлечение пользователей: например, можем рассчитать стоимость рекламной кампании или стоимость любого другого мероприятия по привлечению и далее посчитать, сколько же пользователей мы таким образом привлекли. После этого мы делим стоимость на количество пользователей и таким образом получаем стоимость привлечения. Кстати, в мобильных или десктопных приложениях эту метрику часто заменяют на CPI, cost per install. Эта метрика считается следующим образом. Для приложений мы всегда можем посчитать, сколько установок мы получили. Соответственно, в первой формуле мы можем количество пользователей заменить на количество установок, таким образом от CPA мы перейдем к CPI. При расчете этой метрики есть один важный нюанс, который обязательно нужно учитывать. Нам важно уметь отвечать на вопрос, кого именно мы считаем привлеченным пользователем. Ведь если мы привлекли пользователя, потратили деньги на его привлечение, и он зашел к нам всего лишь один раз, скажем, не разобрался, как использовать сервис, или вообще зашел на него по ошибке и больше не появлялся, то разве нам интересно считать его привлеченным пользователем? Получается, что такой пользователь не оставил о себе практически никаких следов, скажем, не оставил контактов, никак сервисом не воспользовался, и никаких средств нам не принес. Получается, что мы не можем в дальнейшем с ним связаться и не можем никак на него повлиять. Тогда возникает вопрос: как же нам оценивать это по-другому? Тут следует исходить из наших целей и специфики бизнеса. Мы можем задавать здесь практически любые ограничения. Мы можем рассматривать только зарегистрированных пользователей, или, если сервис предполагает некоторые покупки, только пользователей, которые покупку совершили. Соответственно, по аналогии мы можем поступать с любым целевым действием, необязательно это должна быть покупка. Также мы можем рассматривать пользователей, который провели на сервисе больше, чем x времени или просмотрели более, чем n страниц. Соответственно, мы можем задавать любые ограничения, которые согласуются с нашим бизнесом. И последний показатель, который хочется обсудить — это коэффициент ROI, или return on investment. Этот показатель позволяет анализировать эффективность инвестиций и рассчитывать их возвращаемость. Рассчитывается показатель следующим образом. Нам нужно оценить общий доход, далее вычесть из него расходы, поделить на расходы, и, для того чтобы получить значение в процентном соотношении, умножить на 100. С помощью этого показателя мы можем анализировать эффективность инвестиций как в некоторый бизнес в целом, так и в некоторую конкретную задачу. В нашем случае нам чаще всего будет интересно оценить эффективность привлечения. Давайте проанализируем эффективность инвестиций на примере. Предположим, у нас есть два варианта инвестиций: инвестиция A и инвестиция B. Их показатели перед вами. По формуле для расчета коэффициента ROI давайте его рассчитаем. Таким образом, мы получаем, что эффективность инвестиции для инвестиции A составляет 10 %, а для инвестиции B — 25. Получается, что инвестиция B выгоднее, чем инвестиция A, причем результаты сравнения очевидны. 25 лучше, чем 10 в 2,5 раза, поэтому кажется, что инвестиция B точно выгоднее. Вопрос: всегда ли это так? Давайте предположим, что ROI для инвестиции A был рассчитан за 3 месяца, а для инвестиции B — за 2,5 года. Тогда результаты сравнения перестают быть такими очевидными, потому что кажется, что возвращаемость 10 % за 3 месяца — довольно неплохой показатель, а что касается возвращаемости 25 % за 2,5 года, это может быть как очень хорошим, так и очень плохим показателем в зависимости от конкретного бизнес-кейса. Получается, что для того, чтобы корректно сравнивать между собой инвестиции, важно либо убедиться что они были, что коэффициент ROI был рассчитан при одинаковых условиях, например, за одинаковый период времени, либо сделать соответствующие правки. Итак, мы с вами на этом заканчиваем. Мы рассмотрели целый ряд метрик для оценки эффективности привлечения — это метрики, связанные с общим количеством пользователей и количеством новых пользователей, конверсии, стоимость привлечения одного пользователя или стоимость одной установки, а также коэффициент ROI. В следующем видео мы продолжим рассматривать аудиторные показатели и поговорим про активность пользователей.

В этом видео мы поговорим про метрики характеризующие поведение пользователей на сервисе и научимся оценивать, насколько активно пользователи вовлечены в работу с сервисом. Мы рассмотрим три вида: количественные метрики, сессионные метрики и временные. Начнем с количественных. Казалось бы, наиболее естественным выглядят метрики вида daily active users, weekly active users и monthly active users, то есть количество активных пользователей на сервисе, но тут возникает интересный вопрос, как же отделить активных пользователей от не активных? На самом деле, рассчитать эту метрику очень просто, если мы знаем критерии активности. Если мы понимаем, как отделить активных пользователей от н активных, то нам просто достаточно рассмотреть всех пользователей за заданный промежуток времени, день, неделю или месяц, и посчитать их общее количество. Соответственно, самая интересная часть это задать критерии активности. Исходя из чего это можно делать? Все зависит от того, какую задачу приложение решает и какие цели вы себе ставите. Можно задавать критерии активности исходя из того, какие действия пользователь совершил на сайте, то есть достиг ли он определенных целей, которые мы перед ним ставили. Скажем, продолжительность времени проведенного в вашем приложении, либо можно исходить из того, сколько раз пользователь на сайтзашел, какие действия он там сделал. Все зависит от конкретной предметной области. Ну, и, казалось бы, это хорошие метрики, которые позволяют оценить активность наших пользователей, но не все так просто. Данный показатель не позволяет нам отличить ситуацию, когда каждый день к нам приходят новые пользователи, что-то активно делают и больше не возвращаются от ситуации, когда у нас есть стабильное ядро пользователей, которые регулярно приходят и регулярно сервисом пользуются. Возникает вопрос, как же научиться отличать одну ситуацию от другой? Но часто для решения этой задачи используют показатель под названием sticky factor. Он считается как отношение daily active users к monthly active users. Предположим, у нас есть сервис, которым стабильно пользуются 10 тысяч человек и в течение месяца они все приходят. Если каждый из этих 10 тысяч человек приходит каждый день, то sticky factor будет равен единице. Естественно, мы будем видеть, что у нас есть ядро активных пользователей, все они каждый день на сервисе. Другая ситуация, когда у нас есть 10 тысяч активных пользователей, но каждый из них приходит всего лишь несколько раз в месяц. Тогда это отношение будет сильно меньше единицы и мы поймем, что не все пользователи приходят к нам регулярно. Соответственно, это отношение позволяет нам охарактеризовать в некоторой степени стабильность нашей аудитории. Другое решение, позволяющее нам взглянуть на стабильность аудитории это рассматривать только лояльных пользователей. Соответственно, в данном случае нам придется сначала отфильтровать лояльных пользователей, а потом подмножестве пользователей посчитать метрики daily active users, weekly active users или monthly active users аналогичным образом, как мы это делали без такой фильтрации. Соответственно, этот показатель позволит нам более адресно посчитать активных пользователей и, соответственно, мы не будем учитывать тех пользователей, которые, скажем, пришли один раз, что-то активно делали и ушли. Мы будем рассматривать только лояльных к сервису пользователей. Здесь возникает вопрос: каким образом задать критерий лояльности, то есть в данном случае нам уже нужно задать два критерия, критерий лояльности и критерии активности. Точно также нужно делать исходя из вашей предметной области и задач, которые сервис решает. С одной стороны мы можем задавать критерии лояльности аналогичным образом, как мы это делали с критерием активности, например, рассматривать тех пользователей, которые больше месяца, скажем, пользуются нашим сервисом, либо можем придумать что-нибудь более специфичное предметной области, скажем, рассматривать только тех пользователей, которые используют платные услуги. Теперь, давайте, рассмотрим сессионные показатели для того, чтобы понять, что это такое сначала хочется разобраться в том, что же такое сессия. По сессии мы будем понимать последовательность действий, которые пользователь совершает на сервисе в рамках одного визита. Если мы рассмотрим, например, с поисковой системой, то сессия это последовательность действий, которые совершает пользователь в рамках решения своей поисковой задачи, то есть в процессе поиска ответ на свой вопрос. Это те запросы, которые он задает, те страницы, которые он просматривает, куда он переходит, как он переформулирует запрос и так далее. С другой стороны, если мы рассматриваем онлайн-магазин, то сессия пользователя это то, как он рассматривает каталог, на какие страницы товаров он переходит, оформляет ли он заказ, совершает ли он покупку. Соответственно, это последовательность действий пользователя на сервисе в рамках одного визита. Какие же метрики мы здесь будем рассчитывать? Во-первых, это метрика, под названием средняя сессия. Очень логично, которая, с одной стороны, характеризует вовлеченность и длительность использования пользователями нашего сервиса. Расчитать ее достаточно просто, достаточно посчитать суммарную длину всех сессий и разделить их на количество таковых. Возникает вопрос, как этот показатель правильно интерпретировать? Хотим ли мы всегда, чтобы средняя сессия, скажем, была большой или была маленькой? Опять же, это зависит от того, с каким сервисом мы работаем. Если, скажем, это какой-то сервис не предполагающий длительного использования, ну, скажем, заказ чего-нибудь, заказ такси или заказ еды, то кажется, что чем быстрее пользователь справляется со своей задачей, тем больше его удовлетворенность, тем более он доволен. С другой стороны, если мы говорим о каком-то медийном сервисе, допустим, сервис с просмотром видеороликов или сервис для прослушивания музыки, или же онлайн-игры, то здесь кажется, что, наоборот, чем дольше пользователь работает с сервисом, чем больше времени он на нем проводит, тем более он удовлетворен работой данного сервиса, соответственно, интерпретация очень сильно зависит от предметной области. Это нужно учитывать. Еще один важный нюанс, который нужно учитывать, это расчет данной метрики в разрезе сегментов. Мы, конечно, же можем посчитать эту метрику для всех наших пользователей, но тогда мы получим некоторое среднее по больницам, мы будем знать в среднем длину сессии, но нам будет сложно делать из этого знания какие-то полезные выводы. Совершенно другая ситуация, если мы рассмотрим разные сегменты аудитории. Например, что мы можем сделать? Мы можем взять сегмент новых пользователей, которые пришли к нам за какой-то момент в прошлом и посмотреть, как эти пользователи продолжили свое взаимодействие с сервисом. Часть из них, конечно, же довольно быстро уйдет, часть в это время еще попользуется сервисом и также перестанет им пользоваться, а часть пользователей наверняка станет лояльными. Что, если мы поделим пользователей на группы тех, кто ушел сразу и тех, кто остался лояльным и потом вернемся к этому моменту в прошлом и посмотрим на среднюю длину их первой сессии? Тогда, конечно же, мы сможем сделать некоторые полезные выводы. Скажем, мы поймем как средняя длина первой сессии влияет на последующее взаимодействие пользователя сервисом и, таким образом, мы плавно переходим к следующему показателю связанному со времени. Это лайфтайм — показатель количества длины между первым и последним визитом пользователя в наш сервис. Это тоже достаточно простой показатель. По историческим данным его можно легко рассчитать. Мы всегда знаем первый визит пользователя и каким-то образом можем понять, когда же визит был последним и вот этот ключевой момент в расчете данной метрики. Как определить что это последний визит? Нам опять же нужно задать некоторые формальные критерии для того, чтобы понимать, что данный визит мы считаем последним. Но опять же в этом месте нужно исходить из особенностей вашего сервиса. С одной стороны в хорошем случае мы можем получить явный сигнал о том, что данный визит был последним, например, пользователь может удалить свой аккаунт или явно отписаться от использования сервиса, или удалить приложение со своего устройства. В этом случае мы с вами явно поймем, что сейчас пользователь перестает пользоваться сервисом, этот визит последний. Но так бывает далеко не всегда, это достаточно редкий случай. Часто пользователь просто перестает заходить на сервис, причем не обязательно до этого он перестает, начинает пользоваться сервисом реже, в какой-то момент просто он перестает это делать и все, больше мы этого пользователя не видим. Конечно, еще какое-то время мы можем считать его активным пользователем, но и в этом случае мы тоже можем с такими пользователями работать. Например, мы можем создать некоторые пороговые значения, например, считать пользователя отказавшимся от сервиса в случае отсутствия более чем в Х дней, или в случае отсутствия целевых действий, например, отсутствия покупок или отсутствия каких-то платных транзакций. Соответственно, в этом месте нам нужно научиться задавать критерии отказа пользователей от сервиса и после того, как мы формализуем данный критерий, мы сможем рассчитывать эту метрику. Итак, мы рассмотрели целый ряд метрик, характеризующих поведение пользователей на сервисе. Во-первых, это метрики связанные с активностью такие, как daily, monthly and weekly active users, а также усовершенствование этой метрики с учетом лояльных пользователей. Также мы рассмотрели сессионную метрику средняя длина сессий и поняли, что эту метрику стоит рассматривать в разрезе сегментов, а также поговорили про метрики лайфтайм. В следующем видео мы продолжим говорить про аудиторные метрики и рассмотрим метрики связанные с монетизацией.

[БЕЗ_ЗВУКА] В этом видео мы продолжаем анализировать аудиторные метрики и теперь поговорим про метрики для оценки монетизации. Под монетизацией мы понимаем процесс получения прибыли от нашего сервиса или продукта. В рамках оценки монетизации мы поговорим про три большие группы метрик. Это метрики, связанные с долями и конверсиями, метрики, связанные с платежами, и метрики, позволяющие оценить доход. Итак, начнем с долей и конверсий. Прежде всего, нам интересно понять, как много пользователей из тех, кто приходит на наш сервис, используют платные услуги или транзакции. Для того чтобы это оценить, мы будем использовать две метрики: paying share и paying conversion. Метрика paying share считается следующим образом. Мы фиксируем некоторую дату и смотрим, как много уникальных пользователей мы встретили за все время использования сервиса до этой даты. Далее мы смотрим, какая доля из этих пользователей использовала платные услуги или транзакции, и таким образом, считаем метрику paying share. Ее необязательно рассчитывать за все время использования сервиса, можно ее рассчитать в рамках некоторого периода. И вот, если мы хотим анализировать этот показатель в динамике, скажем, рассчитать долю пользователей, использующих платные услуги, за день, за неделю или за месяц, дальше проследить, как она меняется во времени, то чаще всего эту метрику называют paying conversion, то есть считаются они практически одинаково, только paying conversion чаще всего считается за некоторый достаточно узкий фиксированный период и отсматривается в динамике. Эти метрики позволяют нам делать очень много интересных выводов, скажем, понимать, как внешние факторы влияют на долю платных пользователей. Скажем, мы можем оценить, как дни недели влияют на то, какая доля пользователей использует платные услуги, как влияют праздники, как влияют ваши рекламные кампании или какие-то изменения на сервисах конкурентов. Соответственно, первые метрики, которые мы считаем в рамках оценки успешности монетизации нашего сервиса, — это доли и конверсии. Далее, после того как мы оценили, какая доля пользователей использует платные услуги, нам интересно посмотреть непосредственно на платежи. Соответственно, первое, что мы можем посчитать — это общее количество платежей, сколько платежей совершалось на нашем сервисе за некоторый фиксированный период времени. И дальше, когда мы поняли, сколько платежей было, мы с вами можем оценить среднее количество платежей на пользователя. Эти показатели также интересно оценивать в динамике и смотреть, как внешние факторы на них влияют. Итак, мы понимаем, какая доля пользователей использует платные услуги, сколько было платежей. Кажется, можно оценивать доход. Для того чтобы оценить доход, мы можем, с одной стороны, оценивать доход как gross, то есть оценивать общее количество средств, которые мы заработали, и также важно оценивать показатель под названием revenue, или прибыль. Он оценивается, как доход минус затраты. Эти показатели также очевидным образом считаются в динамике и позволяют понять, как наша прибыль зависит, скажем, от сезонности или от других факторов. Теперь, после того как мы научились оценивать доход, давайте считать средний доход. Одна из наиболее популярных метрик, которая используется в различных предметных областях, начиная от телекома, заканчивая интернет-магазинами, — это метрика ARPU, average revenue per user. Она считается следующим образом. Мы всегда можем оценить за фиксированный период любой длины, как много прибыли мы получили, оценить доход и вычесть оттуда затраты. Далее, мы можем оценить, как много пользователей посетили наш сервис за это время, и разделить первую величину на другую. Это и есть average revenue per user, или средний доход от пользователя, средняя прибыль от пользователя. Интересная модификация этой метрики — это average revenue per paying user. В данном случае мы также оцениваем прибыль, однако делим ее не на общее количество пользователей, а только на тех пользователей, которые использовали платные услуги. Интересно оценивать эти два показателя вместе и сравнивать их между собой. На них также часто смотрят в динамике. В случае, если речь идет о некотором продающем сервисе, то есть сервисе, в рамках работы с которым мы предполагаем некоторые покупки со стороны пользователя, к первым двум показателям важно добавить и третий — это средний чек. Этот показатель позволяет нам оценить, сколько в среднем денег пользователь тратит в рамках одной покупки. Итак, мы научились оценивать средний доход от пользователя, теперь давайте поговорим про еще более интересный показатель под названием lifetime value. Этот показатель позволяет нам оценить, сколько в среднем денег принес пользователь за все время своего существования на сервисе. Если следовать определению строго, то этот показатель мы сможем рассчитать только в момент, когда пользователь закончит использовать наш сервис. Тогда мы сможем сложить всю прибыль, которую он приносил в течение использования сервиса, и подсчитать его lifetime value. Однако не всегда нам это выгодно. Конечно, для части пользователей, которые от нас уже ушли, мы можем напрямую посчитать этот показатель, но возникает вопрос, как же быть со всеми остальными, с теми, кто все еще активно или не очень активно, но тем не менее пользуется нашим сервисом. Давайте проанализируем, какие показатели на lifetime value могут влиять. Ну, во-первых, это — time, логично, чем дольше время активной жизни пользователя на сервисе, тем потенциально больше денег он может нам принести, и это — value, то есть среднее количество денег, которые пользователь нам приносит, ну, или average revenue per user, средний доход от пользователя. Получается, что если мы можем оценить средний доход, то есть у нас достаточно статистики, для того чтобы этот показатель оценить, и если мы можем строить прогнозные модели, которые умеют оценивать потенциальное время жизни пользователя, то мы с вами можем построить некоторое ожидание на наш lifetime value. Это важно для того, чтобы ранжировать пользователей по потенциальному финансовому эффекту от них. Если мы хотим проводить различные рекламные кампании, делать бонусы или подарки, то, конечно же, нам хочется в первую очередь обрадовать тех пользователей, от которых мы ожидаем больший эффект. А теперь давайте подведем итог. Мы с вами рассмотрели целый ряд метрик монетизации. Это метрики, связанные с долями и конверсиями, — paying share и paying conversion. Мы рассмотрели метрики, связанные с количеством платежей, — общее количество платежей и среднее количество платежей. Также мы рассмотрели метрики, связанные с доходом, — доход и прибыль от пользователя, и научились считать эти метрики в среднем, в зависимости от количества пользователей. Также мы поговорили про очень интересный показатель lifetime value. И на этом мы заканчиваем рассматривать метрики монетизации. В следующем видео мы поговорим про метрики, связанные с удержанием пользователей.

В этом видео мы заканчиваем анализировать аудиторные показатели, и нам осталось поговорить про метрики, связанные с удержанием и оттоком. Мы будем рассматривать две группы метрик: метрики, основанные на возвращаемости пользователей на сервис, и метрики, непосредственно оценивающие отток. И первая метрика, которую мы рассмотрим, называется return rate — это классический показатель для оценки возвращаемости. Эта метрика рассчитывается за период фиксированной длины — и в классическом варианте это месяц. Однако мы с вами можем гибко специфицировать этот период в зависимости от нашего бизнеса. Это может быть неделя, месяц или несколько месяцев, даже полгода или год. Рассчитывается эта метрика следующим образом. Нам нужно оценить, какая доля ежемесячной аудитории уже пользовалась сервисом раньше и теперь решила вернуться. Если показатель return rate оценивает возвращаемость в целом, то для того, чтобы оценить её более гибко, существует показатель под названием X-day retention. Это может быть 1-day retention, 7-day retention or 28-day retention. Фактически количество дней мы с вами можем задавать так, как нам удобно. Рассчитывается метрика следующим образом. Мы рассматриваем пользователей, которые пришли на сервис в первый раз, и далее оцениваем, какая доля из этих пользователей решила вернуться на сервис на следующий день — это показатель 1-day retention. Далее мы можем рассмотреть следующую метрику: мы фиксируем пользователей, которые пришли на сервис в первый раз, и смотрим, какая доля из этих пользователей вернулась на сервис в течение ближайших семи дней — это 7-day retention. И по аналогии, доля пользователей, которые вернулись на сервис в течение 28 дней после своего первого захода или первого использования — это 28-day retention. Таким образом, количество дней мы можем гибко специфицировать и, сравнивая эти показатели между собой, понимать какая доля пользователей у нас возвращается за окна разной длины. Для того, чтобы ещё более гибко оценить возвращаемость, существует показатель под названием rolling retention. В отличие от классического retention он устроен чуть более гибко и позволяет нам оценить, какая доля пользователей из тех, кто первый раз зашёл на сервис в выбранную дату, до сих пор активна. Этот показатель также можно рассчитывать для окон разной длины. В случае если мы считаем 1-day rolling retention, он полностью совпадает с rolling retention. То есть мы фиксируем пользователей, которые в первый раз зашли на сервис, например, зашли в первый раз на сервис 1 января 2015 года, и смотрим, какая доля из этих пользователей всё ещё активна. Также мы можем рассмотреть показатель rolling retention за периоды времени большей длины и оценить, какая доля пользователей из тех, что первый раз зашли на сервис в день X, вернулись через 7 дней или через 28 дней после первого захода и позже. Теперь перейдём к оценке оттока. Здесь классической метрикой является метрика под названием churn rate. Она позволяет оценить долю пользователей, которые перестали пользоваться нашим сервисом. Эту метрику также можно считать за периоды разной длины — чаще всего это месяц, и эта метрика оценивает, какая доля из нашей ежемесячной аудитории ушла и больше не вернулась. При расчёте этой метрики есть следующий нюанс. Нам нужно чётко сформулировать критерий, по которому мы будем определять ушедших пользователей. Не всегда пользователь даёт нам явно знать о том, что он уходит. Он не присылает нам оповещений, не звонит нам, часто не оставляет никаких сигналов. Он просто пропадает и перестаёт пользоваться сервисом. Соответственно, этот показатель очень сильно зависит от того, каким образом мы формализовали понятие «уход», или «отток», пользователя. Итак, мы с вами на этом заканчиваем. Мы рассмотрели несколько метрик, связанных с оценкой возвращаемости пользователей — это return rate, retention и rolling retention, а также рассмотрели метрику churn rate. На этом мы заканчиваем анализ аудиторных показателей и со следующего видео начнём разбирать прикладные задачи.

[БЕЗ_ЗВУКА] В этом видео мы разбираем одну из наиболее актуальных задач в области анализа поведения пользователей — задачу прогнозирования оттока. Эта задача активно решается в самых разных предметных областях, например, в таких областях, как банкинг или телекоммуникация. Здесь важно успевать отслеживать переходы клиентов банка в другие банки или переходы клиентов одной телекоммуникационной компании в другие и вовремя проводить методики по удержанию таких клиентов. Причем задача является актуальной не только для таких крупных областей, она также очень актуальна для сферы ритейл, для интернет-маганизов, для сферы досуговых сервисов, например, онлайн-кинотеатры или онлайн-игры. Теперь давайте обсудим, почему же эта задача является экономически обоснованной. Вообще говоря, для большинства сервисов справедливо следующее замечание: чем больше клиентов, чем больше пользователей у сервиса есть, тем лучше он монетизируется и тем больше прибыли он приносит. Поэтому с этой точки зрения нам всегда выгодно иметь много пользователей. Возникает вопрос: как же этого добиться? Вообще говоря, добиться этого можно двумя способами: во-первых, больше пользователей может появиться за счет того, что мы очень активно их привлекаем, и у нас есть постоянный приток новых пользователей, а также за счет того, что мы очень активно предотвращаем отток, удерживаем старых пользователей, и у нас сокращается тем самым уменьшение активной пользовательской базы. Соответственно, нам важно хорошо решать обе эти задачи. Часто удержать одного пользователя стоит существенно дешевле, чем привлечь нового пользователя. Более того, когда мы удерживаем пользователя, мы понимаем, какого именно клиента мы удерживаем, и нам очень важно удерживать наших ключевых клиентов, которые приносят сервису много денег. С другой стороны, когда мы привлекаем одного нового пользователя, мы никогда не знаем, как сложится его взаимодействие с сервисом и перейдет ли он, скажем, в группу лояльных пользователей. Соответственно, задача удержания важна еще с этой точки зрения. Возникает вопрос: а как же нам ее решать? Кажется, что нам выгодно удерживать всех пользователей, которые у нас есть. Но с другой стороны, мы понимаем, что процесс удержания — не бесплатный. Для того чтобы пользователя удержать, нам нужно какое-то количество средств в это инвестировать. Соответственно, удерживать абсолютно всех пользователей мы можем далеко не всегда. Это дорого. Для того чтобы эффективно управлять процессом удержания, нам нужно уметь адресно удерживать тех пользователей, которые, с одной стороны, нам важны, а с другой стороны, тех пользователей, которые действительно склонны к оттоку. Плюс нужно учитывать тот факт, что процесс удержания происходит не мгновенно — нам нужно уметь выделять пользователей, склонных к оттоку, до того, как они приняли решение о том, чтобы от нас уйти, и непосредственно это сделали. Теперь давайте формализуем постановку задачи. Прежде всего, нам нужно определиться с тем, как мы формализуем понятие оттока. Далеко не всегда пользователи оставляют нам официальное заявление о том, что они прекращают пользоваться сервисом в течение десяти дней — это, скорее, вымышленная ситуация. Поэтому для того чтобы строить прогнозные модели — модели, которые умеют прогнозировать отток, нам нужно формализовать его определение. Следующий шаг — это определиться с типом модели, которую мы будем строить. Должна ли это быть модель регрессии или классификации? Должна быть классификация бинарной или многоклассовой? Какие классы нас интересуют? Далее мы уже говорили о том, что процесс удержания — не мгновенный, нам нужно какое-то время, для того чтобы связаться с пользователем через выбранный канал, провести процесс удержания, и поэтому нам важно прогнозировать отток заранее. Соответственно, нам важно оценить, сколько времени нам нужно, для того чтобы удерживать пользователей и прогнозировать отток с заданным горизонтом. После того как мы определили горизонт прогнозирования, нам важно зафиксировать методику оценки качества модели. Это важно сделать до того, как мы непосредственно начали строить модель, для того чтобы мы могли сформулировать некоторые гипотезы, построить предположения и оценки того, какое качество модели должно быть, и дальше оптимизировать заданную метрику и проверять, соответствует ли она нашим ожиданиям. Также нам очень важно зафиксировать дизайн эксперимента. Понятно, что большинство моделей строится по историческим данным — мы оцениваем данные, которые нам уже известны о пользователях, которые пользовались сервисом раньше либо пользуются им сейчас. И на основании этих данных строим модель оттока. Однако офлайна и оценки качества моделей часто недостаточно. Нам важно проверить модель в онлайне, важно провести какие-то эксперименты, для того чтобы подтвердить, работает ли наша модель в данном сервисе или не работает. Вот задача того, как мы будем это делать, построение и дизайн такого эксперимента, очень важна. Ее также нужно зафиксировать до того, как мы непосредственно перешли к построению модели оттока. И также нам важно зафиксировать требования к модели. Нам важно понимать, нужна ли нам вероятностная модель, важно ли нам знать, с какой вероятностью каждый пользователь собирается от нас уйти, важно ли нам, чтобы модель была интерпретируемой, хотим ли мы потом пользоваться интерпретацией и понимать причины, почему мы каждого пользователя отнесли к классу «отток» или «неотток». И также нам нужно понимать, есть ли у нас технические ограничения, как часто мы хотим модель применять, как часто мы ее хотим обновлять, переобучать и насколько вычислительно эффективно она должна работать. Давайте рассмотрим пример. Предположим, что мы работаем с некоторым медийным сервисом, который предоставляет своим клиентам доступ к своему контенту по подписке. Это может быть электронная библиотека, онлайн-кинотеатр или какой-то музыкальный сервис. Как в этом случае можно формализовать понятие оттока? Мы можем выбрать следующее определение: пользователь разрывает договор подключения к сервису. Это такой формальный критерий, который мы с вами можем явно померить. Давайте предположим, что мы хотим строить модель бинарной классификации. В этом случае мы хотим относить каждого пользователя к одному из двух классов: либо класс «отток» —пользователь прекращает пользоваться сервисом, либо — «неотток». Предположим, что нас устраивает горизонт прогнозирования в две недели. Это значит, что двух недель нам достаточно, для того чтобы выбрать канал взаимодействия и применить к пользователю методику удержания, скажем, связаться с ним каким-то образом по телефону, отправить SMS либо отправить сообщение на электронную почту и предложить ему некоторые условия, выяснить, доволен он или нет, и как-то с ним провзаимодействовать, попытаться его удержать. Далее давайте выберем методику оценивания модели. Так как мы решаем задачу бинарной классификации, мы можем остановиться на чем-нибудь достаточно простом. Допустим, мы будем использовать метрику AUC для оценки качества модели. И далее — дизайн эксперимента. Давайте будем проводить классический А/Б тестинг: построим модель прогнозирования оттока, далее выберем некоторый сегмент пользователей, скажем, 10 % случайных пользователей, применим к ним нашу модель и попробуем удержать тех пользователей, которые будут относиться к классу «отток», с помощью существующих методик удержания. Далее оставшихся пользователей мы трогать не будем. И будем сравнивать долю оттока и другие метрики на нашем сегменте, на тестовом сегменте, с остальными пользователями. Будем ожидать, что на нашем сегменте, где мы занимаемся удержанием, отток уменьшится. Теперь давайте подумаем, какие определения оттока можно было бы в этой задаче использовать. Первое определение мы с вами уже обсудили — это формальный разрыв договора, когда пользователь явно нам сообщает, что начиная с некоторой даты, он прекращает свою подписку и больше нашим ресурсом пользоваться не планирует — хороший формальный критерий. С другой стороны, мы понимаем, что не всегда пользователи явно хотят сообщать нам о своих намерениях. Поэтому мы можем строить некоторые правила, некоторые эвристические критерии, которые позволят нам с той или иной вероятностью понять, что пользователь больше не с нами. Во-первых, это может быть отсутствие платных транзакций в том случае, если сервис их предполагает. Например, отсутствие платных транзакций в течение десяти дней и более либо отсутствие платных транзакций в течение 90 дней — вот два таких хороших критерия. С другой стороны, мы можем смотреть не обязательно на платные транзакции, мы можем измерять отсутствие пользователя на сервисе, скажем, отсутствие его в течение 14 дней или 28 дней. Возникает вопрос: вот у нас уже сформулированы пять различных критериев, как же нам из них выбрать, какой из них наиболее правильный, какой из них нам больше подходит? Давайте попробуем их каким-то образом провалидировать. И первое, на что предлагается смотреть в рамках такой валидации, это какая доля пользователей попадает под наш критерий, попадает под это определение оттока. Вот предположим, что если мы с вами померим по историческим данным, то есть по тем пользователям, которые уже были у нас на сервисе и в какой-то момент ушли, какая доля из этих пользователей попадает под каждое из определений оттока. Вот начнем с первого: разрыв договора. Предположим, что в нашем сервисе под это определение попадает всего лишь 0,1 % пользователей, то есть всего лишь 0,1 % пользователей явно нам сообщила, что вот с некоторой даты они прекращают пользоваться сервисом. Теперь давайте проанализируем остальные показатели. Предположим, что отсутствие платных транзакций в течение десяти дней — под это определение попадает 22 % пользователей по историческим данным. Отсутствие платных транзакций в течение 90 дней — под это определение попадает 5 % пользователей. Отсутствие на сервисе в течение двух недель — под него попадает 16 % пользователей. И отсутствие на сервисе в течение 28 дней — 9 % пользователей. Мы видим, что процентные соотношения очень сильно отличаются. С одной стороны, мы понимаем, что когда под это определение попадает довольно много пользователей, большая группа — 16, 20 %, кажется, что это довольно много, и интуитивно понятно, что, скорее всего, это слишком «мягкое» правило. Скорее всего, под это правило попадает очень много пользователей, которые, на самом деле, и не собираются от нас уходить. С другой стороны, если мы рассматриваем первый вариант разрыва договора, то мы видим, что под этот критерий попадает очень мало пользователей. То есть, скорее всего, если мы на нем ограничимся, то конечно же, мы найдем тех пользователей, которые явно хотят от нас уйти, но, возможно, мы упустим достаточно большой сегмент тех, кто хочет от нас уйти, но явно нам об этом не сообщает. Соответственно, нам нужны еще какие-то критерии, для того чтобы принять решение о том, какое из этих определений нам больше подходит. Давайте проделаем следующие измерения. Давайте по историческим данным оценим, какая доля пользователей из тех, что подходит под каждое определение оттока, на самом деле возвращается, то есть какая доля пользователей из тех, кого мы с вами отнесли к оттоку, к каждому из определений, на самом деле оттоком не являлась. Вот давайте это оценим. Предположим, что для первого определения мы получили 0 %. Это логично — если пользователь явно разорвал договор, то значит, действительно, он хотел от нас уйти. Теперь давайте проанализируем остальные. Кажется, что если у пользователя отсутствовали платные транзакции в течение небольшого периода времени, скажем, в течение десяти дней, то 80 % из этих пользователей на самом деле не планировало от нас уходить. Возможно, у них были какие-то другие дела, они были в отпуске или еще что-то, то есть это очень слабые критерии, которые совсем недостоверны. Хорошо, давайте рассмотрим следующий — отсутствие платных транзакций более 90 дней. Это уже более хороший критерий, потому что мы видим, что мы ошибаемся всего лишь в 12 % случаях. Большинство пользователей из тех, кто действительно попал под этот критерий, правда, от нас ушли. Аналогичным образом мы можем оценить последние два критерия. Теперь у нас есть много дополнительной информации, для того чтобы принять решение о том, какое определение оттока выбрать. С одной стороны, нам известна доля пользователей, которая попадает под каждое определение оттока, с другой стороны, нам известно, насколько каждое из определений достоверно по историческим данным. Вот исходя из этой информации, вы можете выбрать то определение, которое вам кажется наиболее правильным. В данном случае я предлагаю остановиться на определении «отсутствие платных транзакции более 90 дней». С одной стороны, под него попадает достаточное количество пользователей — это 5 %, а с другой стороны, оно достаточно достоверное — всего лишь 12 % пользователей из тех, кого мы к ним отнесли, после возвращаются на сервис. Теперь давайте подумаем про горизонт прогнозирования. Для того чтобы оценить, какой горизонт прогнозирования нам необходим, нам нужно отталкиваться от нескольких предположений. Во-первых, нужно понимать, как быстро мы можем связаться с пользователем. Это очень сильно зависит от специфики сервиса, который мы анализируем. В частности, скажем, отправить электронное сообщение может быть достаточно быстрым, а для того чтобы связаться с пользователем с помощью оператора из колл-центра и поговорить с ним — вот этот процесс может занять существенно дольше времени. Соответственно, это первый критерий, на который нужно смотреть — как быстро мы можем провзаимодействовать с пользователем и какие каналы нам для этого доступны. Следующий критерий — это то, какие методики удержания мы используем. Нам важно понимать, сколько занимает сам процесс удержания, сколько пользователю требуется времени на то, чтобы принять решение. Важно понимать, что на разных этапах принятия решения об отказе использования сервиса, требуется разное время, для того чтобы удержать пользователя. Скажем, в самом начале пользователь еще не уверен, хочет ли он действительно отказаться от сервиса, и нам проще его удержать. С другой стороны, если мы дотерпели до самого конца, то пользователь, возможно, уже выбрал некоторый аналог, изучил его, и в этом случае нам сложнее его удержать — нам на это требуется гораздо больше ресурсов и больше времени. Еще один важный момент, на который нужно обратить внимание — это качество модели прогнозирования. Понятно, что чем дальше во времени от момента сейчас расположено событие оттока, событие отказа пользователя от использования нашего сервиса, тем сложнее нам его прогнозировать, тем меньше свидетельств, событий или каких-то фактов изменения поведения пользователя мы с вами наблюдаем. Теперь давайте поговорим о данных. Для того чтобы строить хорошую, уверенную модель прогнозирования, нам нужно убедиться в том, что у нас есть достаточное количество данных. Во-первых, нам нужно проанализировать то, какие данные о пользователях нам, в принципе, доступны: доступен ли нам лог поведения пользователя, знаем ли мы все события, все основные события, которые происходят с пользователем на сервисе. Второй важный вопрос — это то, за какой исторический период нам доступны данные, как долго мы их храним, правда ли, что нам доступны данные за долгую историю или мы храним только последние события. Если же мы храним только последние события, достаточно ли их для обучения, или нам нужно позаботиться заранее о том, чтобы начать хранить больше событий, то есть историю за более длительный период. Далее нужно понимать, что данные могут храниться в разных источниках, в разных системах хранения данных, в разных базах данных. Они могут храниться в разных форматах, поэтому нам важно заранее продумать то, каким образом нам следует объединять данные, как мы будем склеивать данные по пользователям, правда, что у нас есть ключи, по которым мы можем объединить, скажем, данные о покупках пользователей на сервисе с данными о его заходах на этот сервис, о просмотрах. То есть нам важно понимать, как мы будем объединять наши данные в один цельный dataset. Далее важно понимать, содержится ли в данных сигнал, то есть есть ли у них та информация, на основе которой у нас получится строить модель. Ведь нам важно не просто иметь какие-то абстрактные данные о пользователе, нам важно иметь те данные, исходя из которых мы сможем делать предположения, делать выводы о том, что поведение пользователей изменилось таким образом, что, скорее всего, он собирается от нас уйти. И нам важно понимать то, каким образом данные следует обрабатывать, как их правильно чистить, какие события следует учитывать, какие события — нет. Теперь, когда мы убедились, что нам доступны данные про пользователей, эти данные доступны за достаточно длительный исторический период, и также в данных предположительно содержится сигнал, на основании которого мы сможем строить модель прогнозирования, нам важно посмотреть на эти данные более пристально, то есть нам нужно выполнить первичный анализ данных. Для этого важно решить задачу визуализации данных. Нам важно понять, какие ключевые характеристики есть у наших пользователей. Для этого часто бывает полезно разбить пользователей на два класса: на целевой класс и нецелевой класс по историческим данным, ведь для исторических данных мы знаем, какие пользователи от нас уже ушли, поэтому мы с вами можем анализировать пользователей в разрезе двух классов. Дальше нам важно посмотреть, по каким ключевым характеристикам эти пользователи отличаются. Важно понять, отличается ли у них, скажем, время использования сервиса, отличается у них средний чек, или ARPU, и другие важные характеристики. Более того, часто бывает очень полезно решить задачу сегментации, особенно на классе оттока, то есть на нашем целевом классе. Нам важно понять, из чего этот класс строится и какие группы пользователей в него входят. Может так оказаться, что в рамках этого класса существует несколько больших групп пользователей, например группа пользователей, которые пришли на сервис недавно, скажем, всего лишь один или два дня назад, посмотрели на сервис, изучили его и просто поняли, что он им не подходит, поэтому и решили уйти. С другой стороны, это могут быть пользователи, которые давно и активно пользовались сервисом и далее по каким-то причинам решили от него отказаться. Понятно, что нам с вами гораздо интереснее и гораздо важнее удержать вторых пользователей — тех, кто сервисом пользовались активно. Более того, про них мы знаем гораздо больше, у нас есть больше информации, и, скорее всего, задачу для них получится решить с более высоким качеством. Соответственно, мы с вами после этапа проведения сегментации сможем ответить на вопрос, из каких сегментов складывается наш отток, можем ли мы одинаково хорошо для каждого из этих сегментов решить эту задачу и хотим ли мы этого, то есть нужно ли нам действительно удерживать пользователей из всех сегментов. Часто в процессе сегментации нам полезно не просто проанализировать получившиеся сегменты, то есть рассчитать на них аудиторные показатели, сравнить и оценить их в целом, но и провести так называемый ручной анализ данных, то есть выбрать по одному или нескольким пользователям из каждого сегмента — особенно нас интересуют те сегменты, которые представляют больший интерес с экономической точки зрения, — и посмотреть глазами на историю их взаимодействия с сервисом. Это бывает невероятно полезно, для того чтобы понять, по каким причинам эти пользователи могли принять то или иное решение, и дальше разработать некоторые методики по их удержанию. А мы с вами на этом заканчиваем. В этом видео мы разобрали постановку задачи прогнозирования оттока пользователей. Хочется обратить ваше внимание на то, что в рамках постановки задачи важно, во-первых, убедиться в том, что задача обоснована с точки зрения бизнеса. Также важно поставить формально постановку задачи, то есть постановку задачи с точки зрения анализа данных, с точки зрения машинного обучения. А также важно провалидировать полученную постановку. На следующем видео мы продолжим разбирать задачу прогнозирования оттока пользователей и обсудим построение и оценку модели.

[БЕЗ СЛОВ] В этом видео мы продолжим разбирать задачи прогнозирования оттока пользователей. В прошлый раз мы остановились на том, что мы сформулировали постановку задачи, теперь давайте перейдем непосредственно к построению модели. И первое, с чего мы начнем, это построение набора данных, или датасета, для обучения и оценки качества модели. Первое, о чем хочется упомянуть, это то, что мы можем работать с данными разного типа. Это могут быть как числовые данные, например, данные, связанные с количеством визитов пользователей на сервис в месяц или в неделю, со средним чеком или другими показателями, которые можно измерить в цифрах. С другой стороны, нам могут быть доступны номинальные данные, например, пол пользователя, тарифный план, который он использует, или пакет услуг. С другой стороны, мы можем работать с порядковыми данными. Это также нечисловые данные, то есть номинальные данные, однако на них мы можем установить некоторое отношение порядка. Например, это могут быть данные про категорию пользователя, скажем, это может быть абонент стандартный или корпоративный или бизнес-абонент. С одной стороны, это номинальные признаки, с другой стороны, мы можем некоторое отношение порядка на них установить. Также мы часто будем сталкиваться с временными рядами, потому что когда мы говорим о поведении пользователей, мы говорим о том, как пользователи взаимодействуют с нашим сервисом в течение некоторого времени. Поэтому временные ряды здесь будут практически всегда: это история использования услуг, история заходов на сервис, история смены тарифных планов, история покупок и различных платежей. С этими данными также важно работать аккуратно, важно понимать, как их обрабатывать, и очень многое об этом вы наверняка узнали из предыдущего урока. Теперь важно понимать следующее: когда мы работаем с данными разного типа, нам нужно убедиться в том, что те инструменты, которые мы используем, мы используем правильно. То есть мы не используем категориальные данные в качестве числовых. Если мы все-таки используем номинальные или порядковые данные, мы их обрабатываем соответствующим образом. Если мы используем временные ряды, то мы понимаем, как мы их обрабатываем: либо мы используем ряд целиком, либо мы рассчитываем характеристики, специфичные для этого ряда, например, такие показатели, как лаг автокорреляции. Это важно. Далее давайте немножечко поговорим про выборку. Часто целевой класс может составлять единицы или даже десятые доли процентов от всей выборки. Такая несбалансированность классов может негативно сказаться на модели классификации. Во-первых, может не хватить данных для обучения, данных для настройки на целевой класс. Это может привести к тому, что объекты не будут классифицироваться к этому классу, потому что, скажем, с точки зрения модели это может быть очень рискованно. Часто подобные проблемы возникают на практике. Нам с вами очень важно заметить это в процессе обучения модели, важно заметить это на метриках, то есть важно выбирать такие метрики, которые к этому чувствительны, и решать эту проблему в процессе построения модели. Давайте обсудим, как ее можно решать. Вообще подходов достаточно много, мы с вами рассмотрим три наиболее часто используемых подхода. И первый подход называется reweighting, или перевзвешивание. Идея этого подхода заключается в следующем: давайте зададим веса объектам целевого класса таким образом, чтобы скомпенсировать их количество. Как это можно делать? Первое предположение следующее: давайте скомпенсируем количество объектов меньшего класса их важностью. Скажем, если мы изначально имеем соотношение 1 к 100, давайте зададим веса таким образом, чтобы это соотношение изменилось, скажем, 1 к 10, 1 к 2 или даже 1 к 1. Под соотношением мы понимаем следующее: мы с вами суммируем количество объектов с весами одного класса, количество объектов с весами другого класса и далее считаем соотношение. То есть если изначально у нас веса всех объектов равняются единичке, то есть мы веса фактически не задаем, то соотношение объектов разных классов — это доля объектов одного класса по отношению к доле объектов другого класса. Вот если теперь целевому классу мы добавим большие веса, больше единицы, мы это соотношение можем склонить в сторону объектов целевого класса, то есть как-то немножечко это скомпенсировать. С другой стороны, мы можем задавать веса объектам, исходя из стоимости ошибок классификации разного рода. Мы понимаем, что в рамках задачи оттока нам важнее найти клиентов, которые собираются от нас уйти, чем найти клиентов, которые от нас уходить не собираются. Поэтому если мы ошибочно отнесем клиента, который уходить не собирается, к оттоку, это не так страшно, как если мы пропустим клиента, который от нас уходить собирается, потому что в этом случае мы, конечно же, не сможем его удержать. Соответственно, исходя из этих соображений, если мы понимаем, скажем, в цифрах, в деньгах, насколько стоимость этой ошибки больше, исходя из этого мы можем задать соответствующие веса объектам. Следующая стратегия, которую мы рассматриваем, называется oversampling. Идея этой стратегии следующая: если у нас ощущается нехватка объектов целевого класса, если представителей класса «отток» слишком мало, давайте сгенерируем больше объектов этого класса. Весь вопрос в том, на основании чего эти объекты генерировать. Ну, самое простое, что мы можем сделать, это задублировать объекты этих классов. На самом деле, этот метод часто сводится к тому, чтобы просто увеличить вес этих объектов. С другой стороны, мы с вами можем сгенерировать новые объекты на основании существующих. Скажем, взять существующие объекты класса «отток» и несколько изменить значения некоторых факторов, то есть с помощью таких небольших случайных изменений породить больше объектов, похожих на настоящие объекты класса «отток». С другой стороны, мы можем генерировать новые объекты на основании нескольких объектов из класса «отток». То есть, скажем, взять группу некоторых объектов и каким-то образом их усреднить, построить объекты, похожие на несколько объектов целевого класса. Другая стратегия — в некотором роде противоположная этой стратегии. Это стратегия undersampling. В рамках этой стратегии мы исходим из предположения, что у нас слишком много объектов из нецелевого класса, и давайте мы от какой-то части этих объектов просто избавимся. Ну, что нам нужно сделать? Нам нужно выбрать какие-то объекты, которые мы из выборки удалим. Мы уже понимаем, что это объекты нецелевого класса, осталось только понять какие. Но самое простое — давайте уберем случайные объекты нецелевого класса. Кажется, их достаточно много, чтобы такая процедура не испортила качество нашей выборки. С другой стороны, мы можем убирать их не совсем случайно. Давайте каким-то образом выберем из них группу схожих объектов, допустим, решим задачу кластеризации, и далее оставим только по нескольку представителей из каждой группы схожих объектов, а всех остальных уберем. Вот это тоже способ сбалансировать нашу выборку. Итак, мы с вами обсудили три подхода для балансировки выборки: перевзвешивание, oversampling и undersampling. Теперь давайте перейдем непосредственно к обучению модели. Мы зафиксировали набор данных, подумали о том, как мы будем решать проблему балансировки классов, поэтому теперь можем смело переходить к обучению. Предположим, что мы уже выбрали модель, выбрали инструмент, с помощью которого мы будем строить модель, поэтому теперь нужно проконтролировать несколько вопросов. Первый вопрос — это обучение на данных, доступных не только за исторический период. Нам важно убедиться, что в процессе обучения модели мы используем тот же самый набор данных, который нам будет доступен при применении модели в prediction. То есть в тот момент, когда мы захотим взять готовую модель и применить ее к пользователям, которые сейчас в режиме real time пользуются нашим сервисом, у нас не возникнет конфликта по данным, то есть у нас не возникнет таких данных, которые доступны в оффлайне, которые доступны о клиентах из прошлого, но недоступны о клиентах из будущего. Допустим, у нас была некоторая услуга, которой клиенты пользовались, мы использовали данные об этой услуге в процессе обучения, но сейчас этой услуги уже нет, поэтому когда мы будем пытаться применить нашу модель, обученную на данных с этой услугой к пользователям, которые пользуются сервисом сейчас, у нас возникнет некоторый конфликт по данным. Вот этого нужно избегать. Следующая проблема — это обучение на данных из будущего. Нам нужно очень внимательно контролировать временные промежутки, на которых мы строим модель. Важно, чтобы в обучающей выборке не было тех событий или тех данных, которые нам на момент обучения не должны быть известны, скажем, тех событий, которые еще не произошли. И последняя классическая проблема построения модели — это контроль переобучения. Нам важно не переобучиться под конкретную группу пользователей, не допустить подбора параметров, которые будут хорошо подходить к маленькой группе, однако будут плохо работать на новых пользователях. Теперь давайте поговорим про кросс-валидацию. Это понятие вам уже знакомо, в частности оно используется для борьбы с переобучением в процессе оптимизации модели. В рамках нашей задачи мы можем рассмотреть два подхода к проведению кросс-валидации. Это кросс-валидация по объектам и кросс-валидация по времени. В рамках кросс-валидации по объектам мы делим объекты на выборки по непересекающимся группам пользователей, то есть те пользователи, которые участвуют в обучении, не участвуют в тестировании модели. Это хороший подход. С другой стороны, мы можем делать кросс-валидацию по времени, то есть мы можем взять пользователей за более ранний период времени, обучить на них модель и применить ее к пользователях за более поздний период времени. При этом мы не запрещаем этим объектам пересекаться по пользователям, то есть мы не запрещаем одному и тому же пользователю быть как в обучении, так и в тесте, однако мы будем рассматривать разные данные касательно этого пользователя. Кстати, эти подходы можно комбинировать, то есть можно строить выборки таким образом, чтобы они не пересекались ни по пользователям, ни по времени. В рамках каждой конкретной задачи вы можете выбирать тот подход, который кажется вам более правильным. Что касается задачи оттока, здесь я советую использовать кросс-валидацию по времени, исходя из того, что данный вид кросс-валидации ближе к тому, как мы будем использовать модель в реальности. То есть когда мы будем обучать модель на всех данных и применять их к пользователям, которые сейчас активно используют наш сервис, эта ситуация ближе к кросс-валидации по времени, то есть на более ранних данных мы модель построили, к более поздним данным мы ее применяем. Соответственно, можно использовать кросс-валидацию по времени либо комбинированный вариант. Теперь давайте поговорим про подбор параметров. Помимо того, что подбор параметров нужно делать на основании кросс-валидации, важно всегда оставлять некоторую Независимую выборку, которая никак не используется в процессе подбора параметров и других измерений в процессе оптимизации модели. Это важно для того, чтобы мы имели такой неприкосновенный инструмент, для того чтобы протестировать финальное решение. В тот момент, когда мы обучили модель практически на всех данных, нам важно понять, не допустили ли мы нигде никаких ошибок. Вот в этом случае всегда можно использовать ту выборку, которая в предыдущем анализе не участвовала никак. Такая выборка называется hold-out dataset. Таких датасетов может быть несколько, они могут быть построены по разным принципам, но единственное, что их всегда объединяет — они абсолютно никак не участвуют в процессе оптимизации настройки параметров модели. Следующая важная вещь — это оценка качества. Во-первых, нам нужно с самого начала определиться с целевой метрикой. Такая метрика должна быть одна, и именно это метрику мы с вами будем оптимизировать. На основании этой метрики мы будем принимать решение о том, что модель достаточно хороша, для того чтобы использовать ее на реальных пользователях, для того чтобы проводить онлайн-эксперимент, например, A/B testing. При этом метрика, которую мы оптимизируем, должна удовлетворять ряду требований. Ну самое большое требование — желательно, чтобы это была та же самая целевая метрика, которую мы будем считать в рамках онлайн-эксперимента, та бизнес-метрика, на которую мы будем смотреть. Но если это невозможно, то мы можем выбрать метрику таким образом, чтобы она с ней коррелировала и соответствовала целевой метрике. Очень важно оптимизировать в офлайне такую метрику, которая будет соответствовать той метрике, которую мы оцениваем онлайн. Также важно оценивать модель «скользящим окном» по времени. Важно понимать, меняется ли качество модели в зависимости от того, в какой день мы ее обучаем, в какой день мы ее применяем, влияют ли на нее недельные тренды, месячные тренды и так далее. Нам нужно понимать, насколько модель устойчива к сезонным изменениям. Теперь давайте поговорим про улучшение модели. Мы всегда сталкиваемся с такой ситуацией, что мы получили некоторую модель, начинаем ее применять, она достаточно хорошо работает, и возникает вопрос, нужно ли нам инвестировать еще время и средства в то, чтобы улучшать качество этой модели, или же нам нужно здесь остановиться и использовать модель в таком виде, в котором она есть. Ну для того чтобы ответить на этот вопрос, для того чтобы оценить перспективность улучшения модели, нужно провести некоторое исследование. Во-первых, важно понять, на каких группах объектов модель ошибается, перспективные ли это группы объектов, важно ли нам на этих группах объектов получать хорошее качество классификации. Также нам важно посмотреть на распределение ошибок, понять, вообще говоря, от чего оно зависит. Важно оценить экономическую перспективность, то есть понять, как много денег мы теряем на ошибках модели, сколько нам стоят эти ошибки, а также являются ли инвестиции в дальнейшее улучшение модели экономически выгодными. То есть если у нас ошибок уже достаточно мало, кажется, что потери небольшие, а инвестиции в улучшение модели планируются существенные, то это может быть просто экономически необоснованно. Важным этапом оценки любой модели, построенной на данных пользователей, является этап интерпретации результатов. Нам часто бывает интересно понять, какие же факторы внесли наибольший вклад в обучение модели, какие факторы оказались наиболее сильными. Также интересно проанализировать, как изменение факторов, скажем, рост или падение конкретного фактора — особенно фактора, который находится в топе, который является сильным фактором, —сказывается на результате классификации. Приводит ли рост фактора к увеличению вероятности того, что пользователь будет классифицирован как отток, или же к уменьшению. Такой анализ позволит нам сформулировать новые гипотезы о том, по каким причинам пользователи уходят, с какими проблемами они сталкиваются и каким образом на это можно повлиять. Также нам важно проанализировать объекты. Нам важно понять, на каких объектах модель работает наиболее уверенно, где у нас получается мало ошибок, где получается много, на каких объектах модель ошибается, как эти объекты группируются и какие сегменты из них можно выделить. Это также позволит нам понять, имеет ли смысл инвестировать в улучшение модели, а может быть, эти классы нужно рассматривать отдельно и строить на них отдельную модель. Теперь давайте поговорим про работу модели в production. После того как мы обучили первую модель и начали ее использовать, нам важно понять, насколько хорошо эта модель работает, насколько сильно меняется ее качество во времени. С одной стороны, это важно для того, чтобы вовремя задетектировать то, что модель начинает «протухать», то, что она уже не актуальна современным данным и успеть ее переобучить, перестроить, начать использовать новую модель. Как это понять? Ну, во-первых, важно в процессе использования модели регулярно измерять метрики качества и следить, смотреть на них в динамике, смотреть, как они изменяются. Также нам важно заранее оценить, насколько быстро модель обучается, сколько времени нам требуется на то, чтобы построить новую модель, оценить и принять решение о том, что можно модели заменять. Соответственно, эти оценки нужны для того, чтобы мы могли заблаговременно задетектировать момент, когда нужно будет переключиться на новую модель, момент того, что старая модель начинает «протухать», и успеть за это время подготовить новую модель и произвести переход, произвести переключение с одной модели на другую. Как же такой мониторинг качества должен быть устроен? Ну в данном случае нам нужно следить за двумя вещами — за изменениями данных и за изменениями модели. С точки зрения изменения данных нам важно понимать, не изменились ли наши данные, не появились ли новые события или новые факторы, которые в модели еще не учтены, но при этом существенно влияют на поведение пользователей. Актуальны ли всё еще те допущения и эвристики, которые мы строили в процессе построения текущей модели, не пора ли нам их заменить и использовать какие-то новые допущения. С другой стороны, нам важно мониторить качество модели и оценивать не только ключевую метрику, которую мы оптимизировали, но также смотреть на модель с разных точек зрения, смотреть на разные метрики. А теперь давайте подведем итог. Мы с вами рассмотрели задачу прогнозирования оттока пользователей. Мы поняли, что это очень сложная задача, состоящая из целого ряда этапов. Очень важно оценивать качество решения задачи на всех этих этапах, начиная от постановки формальной задачи, заканчивая эксплуатацией и доработкой модели. Также важно заранее составить список потенциальных узких мест и продумать способы их детектирования. Мы с вами обсудили возможность несогласованности метрик, несбалансированности выборки, переобучения или обучения на данных из будущего. Все эти проблемы актуальны не только для задачи прогнозирования оттока, но также для других задач из области анализа пользовательского поведения, например, работа с пользователями или привлечение пользователей.
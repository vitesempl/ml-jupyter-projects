[БЕЗ_ЗВУКА] В этом уроке мы поговорим про рекомендательные системы. Что же мы хотим научиться делать, когда строим рекомендательную систему? Прежде всего, мы хотим научиться что-то рекомендовать пользователям. Что нам для этого нужно? Для этого нам нужны сами пользователи, сами объекты, которые мы рекомендуем, и какие-то данные о связи пользователей и объектов, например, какой-то feedback от пользователей насчет того, какие объекты им понравились, а какие — нет. Как может ставиться задача рекомендации фильмов? У нас могут быть оценки, которые пользователи поставили фильмам, которые посмотрели. И мы можем задаться целью спрогнозировать оценки для тех фильмов, которые пользователи еще не видели, и на основе этих оценок рекомендовать пользователям то, что больше всего понравится. В этом случае мы имеем дело с матрицей «Пользователи-фильмы», в ячейках которой у нас будут оценки, которые пользователи ставили. При этом не все ячейки заполнены, некоторые из них пустуют, потому что фильм не был просмотрен. Но те, которые заполнены, могут быть заполнены как высокой оценкой, так и низкой оценкой, что дает нам знание и о том, что человеку нравится, и о том, что человеку не нравится. Наша задача в этом случае — заполнить ячейки, в которых нет никакой оценки, для того чтобы на основе этих спрогнозированных значений можно было рекомендовать что-то пользователям. Совсем другая ситуация с рекомендациями товаров. Здесь мы уже не знаем, какой товар пользователю не понравился, потому что у нас есть данные только о том, что пользователь что-то посмотрел, что-то купил. В этом случае мы должны строить рекомендации, основываясь только на положительном feedback, и этот случай называется случаем implicit feedback, а предыдущий случай, когда у нас были как высокие оценки, так и низкие — случаем explicit feedback, как мы уже обсуждали в предыдущих курсах. При этом мы можем решать задачу построения рекомендаций как для конкретного пользователя на основе каких-то его параметров или на основе его поведения, так и задачу построения рекомендаций для конкретного объекта. Ну, например, показать похожие фильмы или похожие товары, или аксессуары к данному товару. Кстати говоря, задача рекомендаций к товару может решаться с помощью уже известного вам понятия взаимной информации. Можно просто посмотреть, какие товары встречаются в пользовательской сессии вместе, то есть какие товары пользователи смотрят вместе, или какие товары пользователи покупают вместе, но о покупках обычно меньше данных, и на основе этого рекомендовать какие-то сопутствующие товары. Кроме того, нам могут потребоваться рекомендации в каком-то специальном сценарии, например, часто на сайтах магазинов на главной странице показывают самые популярные товары, хиты. При этом, конечно же, понятие популярности в какой-то степени абсолютно, то есть мы можем сформулировать его таким образом, чтобы все товары одинаково для всех пользователей расположить в порядке убывания популярности. Но при этом мы можем добавить какую-то небольшую персонализацию, то есть немножко переставить товары из топа популярных для того, чтобы показать человеку именно то, что ему интересно. А кроме того, мы можем также персонализировать рекомендации товаров из той же категории, можем персонализировать блок с сопутствующими товарами или с товарами, которые просто покупают вместе. Итак, мы поговорили с вами о том, что же делают при построении рекомендательных систем, какие задачи решают; упомянули, что мы можем делать рекомендации как для пользователей, так и для объекта; и обсудили некоторые дополнительные ограничения, которые могут возникать в задаче рекомендации. В следующем видео мы вспомним некоторые методы построения рекомендации, которые мы уже обсуждали ранее.

[БЕЗ_ЗВУКА] В этом видео мы с вами вспомним те методы, с которыми уже знакомились, а именно kNN, применительно к задаче рекомендаций, и матричные разложения. Итак, мы имеем дело с матрицей «Пользователи и объекты». В этой матрице у нас есть какие-то оценки, поставленные объектам, которые пользователи уже видели. И для объектов, которые пользователи еще не видели, эти оценки нужно спрогнозировать, для того чтобы рекомендовать те товары, которые наиболее вероятно понравятся, или те фильмы, которые наиболее вероятно понравятся, или те треки. Мы можем посмотреть на то, какие пользователи похожи на того пользователя, для которого нам нужно сделать рекомендации, и с разными весами, в зависимости от степени похожести, усреднить оценки, которые они уже ставили данному объекту. Такой подход называется user-based kNN, и аналогично ему можно придумать item-based kNN, а именно посмотреть, какие товары похожи на тот товар, для которого нам нужно спрогнозировать оценку, и заполнить эту оценку на основе похожих товаров. Другой подход — это матричные разложения. В этой ситуации мы выдвигаем гипотезу, что оценку, которую пользователь ставит объекту, можно приблизить некоторой простой моделью, а именно мы можем каким-то образом подобрать числа, описывающие каждый объект, и числа, описывающие каждого пользователя, получив таким образом какие-то векторы в пространстве одной и той же размерности. При этом потребовать, чтобы скалярное произведение вектора, описывающего пользователя, и вектора, описывающего объект, хорошо приближало оценку, которую пользователь объекту ставит. Что значит — хорошо приближало? Мы формализуем с помощью некоторой оптимизационной задачи. Например, можно посмотреть на квадраты отклонения, как получается в SVD-разложении, или придумать какую-нибудь другую формализацию, как бывает в NMF-разложениях. Профили товаров и пользователей, то есть векторы, описывающие товары и пользователей, мы подбираем из этой оптимизационной задачи. Таким образом, мы получаем описание объектов и пользователей, с помощью которого можем спрогнозировать и те значения матрицы, которые нам пока неизвестны, потому что пользователь пока не видел объект. Итак, мы с вами вспомнили о том, как можно применить kNN в задаче рекомендации, и вспомнили о матричных разложениях.

[БЕЗ_ЗВУКА] В этом видео мы рассмотрим различные подходы к построению рекомендательных систем. На самом деле, таких подходов довольно много, все они перед вами, и каждый из них мы с вами рассмотрим. Давайте начнем с самого первого. Самый первый подход называется коллаборативная фильтрация. Конечно же, с ней вы уже знакомы, поэтому я всего лишь коротко напомню идею. В рамках этого подхода мы строим рекомендации для каждого пользователя на основании предпочтений похожих пользователей. То есть из множества U мы выбираем тех пользователей, которые похожи на нашего пользователя Ui, далее смотрим, как они оценили объекты, которые наш пользователь еще не видел, и на основе этих оценок строим оценки для тех самых объектов. Далее, рекомендации мы строим на основе полученных оценок. Все очень логично. И следующий подход к построению рекомендаций, который мы с вами рассмотрим, называется content-based. В рамках этого подхода мы опять работаем с множеством пользователей и множеством объектов, однако сам подход к построению рекомендаций очень сильно отличается. В рамках этого подхода нам нужно представить каждый объект из множества I в виде вектора признаков. И сразу же возникает вопрос, откуда, вообще говоря, эти признаки возьмутся? Все очень просто: эти признаки зависят от той предметной области, в которой мы работаем. Скажем, если мы с вами работаем с рекомендательной системой для кино, то нам нужны признаки, которые позволяют описать каждый фильм. Скажем, про каждый фильм мы, скорее всего, знаем жанр, знаем режиссера, знаем год издания, знаем актеров, которые в нем играли. Соответственно, вот именно эти факторы и могут быть признаками. Если же мы говорим о рекомендательной системе, связанной с некоторыми продуктами, например, с одеждой, то здесь ситуация совершенно другая. Мы можем описывать бренд, цвета, размеры, категорию — совсем другие признаки, релевантные нашей предметной области. Предположим, с признаками все понятно, с объектами мы разобрались. Теперь нам нужно научиться описывать пользователя, ведь на самом деле про пользователя мы тоже знаем довольно много информации. Как минимум, мы понимаем, как наши пользователи взаимодействовали с рекомендательной системой. Соответственно, для каждого пользователя мы можем рассчитать признаки, связанные с его поведением, например, любимая категория продуктов, любимые фильмы, любимые жанры, любимые режиссеры. Все эти признаки также помогут нам в построении рекомендательной системы. На самом деле, мы можем поступить еще интереснее и для каждой пары пользователь-объект рассчитать признаки, описывающие их взаимодействие, например, рассмотрим рекомендательную систему продуктов. В этом случае мы можем рассчитать следующие признаки: просматривал ли ранее пользователь этот продукт, как часто пользователь покупал такие продукты, дата последней покупки пользователем этого продукта и частота покупок продуктов из этой же категории, то есть довольно много всего. Соответственно, мы с вами научились считать три группы признаков: признаки, описывающие товар, признаки, описывающие пользователя, и парные признаки. Теперь мы можем собрать обучающую выборку, описывающую каждую пару пользователь-объект. Единственный вопрос, который остался, это что же будет выступать в роли целевой функции. Что мы будем прогнозировать? Здесь все просто: давайте будем прогнозировать те самые оценки, которые пользователи дают объектам. Таким образом, получив обучающую выборку, мы получили возможность построить модель, модель классификации или регрессии, которая будет приближать оценки пользователей. Соответственно, предположение, которое здесь делается по тем признакам, которые мы выделили ранее, по описаниям объектов, по описаниям пользователей и по парным признакам, мы сможем восстановить предпочтения пользователей — довольно разумное предположение. Далее, применяя полученную модель к неизвестным парам пользователь-объект, мы будем приближать те оценки, которые бы пользователь поставил этому объекту. И, соответственно, на основе таких восстановленных оценок мы будем строить рекомендации. Довольно интересный подход. Теперь давайте рассмотрим следующий подход — это рекомендации на основе демографии. Они строятся тоже довольно интересным образом. Первое, что нам нужно сделать, это собрать все данные, которые нам доступны о пользователе. Как минимум, нам доступны данные о том, как пользователь использует нашу рекомендательную систему, но в целом нам могут быть доступны и внешние, дополнительные данные. Например, нам могут быть известны социально-демографические характеристики пользователя: его пол, его возраст, род деятельности, образование. На основе собранных данных нам нужно произвести сегментацию пользователей, то есть поделить пользователей на группы, на группы похожих пользователей, а далее для полученных групп посчитать их предпочтения, то есть посмотреть, какие объекты предпочитают пользователи из одной группы. Как же строить рекомендации? Очень просто! Когда к нам приходит новый пользователь, мы просто смотрим, в какую из этих групп он попадает, на какую группу людей он наиболее похож, и дальше мы имеем возможность строить для него рекомендации, исходя из того, какие предпочтения имеет группа. Ну и аналогичным образом мы можем делать рекомендации для членов группы, исходя из того, что нравится другим членам этой же группы. Все довольно просто. Соответственно, такие рекомендации носят название demographic-based, основанные на демографии либо каких-то других признаках, описывающих пользователей. И следующий подход, который мы рассматриваем, называется utility-based. Он несколько похож на content-based подход с той точки зрения, что нам снова нужно представить каждый объект с помощью вектора признаков, но дальше начинаются расхождения. Для каждого пользователя мы должны разработать его собственную utility function, или функцию полезности, которая будет оценивать полезность данного объекта для данного пользователя. И, естественно, самая большая проблема этого подхода, самый главный вопрос, на который нужно ответить, это как такую user-based utility function построить, то есть как построить вот эту функцию для каждого пользователя. Давайте разбираться на примере. Предположим, что мы разрабатываем рекомендательную систему фильмов. Как в этом случае может выглядеть функция полезности? Мы можем предположить, что каждый пользователь сообщает нам о том, какие интересы у него есть, то есть какие жанры ему нравятся. С одной стороны, он может сделать это явно, выбрав те жанры, которые он предпочитает, с другой стороны, мы можем понять это, оценив те фильмы, которые он просмотрел и которым он поставил высокие оценки. Как в таком случае определить utility function? Про каждый новый объект, про каждый фильм мы знаем, какой у него жанр. Давайте построим функцию, которая на основании жанра фильма будет оценивать его полезность для данного пользователя. Допустим, если фильм имеет жанр science fiction и пользователь любит этот жанр, то полезность этого фильма, значение utility function на нем будет высокое. Если же пользователь предпочитает другие жанры, например, художественные фильмы или историческое кино, то тогда, конечно, полезность этого фильма будет меньше. Соответственно, такую utility function нужно рассчитать для каждого пользователя и далее на ее основе строить рекомендации, выбирать только те объекты, которые получают большое значение по этой функции. И последний подход к построению рекомендаций, который мы с вами рассматриваем, называется knowledge-based, или рекомендации, основанные на базе знаний. В рамках этого подхода мы снова представляем объект в виде векторов признаков, а дальше на основе знания о том, как эти объекты соотносятся с интересами пользователя, мы строим базу знаний, которая с помощью правил эти соотношения описывает. Далее, на основе предпочтений пользователей опять оценивается полезность объектов по этим правилам, и на основании этой полезности строятся рекомендации. Проблема этого подхода опять же состоит в том, что нам нужно эту базу знаний каким-то образом построить, и это часто бывает неочевидно. Итак, мы с вами рассмотрели пять подходов к построению рекомендаций: это рекомендации на основе коллаборативной фильтрации, content-based рекомендации, рекомендации на основе демографии, а также рекомендации на основе функции полезности и на основе базы знаний. На самом деле, выделяют два основных подхода: это коллаборативная фильтрация и content-based рекомендации. Все остальные подходы так или иначе похожи на какой-то из первых двух и часто рассматриваются как их подмножество. Например, рекомендации на основе демографии очень похожи на коллаборативную фильтрацию, там используются схожие идеи, поэтому их не всегда выделяют в отдельный класс, а рекомендации на основе функций полезности и базы знаний часто рассматривают как подмножество content-based рекомендаций. Давайте сосредоточимся на двух этих типах рекомендаций и постараемся их сравнить. Сначала посмотрим на коллаборативную фильтрацию. Такой подход позволяет нам учитывать кросс-жанровые интересы пользователя, то есть строить рекомендации из разных групп, например, рассматривать фильмы разных жанров, продукты разных категорий, ну и вообще рекомендовать ему товары, непохожие друг на друга. С другой стороны, такой тип рекомендаций позволяет нам использовать так называемый неявный feedback, то есть мы можем учитывать неявную информацию, которую пользователь оставляет о продуктах. Это необязательно должна быть явная оценка, мы можем также использовать такие сигналы, как просмотр страниц или время просмотра страницы некоторого объекта. Еще один плюс этих рекомендаций заключается в том, что их качество улучшается со временем. Чем больше статистики про каждого пользователя и про каждый объект мы накопили, тем больше информации мы знаем, и тем более качественные рекомендации мы получаем. Теперь давайте посмотрим, какие же у этого метода есть проблемы. Ну, во-первых, в рамках этого метода очень сильно актуальна проблема холодного старта, причем она актуальна как для пользователей, так и для объектов. Поясню, что это такое. Когда мы видим нового пользователя, он еще не успел сильно повзаимодействовать с нашей системой и не успел оценить много объектов. Соответственно, у нас с вами недостаточно информации для того, чтобы сделать для него хорошие рекомендации, чтобы понять, на кого он похож и какие объекты ему нужно рекомендовать. С другой стороны, когда у нас появился новый объект, не очень много пользователей успели его оценить, и нам снова сложно его кому-то рекомендовать. Также в рамках этого подхода актуальна проблема gray sheep, или серой овцы. Эта проблема заключается в том, что если у нас есть пользователи, которые непохожи на других, например, пользователь, у которого просто нет близких пользователей в нашей базе данных, то мы ничего не сможем ему порекомендовать, потому что он ни на кого не похож, мы не сможем распространить на него поведение других пользователей. Ну и также всегда актуальна проблема популярных объектов. Если у нас есть объект, который все посмотрели, который всем понравился, то, конечно же, мы будем постоянно рекомендовать его для всех. Это довольно очевидная рекомендация, пользы от которой не очень много. Теперь давайте поговорим про content-based рекомендации. В рамках content-based подхода мы имеем почти те же самые преимущества. Мы снова можем использовать неявный feedback пользователя, и качество нашей системы будет только расти со временем. Однако нам уже не так просто строить кросс-жанровые рекомендации. С другой стороны, у нас гораздо меньше проблем. Как минимум, мы избавляемся от проблемы холодного старта для новых объектов, ведь как только объект появляется в нашей системе, мы сразу же понимаем, какие у него есть признаки, а, значит, наравне со всеми остальными объектами можем рекомендовать его пользователям. С другой стороны, проблема «серой овцы» также решается, потому что мы гораздо меньше полагаемся на то, насколько наш пользователь похож на всех остальных, ну и проблема популярных товаров тоже актуальна в сильно меньшей степени. Возникает вопрос: что, если нам хочется, с одной стороны, использовать все преимущества коллаборативного подхода, а, с другой стороны, пользоваться тем, что content-based подход имеет гораздо меньше проблем? Пусть у нас доступно довольно много информации о пользователях, довольно много информации о признаках объекта, но, с другой стороны, у нас очень много оценок. То есть кажется, что нам хочется применять и один подход, и второй, и еще каким-то образом использовать все их преимущества. Давайте так и сделаем. В следующем видео вы узнаете, каким образом можно объединять различные подходы в рамках одной рекомендательной системы.

На предыдущем видео мы рассмотрели различные подходы к построению рекомендательных систем и выяснили, что разные подходы имеют свои преимущества и имеют свои недостатки. Или другими словами, каждый подход имеет свою область применения. Нам с вами захотелось иметь возможность в одной системе использовать преимущества разных подходов и таким образом строить гибридные рекомендательные системы, строить системы, использующие разные подходы к построению рекомендаций. Давайте рассмотрим, какие бывают виды гибридизации систем. На самом деле, их довольно много, мы рассмотрим 6 наиболее популярных. Все они перед вами. И давайте начнем с наиболее простой — это схема Weighted. В рамках этого подхода рекомендательная система работает независимо и независимо генерирует оценки для каждого объекта. Далее, наша финальная оценка строится на основе комбинирования доступных оценок от различных рекомендательных систем с весами. Здесь могут быть очень простые примеры. Если у нас есть две системы, скажем, одна на основе коллаборативной фильтрации, другая — content-based, которые могут оценивать объекты, мы с вами можем построить линейную комбинацию оценок, то есть для каждого объекта сложить оценки от этих двух систем с разными весами. С другой стороны, если наши рекомендательные системы не пытаются спрогнозировать полезность объекта для пользователя, а просто генерируют бинарную оценку — либо объект понравится, либо нет, мы можем использовать схему голосования и, скажем, показывать объект только в том случае, если все системы уверены в том, что объект показывать нужно, что объект пользователям действительно интересен. Это довольно простая схема, поэтому ее часто используют. И следующий подход, который мы рассмотрим, называется Switching. В рамках этого подхода мы снова независимо строим наши рекомендательные системы, и далее, в тот момент, когда нам нужно построить рекомендации для пользователя, мы выбираем, какая рекомендательная система будет это делать. То есть в рамках этого подхода мы уже не смешиваем вместе рекомендации от разных систем, а выбираем, какая система будет строить рекомендации для пользователя. Для того чтобы сделать такой выбор, нам нужно построить некоторые критерии, которые подскажут нам, какую систему следует выбрать. Идея здесь довольно простая. Например, content-based подход позволяет нам решать проблему холодного старта для новых объектов. Поэтому если мы хотим порекомендовать пользователю объект, которого в нашей системе еще не было или он появился недавно, и достаточно много статистики о нем мы еще не накопили, то в этом случае нам логичнее использовать content-based подход. Если же мы пытаемся оценить объект, который уже давно в нашей системе, про него много статистики, то коллаборативная фильтрация, возможно, в этой задаче сработает лучше. Соответственно, мы можем построить некоторые критерии, на основании которых мы будем делать выбор, и использовать правильную рекомендательную систему. Следующий подход, который мы рассматриваем, называется Mixed. В рамках этого подхода мы снова генерируем рекомендации независимо, каждая система строит свой список рекомендаций, однако итоговый список рекомендаций строится на основе смеси рекомендаций от разных систем. Это хорошо работает в тех случаях, когда нам нужно одновременно получить длинный, разнообразный список рекомендаций, например, непрерывный feed новостей или рекомендации медиаконтента. В данном случае часто используют эту схему, потому что мы можем дополнять рекомендации от разных рекомендательных систем друг другом. Следующий, довольно интересный подход называется Feature combination. Этот подход в некоторой степени основан на подходе content-based и является его дополнением. Идея в том, что мы хотим объединить в одной обучающей выборке признаки от разных подходов. Чаще всего это выглядит следующим образом: мы используем информацию о предпочтениях похожих пользователей, полученную в рамках коллаборативного подхода, в качестве признаков для content-based подхода. То есть мы с вами можем рассмотреть рейтинги, которые получил объект с помощью пользователей, похожих на нашего пользователя, и эту информацию использовать как признаки. Таким образом, мы обогащаем признаковые описания объекта, полученного в рамках content-based подхода, и добавляем туда информацию о рейтингах. Это часто довольно неплохо работает. И следующий подход, который мы рассматриваем, называется Cascade. Это очень красивая идея, в рамках которой мы последовательно применяем несколько рекомендательных систем для уточнения рекомендаций. Предположим, что у нас есть рекомендательная система, которая работает вычислительно эффективно и может достаточно грубо и просто поделить объекты на два множества: точно нерелевантные, точно неинтересные пользователю и потенциально релевантные. Тогда давайте применим эту рекомендательную систему, отбросим те объекты, которые нашего пользователя точно не заинтересуют, и дальше будем работать только с той группой объектов, которые потенциально релевантны. Вот к ним давайте применим более сложную рекомендательную систему, которая, может быть, работает дольше, но зато она сможет более точно отранжировать эти объекты для пользователя. Такая схема часто называется Candidate selection, когда с помощью одного алгоритма, зачастую вычислительно более эффективного, мы с вами отбираем множество кандидатов и дальше с помощью другой, более сложной, системы их ранжируем. И последний подход, который мы рассмотрим, называется Feature augmentation. В рамках этого подхода мы тоже используем довольно красивую идею. Мы применяем к нашим объектам и пользователям несколько рекомендательных систем, а дальше их выход используем как входные признаки для системы на следующем уровне. Это довольно интересно. В рамках такой системы мы можем оценить объекты с помощью рекомендательной системы на основе коллаборативной фильтрации, а дальше использовать эти оценки для системы на основе content-based. Часто это бывает полезно, потому что мы сможем учесть внешние данные, не доступные нам для рекомендации. Скажем, мы с вами строим рекомендации товаров, то есть товарные рекомендации одежды, продуктов или чего-то еще, и нам с вами для этого хочется использовать данные из внешней системы, например, данные о том, какие товары пользователь искал, какие запросы он задавал. При этом, конечно же, изнутри нашей системы эти данные нам недоступны, мы ничего про это не знаем. Но с другой стороны, мы можем попросить тех, кому эти данные доступны, построить для нас рекомендации, дать нам их и использовать их для того, чтобы каким-то образом улучшить свои рекомендации, то есть эта система позволяет гибко подключать к рекомендациям внешние данные. Итак, мы с вами рассмотрели целый ряд способов построения гибридных рекомендательных систем. Отдельно хочется отметить, что мы совсем не обязаны использовать только один вид гибридов в нашей рекомендательной системе. Мы можем использовать сразу несколько. Как правило, построение гибридных рекомендательных систем улучшает качество рекомендаций, а также иногда положительно сказывается на их разнообразии. Построение таких систем может помочь решить проблемы, связанные с одним или другим подходом, но, к сожалению, построение гибридов не всегда гарантирует улучшение качества вашей рекомендательной системы.

[БЕЗ_ЗВУКА] В этом видео мы обсудим оценку качества рекомендаций и будем говорить об оффлайн-метриках, то есть метриках, которые можно посчитать на исторических данных. Как мы могли бы измерить качество? Предположим, что мы прогнозируем оценки, которые пользователи ставят каким-то объектам. Тогда может прийти идея: оценивать качество по среднеквадратичной ошибке или по среднему абсолютному отклонению. Но что нам даёт это качество? Можно ли его как-то проинтерпретировать? В случае товаров в качестве оценки у нас будет выступать единичка, если товар был куплен, нолик, если товар не был куплен. Наверное, будет довольно затруднительно понять, что же значит — среднеквадратичное отклонение равно вот столько. С другой стороны, нам даже и не важно, умеем мы хорошо прогнозировать плохие оценки или не умеем. Главное, чтобы умели хорошо хорошие. Отсюда возникает мысль: возможно, такой подход к оценке качества неправильный? Может быть, нужно оценивать качество так, чтобы был важен только топ по оценкам, только то, что мы действительно будем рекомендовать? Один из вариантов это делать даёт нам метрика Precision@k. В данном случае параметр k будет означать, сколько объектов мы рекомендуем. Допустим, мы порекомендовали k товаров, и какие-то товары купили. Давайте посчитаем, сколько товаров, из того что мы прорекомендовали, было куплено, и поделим это количество на k. Мы можем проделать эту операцию для каждой пользовательской сессии. В каждой сессии что-то могло быть куплено. И затем усреднить Precision@k по всем пользовательским сессиям, получив таким образом усреднённый Precision@k. Эту метрику можно использовать для оценки качества рекомендаций по историческим данным. Другая метрика, которую можно использовать для того же, это Recall@k. В данном случае мы снова смотрим на количество купленных товаров из рекомендованных, но теперь делим уже не на количество рекомендаций k, а делим на количество покупок, которые были совершены пользователями. То есть если Precision@k отвечает на вопрос, какая доля того, что мы прорекомендовали, в среднем покупается пользователями, то Recall@k отвечает на вопрос, какая доля от того, что пользователи покупают в среднем, рекомендуется нами и потом оказывается в покупках. Но в то же время эти метрики смотрят на то, какие товары покупаются, но не на то, сколько денег они приносят. Если же нас интересует доход от продажи товаров, может возникнуть следующая простая идея. Давайте просто взвесим наш Recall@k или Precision@k ценами товаров. Давайте вместо купленного из рекомендованных товаров будем рассматривать стоимость купленного из рекомендованных, а вместо количества покупок будем рассматривать стоимость этих покупок или вместо количества рекомендаций — стоимость прорекомендованных товаров. Итак, мы обсудили с вами, почему может быть не очень хорошей идеей измерять среднеквадратичное отклонение или среднее абсолютное отклонение, решая задачу по рекомендации; познакомились с метриками Precision@k и Recall@k; и обсудили возможность модифицировать эти метрики, учитывая цены товаров.

В этом видео мы поговорим об оценке качества в онлайн-эксперименте. Допустим, оффлайновое качество получается хорошим. На исторических данных алгоритм работает крайне неплохо. Значит ли это, что алгоритм будет хорошо себя показывать в бою? Будет ли он действительно давать хороший экономический эффект? Совсем не очевидно. Для этого нам нужно проводить онлайн тестирование. Первая идея, которая приходит в голову — сделать A/B тест: в одной группе использовать алгоритм, в другой группе использовать либо предыдущую версию алгоритма, либо вообще ничего не использовать для рекомендации. Следующая мысль — после A/B теста применять какой-нибудь статистический тест для того, чтобы проанализировать результаты. Итак, как вы уже знаете, в A/B тесте мы случайным образом делим пользователей на равные группы, измеряем какие-то целевые метрики (ну например, количество заказов или доход в каждой группе за период времени теста), получаем какое-то число для каждой группы, и теперь нам нужно сделать какой-то вывод. Ну действительно: пусть в одной группе было заработано 100 млн. рублей, а в другой группе было заработано 105 млн. рублей. Значит ли это, что во второй группе алгоритм отработал лучше? Совсем не очевидно, это может быть просто случайностью. Сейчас вы видите на графике результаты трех групп, равных по размеру, полученных случайным отнесением пользователей к одной из трех групп. Здесь вы видите доход в каждой группе. И, как вы видите, одна из кривых с какого-то момента существенно выше других и, казалось бы, более-менее стабильно выигрывает где-то 10% дохода. Так вот, это разбиение на самом деле случайное, и такое вполне себе бывает, уж особенно с доходом, потому что доход — довольно шумная метрика. Несмотря на то, что такие случайности бывают, с помощью статистических тестов можно как-то побороться с такими проблемами. На практике часто применяется приближение нормальным распределением, ну то есть вы считаете, что покупка совершается с некоторой вероятностью P. Исходя из этого, из центральной предельной теоремы, можете оценить дисперсию для разности количества покупок в двух группах и получить какие-то оценки на каком-то уровне значимости. Также часто используется тест Стьюдента, и часто используется бутстреп, особенно в случае, когда вам нужно получить какой-то статзначимый результат по доходу. При онлайновом тесте смотрят на многие метрики. В первую очередь, конечно, важнее всего доход в группе или прибыль в группе. Но не всегда можно сделать выводы из этой метрики. Так получается, что статзначимость по доходу нужно ждать очень долго, и, может быть, даже нельзя дождаться за какое-то разумное время. Можно смотреть на доход с пользовательской сессии, если разбиение на группы все же не получилось сделать совсем уж равномерным. Можно смотреть на среднюю стоимость купленного товара и на средний чек. В чеке, конечно, может быть несколько товаров. Можно смотреть на конверсию в покупку (то есть какая доля пользователей, которые приходят на сайт, что-то покупают), на клики, на клики конкретно по блокам рекомендаций, и можно смотреть на количество покупок и на доход в разных моделях атрибуции. Ну то есть относить к заслугам рекомендательной системы те покупки, которые были сделаны после просмотра рекомендации или после клика на рекомендацию. При этом бывают разные модели атрибуции. Бывает last click, когда мы считаем результат, то есть покупку, следствием последнего взаимодействия пользователя с товаром. Бывает first click, когда мы считаем, что покупка — это следствие первого взаимодействия с товаром. Бывают другие модели атрибуции. Итак, мы поговорили с вами об онлайн тестировании качества. Вспомнили, что в таких ситуациях нужно проводить A/B тесты, поговорили про статзначимость и обсудили метрики, которые могут быть интересны в онлайн тесте рекомендаций.

[БЕЗ_ЗВУКА] Мы с вами уже немного пообсуждали рекомендательные системы, особенности их построения. Но вот зачем нужны рекомендации, если они не дают хорошего экономического эффекта? Не всегда это понятно. Иногда было бы неплохо простроить связь с экономическим эффектом, с повышением прибыли или хотя бы дохода. В случае рекомендации товаров эта связь достаточно прозрачна. Мы, как и прежде, будем иметь дело с данными о покупках, совершенных пользователями. И теперь мы, с одной стороны, можем действительно связать наши рекомендации с экономическим эффектом, а с другой стороны, в отличие от рекомендации музыки или рекомендации фильмов, здесь у нас не будет негативных примеров, мы знаем только о позитивных примерах, когда пользователь действительно что-то купил, ему действительно что-то понравилось. Что же в этой ситуации можно сделать? Можно попробовать спрогнозировать, какие же товары пользователь купит, и попробовать максимизировать прибыль, используя эти прогнозы. Допустим, на некоторой странице сайта магазина у нас есть блок с рекомендациями, и мы показываем там какие-то четыре товара. Возникает вопрос: какие товары показать, чтобы максимизировать, например, доход магазина за счет показов в этом блоке? Логичная мысль — показывать те товары, которые максимизируют матожидание дохода от их продаж. Итак, пусть мы знаем для этих товаров их вероятности, пусть мы знаем их цены. В таком случае матожидание дохода будет просто суммой произведений цены на вероятность для каждого товара. Значит, этот блок нужно заполнить такими товарами, которые дадут максимальную сумму. Но это просто товары, для которых произведение вероятности на цену самое большое. Допустим, мы идем дальше и хотим научиться максимизировать не просто доход, а прибыль. Тогда нам потребуются данные о маржинальности товаров. И теперь мы будем брать произведение не только вероятности на цену, но еще и на некоторое число, которое отражает маржинальность. При этом нам требуется как-то спрогнозировать вероятность покупки. Для этого нам нужно поставить какую-то задачу классификации. Например, можно рассмотреть следующую задачу. Пусть объектами будут тройки — пользователь, товар и момент времени, а классы — купит или не купит пользователь данный товар в этот момент времени. В качестве признаков мы можем использовать различные параметры пользователя, в том числе полученные из поведения пользователя на сайте, параметры товара, параметры момента времени, например, день недели, и какие-то дополнительные признаки, которые описывают взаимодействие уже перечисленных параметров. Например, как часто пользователь смотрел данный товар, или как часто пользователь смотрел товары из этой категории. Именно такие признаки больше всего сказываются на качестве работы классификатора в этой задаче. Однако мы неизбежно столкнемся с проблемой, что товаров в списке очень много, и для каждого товара применить классификатор, для каждого товара получить набор признаков может быть довольно долгой задачей. В этом случае придется выкручиваться за счет отбора кандидатов, то есть нам потребуется какой-то более простой алгоритм, для того чтобы сгенерировать сколько-то товаров, которые мы будем в дальнейшем пытаться скорить с помощью классификатора, и дальше мы работать будем только с ними. Но как можно отобрать кандидатов? Можно взять просто самые популярные товары или самые продающиеся товары, можно взять товары из тех же категорий, которые смотрел пользователь, можно взять товары, у которых высокий PMI с уже просмотренными или уже понравившимися пользователю товарами. Можно взять товары из заранее подготовленных списков похожих товаров, так тоже можно сделать, а потом уже переранжировать их с помощью машинного обучения. Другая проблема, с которой мы сталкиваемся, — это генерация негативных примеров. Как мы уже с вами говорили, у нас есть только позитивные примеры — случаи покупок. По-хорошему, кажется, что нужно было бы к каждому позитивному примеру, то есть к каждой покупке, добавить все остальные товары, которые не были куплены в этот момент в качестве негативных, но это, конечно, не реально. На такой выборке обучаться не получится. Тогда нужно каким-то образом сэмплировать товары для получения негативных примеров. Например, можно брать случайные товары с равномерным распределением по всем товарам, но в этом случае мы очень часто будем получать в качестве негативных примеров товары, которые не имеют никакого отношения к тому, который был в итоге куплен. И, конечно, классификатор научится отличать такие товары от тех, которые действительно релевантны, но это будет не очень полезное знание. Например, пользователь заходит на сайт для того, чтобы купить холодильник, и мы учимся понимать, что ему не нужны какие-то предметы одежды, которая есть в том же магазине. А нам же нужно уметь отличать товары из похожих категорий или из одной и той же категории. Можно выкрутиться из этой ситуации, генерируя случайные товары с вероятностями, пропорциональными популярности товаров. В этом смысле мы пытаемся смоделировать характерное поведение пользователя за счет использования популярности и научиться отличать какие-то персональные предпочтения от того, что мы видим в среднем по разным пользователям. Другой вариант — это выбирать не случайные товары, а просто самые популярные, но в этом случае в негативных примерах будут постоянно фигурировать одни и те же товары, и, наверное, это будет не очень хорошо для обучения классификатора. И один из самых интересных вариантов — это использовать в качестве негативных примеров те объекты, который рекомендовал бы некоторый алгоритм, то есть мы для построения какого-то алгоритма рекомендаций используем какой-то алгоритм рекомендаций, может быть, просто более простой. Например, можно посмотреть по PMI, какие товары похожи на те, которые пользователь уже смотрел, и взять из них самые популярные. Вот такая простая эвристика, и можно использовать этот алгоритм для генерации негативных примеров. Итак, мы поговорили с вами о том, как рекомендации можно строить с учетом желаемого экономического эффекта, обсудили прогнозирование вероятности покупки товара, поговорили про отбор кандидатов и про генерацию негативных примеров.
Привет! С вами Евгений. В этом уроке мы будем работать с временными рядами и научимся хорошо решать некоторые связанные с ними классические задачи, очень часто возникающие, например, в бизнес-аналитике. Временным рядом называется последовательность y1, ..., yT, ..., ∈ R (потенциально, впрочем, бесконечное) значений признака y, измеряемого через постоянные временные интервалы. Признак y мы будем считать вещественным. Будем работать исключительно с вещественными временными рядами. Важно в этом определении – требование постоянности временного интервала, в которое происходит измерение. Ваш признак вы, может быть, измеряете каждый день, или каждый месяц, или каждый год. Важно, что у вас есть данные именно за последовательные точки с одинаковым временным расстоянием между ними. Временными являются, например, ряды с средними дневными ценами акций какой-нибудь компании, или среднемесячным уровнем безработицы, измеренным за несколько лет, или среднегодовым объемом производства автомобилей за несколько десятилетий. Или вот еще один пример перед вами. Это реальная заработная плата в России в процентах от января 1993 года, измеренная и усредненная за каждый месяц, начиная с этого момента. Как правило, временные ряды интересно прогнозировать, то есть зная значение вашего признака в прошлом, предсказывать, какими они будут в будущем. Формально, это задача ставится, как задача поиска функции fT такой, что значение ряда в момент времени T + d приближается значением этой функции f от известной на момент времени T истории и параметра d. Параметр d определяет, насколько далеко вперед вы хотите предсказывать значение вашего ряда. Как правило, меняется от 1 до некоторой величины D, которая называется горизонтом прогнозирования, d, в свою очередь, отсрочкой прогноза. Практически всегда на протяжении всей нашей специализации до этого, когда мы анализировали данные, мы считали, что имеем дело с простыми выборками. То есть с независимыми одинаково распределенными наблюдениями. Разные наблюдения друг от друга никак не зависели. Задача анализа временных рядов — всё ровно наоборот. Мы надеемся, что данные по прошлому, которые у нас есть, как-то связаны со значениями признаков в будущем. И чем сильнее они связаны, тем больше у нас есть информации о том, как наверное будет себя вести наш признак в будущем, тем лучше мы можем его в будущем предсказывать. Посмотрим еще раз не данные о реальной заработной плате в России. Уже на этом графике, на котором по горизонтальной оси отложено время, а по вертикальной — значение нашего признака, видно, что это ни в коем случае не простая выборка. Измерения здесь не являются независимыми и одинаково распределенными. То, что мы наблюдаем здесь, это разворачивающийся во времени сложно структурированный процесс, и выявив эту структуру, мы сможем учесть её в нашей прогнозирующей модели, и таким образом построить действительно хороший и точный прогноз. Лучше всего мы умеем решать задачу обучения с учителем, поэтому, конечно, хочется сразу задачу прогнозирования временного ряда к ней свести, поскольку этот процесс, разворачивающийся во времени, логично сгенерировать какие-то признаки, связанные со временем, и попробовать сделать какую-то, например, обычную регрессию нашего y на вот такие временные признаки. Ну можно взять, например, линейную функцию во времени, или квадратичную, и каким-то образом подобрать её параметры так, чтобы она лучше всего описывала данные. Это решение слишком простое, чтобы быть хорошим. Действительно, если мы посмотрим на остатки такой регрессии, мы увидим, что эти остатки далеко не похожи на случайный шум. В них остается еще большое количество структуры, которую мы в нашей регрессионной модели не учли. Чем больше особенностей данных, чем больше структуры в нашей модели учитывается, тем лучше предсказания, которые такая модель дает. Поэтому когда мы смотрим на эти остатки, у нас возникает надежда, что мы можем построить какую-то более сложную модель, которая будет лучше описывать имеющиеся у нас данные и заодно давать более точные прогнозы будущего. Вот именно этим мы в течение этого урока и будем заниматься. Давайте для начала введем неформально несколько компонент, которыми очень часто можно описать поведение временных рядов. Первый из них называется трендом. Тренд — это плавное долгосрочное изменение уровня ряда, то есть это какое-то изменение среднего уровня, которое мы можем охарактеризовать, если мы достаточно долго ряд наблюдаем. Еще одна компонента — это сезонность. Сезонностью называется циклические изменения уровня ряда с постоянным фиксированным периодом. Например, в ряде со средней номинальной заработной платой, на которую мы только что смотрели, были очень хорошо выраженные сезонные колебания. Этот признак всегда принимал максимальные значения в декабре каждого года и минимальные в январе следующего года. И в целом, профиль изменений внутри года всегда оставался более-менее постоянным. Еще во временных рядах бывают циклы. Циклом называется изменение уровня ряда с переменным периодом. Очень часто они встречаются в рядах, связанных с какими-нибудь продажами, и объясняются они и циклическими изменениями экономической активности. В экономике выделяют циклы длиной 4—5 лет, 7—11 лет, 45—50 лет и так далее. То есть большое количество таких вот циклов, и они отражаются на разных рядах, связанных с экономической активностью. Еще одним примером такого ряда может служить активность солнечная. Известно, что солнечная активность, которую можно, например, измерить количеством солнечных пятен за день, плавно меняется с периодом, который составляет несколько лет и этот период сам по себе тоже во времени меняется. Значение ряда может определяться как этими тремя компонентами, так и большим количеством других признаков. Некоторые из этих признаков можно явно учесть, другие могут быть слишком слабыми или их может быть совершенно невозможно измерить, и в таком случае, просто удобно считать, что данные содержат какой-то случайный шум. Вот эту последнюю, случайную компоненту ряда, которую спрогнозировать невозможно, мы будем называть ошибкой. Давайте посмотрим на несколько примеров рядов. Перед вами количество контрактов за день в сокровищнице США. В этом ряде достаточно хорошо выраженный понижающийся тренд, который по крайней мере на этом участке, можно описать линейной функцией. Ни циклов, ни сезонности, на этом участке нет, ну по крайней мере, мы не можем утверждать, что они есть, глядя на эти данные. То есть всё, что по крайней мере, не имея никакой дополнительной информации, нельзя описать вот этим трендом, по всей видимости представляет собой ошибку. А здесь перед вами суммарный объем электричества, производимого в Австралии за каждый месяц на протяжении нескольких лет. В этом ряде также очень хорошо выраженный повышающийся в данном случае тренд, но кроме того, в нем есть еще годовая сезонность. Значения признака совершают колебания, минимум которых, всегда приходится на зиму, а максимум — на середину лета. Неудивительно, потому что зимой потребность в электричестве меньше всего — это самый теплый сезон в Австралии. Следующий ряд — это суммарное количество продаж жилой недвижимости в миллионах квадратных метров в США, тоже по месяцам за несколько лет. В этом ряде мы видим сочетание двух основных компонент. Во-первых, это годовая сезонность, минимум всегда приходится на зиму, а максимум на середину лета. Во-вторых, это циклы. Это те самые циклы, связанные с циклическими изменениями среднего уровня экономической активности. В данном случае, период этих циклов составляет примерно 7—9 лет. Вот судя по этим данным. А здесь перед вами ежедневные изменения индекса Доу-Джонса. Глядя на этот ряд, сложно сказать, есть ли в нем вообще какая-то систематическая компонента. В нем явно нет никакого тренда, ни сезонности, ни циклов. По всей видимости, этот ряд представляет собой что-то похожее на случайную ошибку. Но даже такие ряды, оказывается, можно как-то прогнозировать. Итак, в этом видео мы познакомились с временными рядами и узнали, из чего они состоят. А также формально поставили задачу прогнозирования временных рядов, которые мы на протяжении урока будем дальше решать. В следующем видео мы познакомимся с понятием автокорреляции.

[БЕЗ_ЗВУКА] В этом видео мы познакомимся с автокорреляцией — одним из важнейших свойств временных рядов. А разбирать мы его будем вот на таком примере. Перед вами суммарный объем продаж вина в Австралии в количестве бутылок за каждый месяц на протяжении почти 15 лет. Этот временной ряд обладает ярко выраженной годовой сезонностью. Каждый год максимум продаж приходится на декабрь. За этим максимумом приходится довольно существенное падение в январе. В январе объем продаж всегда самый маленький в течение всего года. Давайте посмотрим, насколько сильно связаны друг с другом значения объемов продаж вина в соседние месяцы. Для этого построим вот такой график. По горизонтальной оси здесь отложен y в момент времени t, по вертикальной — y в момент времени t + 1. Таким образом, каждая точка задает продажи в два соседних месяца. Мы видим, что большая часть точек на этом графике группируется достаточно плотно вокруг главной диагонали. Это говорит о том, что значения продаж в соседние месяцы в основном похожи. Еще одно подмножество точек, которое здесь выделяется в правом нижнем углу, как раз связано с теми самыми падениями продаж от декабря к январю, которые мы видели на предыдущем графике. Если мы построим аналогичный график, но по вертикальной оси отложим не y(t + 1), а y(t + 2), мы увидим, что точки вокруг диагонали в основном облаке начинают расплываться. То есть сходство между продажами в месяце через один уменьшается. Если мы возьмем продажи через два месяца, облако станет еще шире, сходства еще меньше. Однако если мы возьмем продажи вина в одни и те же месяцы соседних лет, точки снова стянутся к главной диагонали на нашем графике. То есть значения продаж в одни и те же месяцы соседних лет очень сильно похожи. Квантифицировать степень сходства между значениями ряда в соседних точках можно с помощью величины, которая называется автокорреляция. Определяется она вот так, а по сути представляет собой обычную корреляцию Пирсона между исходным рядом и его версией, сдвинутой на несколько отсчетов. Вот это количество отсчетов, на которые мы сдвигаем ряд, прежде чем посчитать корреляцию, называется лагом автокорреляции. Автокорреляция принимает значения от − 1 до 1 точно так же, как и обычная корреляция Пирсона, а вот так она считается по выборке. По сути, в этом выражении просто все математические ожидания заменены на выборочные средние, все дисперсии — на выборочные дисперсии, после этого сокращены константы. Анализировать значения автокорреляции при разных лагах удобно на графике, который называется коррелограммой. По сути, это график, на котором значения автокорреляции просто отложены в зависимости от τ. Перед вами снова ряд с продажами вина в Австралии и его коррелограмма. Эта коррелограмма имеет типичный вид для ряда, у которого выраженная сезонность. В лагах, кратных сезонному периоду, мы видим большие значения автокорреляции. А вот так выглядит автокорреляция ряда, у которого выраженный тренд. Она тем больше, чем меньше τ, и с ростом τ она начинает постепенно убывать, может быть, колеблясь по синусоиде вокруг горизонтальной оси, соответствующей нулевому значению автокорреляции. Вот автокорреляция ряда с ежемесячным производством электричества в Австралии. В этом ряде есть и тренд, и сезонность. Поэтому здесь есть оба эффекта, о которых мы только что говорили. Тренд здесь настолько сильный, что он вот этот сезонный эффект с пиками в лагах, кратных сезонному периоду, практически сбивает. А вот это типичная коррелограмма ряда, у которого есть сезонность и цикл. Для самого первого лага, кратного сезонному периоду, то есть для года здесь, мы все еще видим пик, но дальше положение этого пика начинает смещаться относительно лагов, кратных сезонному периоду, то есть следующий пик не приходится на два, три, четыре года. И это происходит из-за того, что в ряде есть циклы, длина периода которых плавно меняется. А вот коррелограмма ежедневных изменений индекса Доу-Джонса. Все автокорреляции здесь достаточно маленькие, они близки к нулю, за исключением, естественно, самой первой, которая рисуется при лаге ноль, когда мы считаем корреляцию ряда с самим собой в точности и не делаем никакого сдвига. Естественно, такая автокорреляция всегда равна единице. Возможно, вы заметили на всех этих графиках вот такой загадочный синий коридор вокруг горизонтальной оси. Что этот коридор означает? Стандартные средства работы с временными рядами, как правило, рисуют этот коридор значимости отличий корреляции от нуля, то есть все автокорреляции, которые высовываются из этого коридора, фактически значимо отличаются от нуля. Вот эта значимость считается с помощью уже знакомого нам критерия Стьюдента, точно такого же, как мы использовали для обычной корреляции Пирсона. В данной версии он выглядит следующим образом. Вы берете временной ряд, проверяете нулевую гипотезу о том, что при каком-то фиксированном лаге τ значение автокорреляции равно нулю. Скорее всего, вы это делаете против двусторонней альтернативы, потому что крайне редко при анализе временных рядов у вас есть гипотеза о том, какая именно автокорреляция, положительная или отрицательная. Проверяется эта гипотеза с помощью T-статистики, которая вычисляется с помощью значений автокорреляции, длины ряда и номера лага τ. Если нулевая гипотеза справедлива, эта статистика имеет распределение Стьюдента с числом степеней свободы T − τ − 2. Вернувшись к коррелограмме с ежедневными изменениями индекса Доу-Джонса, мы теперь замечаем, что ни одна автокорреляция здесь не высовывается никогда из коридора незначимости, то есть никакая автокорреляция здесь не является значимо отличающейся от нуля. Итак, в этом видео мы поговорили о том, что такое автокорреляция — мера силы линейной связи между значениями ряда в настоящем и прошлом. Мы узнали, что такое коррелограмма — это график автокорреляционной функции, и как эту коррелограмму правильно читать, как на ней отражается наличие в ряде разных компонент — тренда, сезонности и циклов. Кроме того, мы узнали, как проверяется гипотеза отличия автокорреляции от нуля. В следующих видео мы будем говорить о том, как структуру автокорреляционной функции ряда можно использовать при построении его прогнозирующей модели.

[БЕЗ_ЗВУКА] Перед тем как приступить к первым настоящим прогнозирующим моделям, нам нужно познакомиться еще с одним важным свойством временных рядов. Это свойство стационарности. О нем это видео. Ряд называется стационарным, если для любой ширины окна S распределение ряда в этом окне не зависит от того, в какое место ряда мы окно поставим, то есть свойства распределения совокупности отчетов ряда не зависят от времени. Например, это значит, что автоматически не являются стационарными ряды, в которых есть тренд, потому что в зависимости от того, где мы поставим наше окно, у нас будут разные средние уровни ряда, то есть средние значения вот этого распределения в окне меняются. Кроме того, нестационарны ряды с сезонностью, потому что, если мы возьмем окно ширины меньше сезонного периода, то в зависимости от того, в какой части сезонного периода мы это окно поставим, мы будем получать разные распределения. Интересно, что при этом ряды, в которых есть непериодические циклы, все равно являются стационарными, поскольку мы не можем заранее предсказать, где именно будут находиться максимумы и минимумы нашего ряда. Перед вами девять временных рядов. Давайте подумаем, какие из них можно считать стационарными. Вот эти пять рядов явно не стационарны, поскольку в них есть достаточно сильно выраженный тренд. В этих трех рядах сильно выражена сезонность, поэтому они стационарными тоже не являются. Помимо всего прочего, в этом ряду со временем меняется дисперсия, поскольку размах колебаний в самом начале ряда намного меньше, чем ближе к концу ряда, то есть еще одно свойство распределения — дисперсия — не является постоянным во времени. Таким образом, это оставляет нам вот эти два ряда, один из которых это ежедневное изменение индекса Доу — Джонса, которое мы уже видели, а второй — это размер поголовья рыси. Это ряд, в котором колебания, которые вы здесь видите, имеют нефиксированный период, то есть это ряд с циклами. Поэтому он может считаться стационарным. Формально гипотезу стационарности можно проверить с помощью критерия Дики — Фуллера. Он принимает на вход временной ряд и проверяет гипотезу о том, что он не стационарен, против альтернативы стационарности. Это делается с помощью статистики, которая выглядит достаточно сложно, и мы пока не будем ее рассматривать. И распределение эта статистика имеет тоже специальное, табличное. Мы не будем подробно останавливаться на том, как работает именно этот критерий, потому что он достаточно сложный. А, вообще говоря, существует большое количество критериев для проверки гипотезы стационарности — вы можете использовать любые другие. Мы будем ориентироваться на критерий Дики — Фуллера, потому что для него есть стандартная реализация в Python. Если вы имеете дело с нестационарным рядом, существует несколько стандартных трюков, которые можно использовать, чтобы сделать его стационарным. Например, если в вашем ряде во времени монотонно изменяется дисперсия, можно использовать специальное преобразование, стабилизирующее дисперсию. Очень часто используется обычное логарифмирование. Например, на ряде с продажами электричества в Австралии обычное логарифмирование делает размах колебаний в начале и в конце ряда намного более похожими друг на друга, то есть дисперсия примерно стабилизируется. Логарифмирование — частный случай семейства преобразований, которое называется семейством Бокса — Кокса. Это параметрическое семейство функций с параметром λ, в котором λ определяет, как именно мы преобразовываем ряд по сути. λ = 0 соответствует логарифмированию, λ = 1 — это тождественное преобразование ряда, то есть ряд фактически остается таким, как он был, а при других значениях λ — это преобразование степенно́е. λ можно подбирать некоторым образом так, чтобы дисперсия была как можно более стабильной во времени. Например, для ряда с продажами электричества оптимальным является значение λ = 0,27. При этом λ дисперсии немного более стабильна, чем при использовании обычного логарифма. Еще один важный трюк, который позволяет сделать ваш ряд стационарным, — это дифференцирование. Если вы имеете дело с нестационарным рядом, часто оказывается, что стационарным является ряд его попарных разностей, то есть вы от Y переходите к ряду разностей Yt − Y(t − 1). Такая операция позволяет стабилизировать среднее значение ряда и избавиться от тренда, иногда даже от сезонности. Кроме того, это дифференцирование может применяться неоднократно, то есть вы можете от ряда первых разностей, продифференцировав его еще раз, перейти к ряду вторых разностей и так далее. Длина ряда будет каждый раз немного сокращаться, но зато он будет получаться стационарным. Еще может использоваться сезонное дифференцирование — это когда вы переходите от исходного ряда к ряду попарных разностей его значений в соседних сезонах. Если у вас сезонный период длины S, ваш новый ряд — это ряд из Yt − Y(t − s). Сезонное и обычное дифференцирование могут применяться к ряду в любом порядке, однако рекомендуется начинать именно с сезонного, если у вашего ряда выраженный сезонный профиль. Уже после такого преобразования может оказаться, что ряд стационарен. Пример: на верхних графиках здесь индекс Доу — Джонса и его автокорреляционная функция. Мы видим, что этот ряд достаточно сильно нестационарен, то есть он явно имеет выраженный тренд, от которого удается полностью избавиться, просто продифференцировав. В нижнем ряду график ежедневных изменений индекса Доу — Джонса, тот самый, на который мы уже столько раз смотрели, и его автокорреляционная функция. Критерий Дики — Фуллера подтверждает, что этот новый продифференцированный ряд является стационарным, гипотеза нестационарности отвергается, в то время как для исходного ряда гипотезу нестационарности отвергнуть нельзя. Итак, в этом видео мы ввели понятие стационарности, и мы узнали, как обычный нестационарный ряд можно превратить в стационарный с использованием двух специальных трюков — стабилизации дисперсии с помощью, например, семейства преобразований Бокса — Кокса, и дифференцирования. Кроме того, мы узнали, как именно проверять гипотезу о том, что ряд является нестационарным. В следующем видео мы разберемся с тем, зачем все это было нужно, и начнем рассматривать наконец первые прогнозирующие модели временных рядов.

[БЕЗ_ЗВУКА] В этом видео мы начнем разбираться с первым классом прогнозирующих моделей — это будут модели ARMA. Если помните, мы уже пытались свести задачу прогнозирования временного ряда к задаче обучения с учителем, которую мы очень хорошо умеем решать, и делать регрессию значений ряда на какие-то признаки, зависящие от времени, например, линейные и квадратичные тренды. Получалось очень плохо, этих признаков недостаточно, нужны какие-то еще. Откуда их можно взять? Идея: давайте будем делать регрессию ряда не на какие-то внешние признаки, зависящие от времени, а непосредственно на его собственные значения в прошлом. Составим регрессионное уравнение, в котором в качестве отклика будет стоять yt, в качестве признаков — y в моменты времени (t − 1), (t − 2), ..., (t −p). Параметрами этой модели, которые мы будем оценивать, будут α и φ1, ..., φp — это, собственно, константы, которые нам нужны для того, чтобы модель задать. И кроме того, добавим в модель шумовую компоненту εt, которая будет описывать отклонения значений ряда от всего того, что в этом уравнении записано. Такая модель называется моделью авторегрессии порядка p. В этой модели yt представляет собой линейную комбинацию p предыдущих значений ряда и шумовой компоненты εt. Запомним этот класс моделей. Давайте рассмотрим еще один. Это модели типа скользящего среднего. Для того чтобы лучше понимать, как они устроены, давайте для начала возьмем независимый одинаково распределенный во времени шум εt, вот он перед вами на графике. Давайте теперь для каждого t посчитаем среднее арифметическое между εt и ε(t − 1). То, что получается при этом, перед вами на графике. Если теперь мы будем усреднять не две, а три соседние компоненты ε, то мы получим вот такую кривую. Если мы возьмем среднее по четырем соседним точкам, кривая будет вот такая. То, что получается в результате такого усреднения — это уже ни в коем случае не простая выборка с независимыми одинаково распределенными элементами. Соседние значения на этой красной линии очень похожи друг на друга, потому что в формулах для них участвуют одни и те же шумовые компоненты. Давайте попробуем эту идею обобщить и запишем вот такую модель ряда. Значение ряда в момент времени t, yt, мы будем представлять в виде линейной комбинации значений шума в q предыдущие моменты времени, а также нового значения шума в момент времени t, εt. Параметры, которые в этой модели нужно оценить — это α и все θ: θ1, ..., θq, коэффициенты перед предыдущими значениями шума. Такая модель называется моделью скользящего среднего порядка q. Она утверждает, что значение нашего ряда представляет собой линейную комбинацию q последних значений шумовой компоненты. Эта модель выглядит достаточно странно. Шумовая компонента — это что-то, что мы не можем наблюдать. Как же мы такую модель будем обучать и зачем она нам вообще нужна? Сначала ответим на второй вопрос, а потом постепенно разберемся с первым. Давайте проделаем вот такой трюк. Возьмем авторегрессионную модель порядка p и модель скользящего среднего порядка q и просто сложим то, что стоит в их правых частях. Полученная модель записана перед вами. Она называется моделью ARMA порядка (p, q) и состоит ровно из авторегрессионной компоненты порядка p и компоненты скользящего среднего порядка q. А теперь главное. Теорема Вольда утверждает, что любой стационарный временной ряд может быть описан моделью ARMA(p, q) с правильным подбором значений параметров p и q. Это прекрасный результат. Он говорит нам о том, что семейство моделей ARMA(p, q) достаточно богато для того, чтобы в нем можно было найти более или менее хорошую модель, описывающую любой стационарный ряд. Давайте, например, посмотрим на вот этот ряд с поголовьем рыси. Мы этот пример уже видели и уже знаем, что этот ряд действительно стационарен, а значит, можно надеяться, что в классе ARMA(p, q) для него можно найти какое-то достаточно хорошее описание. Действительно, если мы посмотрим на модель, например, ARMA (2, 2), мы увидим, что то, что получается, уже достаточно сильно похоже на наш ряд. Эта модель не во всех точках близка к истинному значению ряда, но, по крайней мере, это уж точно намного лучше, чем если бы мы сделали линейную регрессию на линейный или квадратичный временной тренд. Настроив эту модель ARMA(2, 2), ее можно использовать и для построения прогноза, то есть для решения той задачи, ради которой мы здесь, собственно, и собрались. Итак, в этом видео мы рассмотрели класс моделей ARMA(p, q). Этот класс, благодаря утверждению теоремы Вольда, мы знаем, что достаточно широк для того, чтобы более или менее точно описывать все стационарные временные ряды. В следующем видео мы поговорим о том, что делать с временными рядами нестационарными.

[БЕЗ_ЗВУКА] В этом видео мы поговорим про модели типа ARIMA — обобщение модели класса ARMA. На данный момент нам известно два важных факта: во-первых, что моделями типа ARMA любой стационарный ряд может быть описан с любой наперед заданной точностью. Во-вторых, что если мы имеем дело с нестационарным рядом, стационарным может оказаться ряд его первых сезонных, или обычных разностей, или не первых, а каких-то следующих, то есть мы знаем, как делать нестационарные ряды стационарными — мы просто их дифференцируем. Эти две идеи и лежат в основе класса модели ARIMA. Моделью ARIMA порядка (p, d, q) называется модель ARMA порядка (p, q) для ряда, который d раз продифференцировали. Перед вами 300 значений индекса Доу-Джонса. Мы уже знаем, что этот ряд нестационарен — да это и видно невооруженным глазом, — но зато стационарен ряд его первых разностей. А это значит, что для ряда разностей, скорее всего, можно подобрать достаточно хорошую модель в классе ARMA. Сделаем это, а затем проведем операцию, обратную дифференцированию. Таким образом мы получим модель ARIMA для исходного ряда. Вот она перед вами. Это модель ARIMA порядка (0, 1, 0), то есть в ней есть одно дифференцирование и ни одной компоненты авторегрессии и скользящего среднего. Это немного странно, то есть модель первых разностей мы моделируем константой. Но когда мы проводим операцию, обратную дифференцированию, то, что получается, в итоге константой уже не является. В этой модели есть свои странности, но в любом случае она намного лучше того, что можно было бы получить, делая просто регрессию этого ряда на какие временные признаки. Давайте теперь разберемся с сезонностью. Пусть наш ряд имеет сезонный период длины S. Возьмем для начала модель ARMA (p, q) и добавим в нее, во-первых, P авторегрессионных компонент, но не предыдущих, а взятых с шагом, равным периоду сезонности, то есть регрессию будет делать на yt − S, yt − 2S, ..., y t − PS. Точно так же добавим Q компонент скользящего среднего, то регрессию на шумовые компоненты в моменты времени t − S, ..., t − QS. Такая модель, в которой сложены вот эти все три части, называется моделью SARMA порядка (p, q) x (P, Q) — вот так это записывается. Наконец, последнее обобщение: моделью SARIMA порядка (p, d, q) x (P, D, Q) называется модель SARMA порядка (p, q) x (P, Q) для ряда, к которому d раз было применено обычное дифференцирование и D раз сезонное. Вот эта модель с шестью параметрами часто называется просто ARIMA, то есть первая буква в названии этой модели часто не пишется, но подразумевается, что сезонная компонента тоже может быть. Вернемся к ряду с реальной заработной платой в России. Критерий Дики-Фуллера не отвергает гипотезу о том, что этот ряд нестационарен. Это нас не удивляет — мы видим, что во времени здесь довольно много всего меняется. Для начала у него меняется дисперсия, то есть разброс скачков ряда в начале совсем не такой, как ближе к концу. Давайте проведем преобразование Бокса-Кокса: выберем оптимальное значение параметра λ, преобразованный ряд перед вами на графике. Критерий Дики-Фуллера все еще не отвергает для этого ряда гипотезу нестационарности. Ну, он сезонный, и тренд тоже здесь довольно выражен, поэтому давайте его еще продифференцируем. Сделаем сезонные дифференцирования — полученный ряд перед вами. Критерий Дики-Фуллера на сей раз гипотезу нестационарности отвергает. То есть для этого ряда мы уже можем утверждать, что он является стационарным, а значит, для него можно попытаться подобрать модель в классе ARMA. Или, на самом деле, можно даже попробовать сразу сезонную какую-то модель. Если мы вернемся обратно к модели исходного ряда, проведя обратное преобразование к преобразованию Бокса-Кокса и к проведенному сезонному дифференцированию, вот так может, например, выглядеть модель. Это модель SARIMA порядка (2, 0, 1) x (2, 1, 2) с преобразованием Бокса-Кокса. Здесь красная линия — это предсказание нашей модели. Как видим, она достаточно хорошо описывает наш исходные ряд, а значит, мы можем надеяться, что и прогнозы она будет давать достаточно хорошие. Давайте вспомним, как для этого ряда выглядели остатки простых регрессионных моделей. Когда мы делали регрессию на линейный квадратичный тренд во времени, мы получали вот такие остатки — мы в них видим очень много структуры, а это значит, что в данных еще остается очень много информации, которую наша модель не учитывает. Вот так выглядят остатки модели ARIMA, которую мы только что построили. Эти остатки намного больше похожи на белый шум, в них есть некий выброс — это кризис 98-го года, который построенной нами моделью плохо описывается. Но тем не менее структуры в том, что осталось после применения нашей модели ARIMA, практически уже нет. В любом случае это что-то намного лучше, чем наша линейная регрессия. Итак, в этом видео мы разобрали класс моделей ARIMA, который описывает произвольные, в том числе нестационарные, временные ряды. В следующем видео мы разберемся с тем, как подбирать многочисленные параметры, которые в моделях ARIMA есть.

[БЕЗ_ЗВУКА] Мы теперь знаем, как устроены модели класса ARIMA. Давайте теперь разберемся с тем, как эти модели правильно настраивать и как с их помощью получать прогнозы. У моделей класса ARIMA есть несколько групп параметров. Во-первых, есть параметры d, D, p, P, q, Q, которые можно считать гиперпараметрами, поскольку они определяют структуру и количество коэффициентов в самой модели ARIMA. Все остальные параметры — α, φ и θ — это те параметры, которые непосредственно стоят в качестве коэффициентов в регрессионном уравнении. Давайте разберемся с тем, как вот это все можно правильно настраивать. Если d, p и q фиксированы, то есть зафиксирована структура нашей модели ARIMA, то параметры α, φ и θ можно подобрать с помощью метода наименьших квадратов, то есть фактически мы будем делать привычную для нас регрессию методом минимизации квадратичной ошибки. Единственный трюк здесь заключается в определении коэффициентов θ, которые стоят при шумовых компонентах из прошлого. Шумовые компоненты мы наблюдать не можем, поэтому для того чтобы подставить их в регрессионное уравнение, их нужно предварительно оценить. Обычно их оценивают с помощью остатков от авторегрессии, которая построена предварительно на этих данных. Если шум, который стоит в нашей модели ARIMA, белый, то есть независимый, одинаково распределенный гауссовский, то метод наименьших квадратов дает оценки максимального правдоподобия для параметров α, φ и θ. То есть мы уже знаем, что эти оценки заведомо хороши. Что касается параметров d и D, которые задают порядки дифференцирования, подбирать их нужно так, чтобы ряд становился стационарным. Мы уже говорили о том, что всегда рекомендуется начинать именно с сезонного дифференцирования, потому что уже после него ряд может оказаться стационарным. Дело в том, что нам выгодно продифференцировать ряд как можно меньше раз. Чем меньше мы дифференцируем, тем меньше дисперсия нашего итогового прогноза. Остается еще четыре гиперпараметра: это p, P, q, Q. Эти гиперпараметры, к сожалению, нельзя выбирать из принципа максимума правдоподобия, потому что чем больше, например, p, тем больше у вас авторегрессионный компонент в вашем уравнении, тем больше в нем параметров φ, и значит, тем лучше вы описываете вашим уравнением данные. То есть чем больше значение гиперпараметров, тем больше параметров в вашей модели, и тем более она сложная. То есть правдоподобие всегда с увеличением p и q только может увеличиваться. Поэтому нужен какой-то другой критерий, для того чтобы сравнивать модели с разным количеством параметров. В качестве такого критерия можно использовать, например, информационный критерий Акаике, который представляет собой сумму взятого со знаком минус удвоенного логарифма правдоподобия и штрафа за количество параметров модели 2k. Оптимальной по критерию Акаике будет модель, у которой значение этого критерия самое маленькое из всех возможных, потому что такая модель будет достаточно хорошо описывать данные, с одной стороны, и содержать не слишком большое количество параметров, с другой. Подбирать значения четырех параметров p, P и q, Q в конечном итоге мы будем перебором: то есть мы будем перебирать разные значения всевозможные и смотреть на модель, у которой получилось самое маленькое значение критерия Акаике. Но начальное приближение для этого перебора можно задать, и в этом нам может помочь автокорреляционная функция. Перед вами ряд с реальной заработной платой в России после преобразования Бокса-Кокса и сезонного дифференцирования, а также его автокорреляционная функция. Начальное приближение для Q нам дает номер последнего сезонного лага, при котором автокорреляция значима. В данном случае сезонных лагов со значимой автокорреляцией нет, поэтому начальное приближение для Q берем, равным нулю. Что касается q, его задает номер последнего несезонного лага, при котором автокорреляция значима. В данном случае в качестве начального приближения для q можно взять 8. Параметры p, P мы будем выбирать по графику не автокорреляционной функции, а ее «родственницы» — частичной автокорреляционной функции. Частичной автокорреляцией назвается автокорреляция после снятия авторегрессии предыдущего порядка. Например, для того чтобы посчитать частичную автокорреляцию с лагом 2, нам нужно построить авторегрессию порядка 1, вычесть эту авторегрессию из ряда и посчитать автокорреляцию на полученных остатках. Начальное приближение для P нам задает номер последнего сезонного лага, при котором частичная автокорреляция значима. В данном случае это лаг номер 24. Таким образом, в качестве начального приближения для P мы будем брать 2, поскольку сезонный период здесь у нас длиной 12. По аналогии p задается как номер последнего несезонного лага, при котором частичная автокорреляция значима. В данном случае начальное приближение для p можно также взять равным 2. Обобщим всю информацию, которую мы получили про ряд реальной заработной платы в России, и будем перебирать разные модели в классе ARIMA со значениями параметров D = 1, d = 0, преобразованием Бокса-Кокса, начиная с тех начальных приближений, которые мы получили из автокорреляционных функций. Сравнивать разные модели будем по информационному критерию Акаике и получим, что самая лучшая по этому критерию модель — это модель ARIMA порядка (2, 0, 1) x (2, 1, 2). Как видите, эта модель достаточно хорошо описывает данные. В целом алгоритм построения моделей в классе ARIMA следующий. Во-первых, в первую очередь всегда нужно построить график ряда и посмотреть на него глазами. Уже при визуальном анализе вы поймете, какие у этого ряда есть особенности: есть ли у него сезонность, какой у него сезонный период, есть ли в ряде пропуски и выбросы, может быть, начало этого ряда вообще следует отрезать, потому что значение в начале ряда совершенно не похоже на те, которые есть в конце. Вам же нужно строить прогноз на то, что будет после конца, поэтому то, что было в самом начале, не так важно. Кроме того, из визуального анализа вы можете понять, нужно ли для ряда стабилизировать дисперсию. Если это нужно сделать, это нужно сделать на втором этапе, применив преобразование Бокса-Кокса, или, если это допустимо, обычное логарифмирование, которое является частным случаем Бокса-Кокса. Если ряд, который вы анализируете, является нестационарным, нужно подобрать порядок дифференцирования, которое его делает стационарным. Таким образом, в модели ARIMA вы фиксируете значения параметров d, D. Дальше. Строятся графики автокорреляционной функции и частичной автокорреляционной функции, с помощью которых вы определяете примерные значения параметров p, P, q, Q. Фактически эти значения — это всего лишь начальные приближения, с которых вы начинаете перебор разных моделей. На следующем шаге все эти модели обучаются, вы сравниваете их по информационному критерию Акаике и выбираете победителя — ту модель, которая этот критерий минимизирует. Есть еще шестой шаг, который связан с анализом остатков. На остатки полученной модели нужно смотреть для того, чтобы понять, насколько эта модель получилась хорошей, можно ли ее теоретически улучшить, нет ли у нее каких-то существенных недостатков. О том, как правильно остатки анализировать, мы поговорим в следующем видео. А пока давайте разберемся с тем, как на основании имеющейся у вас настроенной модели ARIMA правильно строить прогноз. Пусть вот так выглядит построенная вами модель. Вы определили значения всех неизвестных параметров этой модели, получили их оценки, вот они и записаны в этом уравнении: α с крышкой, φ с крышкой, θ с крышкой. Для того чтобы построить прогноз на момент времени T + 1, нужно просто в этом уравнении для начала заменить все индексы t на T + 1. Получается вот так. Следующий шаг. Заметим, что в этом уравнении есть значение ошибки из будущего. Вы не можете знать, какой в будущем будет шум, но можно предполагать, что этот шум в среднем равен нулю. Поэтому можно безболезненно просто заменить будущие ошибки на нули, то есть фактически вы просто удаляете из этого уравнения все члены, которые связаны с ошибками из будущего. Следующий шаг. Здесь еще есть ошибки из прошлого. Ошибки из прошлого ε мы заменяем на остатки вашей модели в этих точках. То есть ошибки в прошлом мы оцениваем с помощью остатков в этих точках, потому что остатки — это и есть самые лучшие оценки ошибок, которые у нас есть. Если нам необходимо построить прогноз не на одну точку вперед, а, например, на две, то при прогнозировании на момент времени T + 2 в нашем уравнении в формуле появляется значение ряда из будущего, то есть в данном случае в нем есть значение Y в момент времени T + 1, которое в момент времени T вы, естественно, знать не можете. Такие значения просто заменяются на соответствующие прогнозы, то есть все значения ряда из будущего заменяются на прогнозы, полученные из предыдущих операций. Вот так выглядит прогноз на два года вперед для ряда с реальной заработной платой в России, построенный с помощью модели ARIMA порядка (2, 0, 1) x (2, 1, 2) и преобразования Бокса-Кокса. Как вы видите, этот прогноз не выглядит тривиальным — он не является константой, он не ведет себя странно, не падает до нуля, то есть в какой-то степени визуально мы этот прогноз одобряем. Итак, в этом видео мы поговорили о том, как правильно подбирать параметры и гиперпараметры для моделей в классе ARIMA, а также разобрали подробный алгоритм выбора оптимальной ARIMA для ваших данных и то, как с помощью этой оптимальной ARIMA потом строится прогноз. В следующем видео мы поговорим про анализ остатков, который позволяет ответить на более глобальный вопрос: является ли моя модель хоть сколько-нибудь хорошей? Нет ли в ней каких-нибудь фундаментальных недостатков? Ведь то, что ваша модель ряда — самая лучшая в классе всех возможных ARIMA, еще не означает, что она сама по себе абсолютно достаточно хороша.

В этом видео мы разберём, как строить прогноз временного ряда с помощью стандартных и не очень стандартных функций, которые есть в Python'е. Задачи, которые мы будем решать, следующие: известны ежемесячные продажи австралийского вина в тысячах литров с января 1980 года по июль 1995. Мы хотим построить прогноз этого ряда на следующие три года. Давайте начнём. Импортируем все нужные модули и создадим ещё некоторые новые функции, например, функцию, которая делает обратное преобразование Бокса-Кокса. К сожалению, в Python'е нет функции, которая это делает в стандартных пакетах, поэтому мы напишем её сами, но в этом нет ничего сложного. Вот так выглядит ряд, который мы собираемся прогнозировать. Что можно заметить про этот ряд? У него достаточно сильно выраженная годовая сезонность, кроме того кажется, что здесь есть какой-то тренд, не линейный, но тем не менее, возможно, этот тренд можно как-то описать. Кроме того, у этого ряда, кажется, нестационарная дисперсия. Размах сезонных колебаний здесь в начале ряда немного меньше, чем вот здесь, ближе к концу ряда. Прежде чем начинать этот ряд моделировать, давайте ещё немного его предварительно поанализируем. Ну, во-первых, проверим критерием Дики-Фуллера формально стационарность. Мы видим, что достигаемый уровень значимости критерия Дики-Фуллера чуть-чуть больше 0,05, то есть гипотеза нестационарности для этого ряда не отвергается, однако значения — пограничны. Давайте сделаем ещё одно очень полезное действие. Сделаем STL-декомпозицию. STL-декомпозиция — это некоторый набор эвристик, который позволяет вам визуально посмотреть, из каких примерно компонент состоит ваш ряд. Вот результат применения STL-декомпозиции — перед вами, на графике. На верхнем из четырёх графиков — исходный ряд. На нижних трёх соответственно тренд, сезонность и остатки. То есть всё, что не определяется суммой вот этого тренда и сезонности, каким-то образом оцененных. Значит, что мы здесь видим? Сезонный профиль достаточно хорошо выражен. Тренд имеет достаточно сложную структуру. Сначала он повышается, затем доходит до некоторого пика, немного понижается и медленно возвращается на исходный уровень. Это ещё раз нам подтверждает, что ряд трудно считать стационарным. В качестве следующего шага давайте сделаем стабилизацию дисперсии методом Бокса-Кокса. Это делает функция boxcox, она возвращает преобразованный ряд и автоматически каким-то образом наилучшее подобранное значение параметра лямбда ( λ). В данном случае это значение равно примерно 0,24. А вот так выглядит преобразованный ряд. Критерий Дики-Фуллера на этом ряде даёт достигаемый уровень значимости примерно 0,03. То есть нулевая гипотеза нестационарности отвергается, и этот ряд критерий Дики-Фуллера считает стационарным. Тем не менее, мы очень хорошо видим, что стационарным этот ряд считать нельзя, потому что, во-первых, в нём очень сильно выражена сезонность, во-вторых, в нём есть вот тот самый тренд, который мы наблюдали на STL-декомпозиции. Критерий Дики-Фуллера — это всего лишь инструмент, и не очень совершенный. Поэтому, если вы видите, что ваш ряд явно не стационарен, не нужно доверять тому, что говорит вам критерий Дики-Фуллера. Вот и мы не будем. Давайте проведём дифференцирование ряда, для того чтобы добиться стационарности. Начнём с сезонного дифференцирования, сделаем это сезонное дифференцирование, снова применим к продифференцированному ряду критерий Дики-Фуллера и посмотрим на его STL-декомпозицию. На продифференцированном ряде гипотеза нестационарности не отвергается. Достигаемый уровень значимости — примерно 0,013. А вот так выглядит результат STL-декомпозиции. Посмотрите, как здесь изменился тренд. Он практически константный на первом участке ряда, но вот в месте, где происходил в исходном ряде перегиб тренда, мы видим существенный провал. То есть не удивительно, что этот ряд остался нестационарным. Давайте применим ещё одно дифференцирование. На сей раз — обычное. На продифференцированном ещё раз ряде критерий Дики-Фуллера гипотезу нестационарности уверенно отвергает с очень маленьким достигаемым уровнем значимости. А вот так выглядит STL-декомпозиция два раза продифференцированного ряда. На этот раз мы на трендовой компоненте не видим никакого систематического поведения. То есть она колеблется примерно вокруг константы. Это то, чего мы хотели добиться. Видимо, этот ряд уже можно считать стационарным. Перейдём теперь к подбору моделей ARIMA. Давайте посмотрим на автокорреляционную и частично автокорреляционную функцию вот этого два раза продифференцированного ряда. Они выглядят вот так. На верхнем графике — автокорреляционная функция, и по этому графику мы будем подбирать начальное приближение для параметров q и Q. Максимальный сезонный лаг, значимо отличающийся от ноля, то есть вылезающий из вот этого синего коридора, это лаг 12. Таким образом, начальным приближением для Q мы будем брать единицу. Что касается q — здесь значимо отличаются от нуля первые два несезонных лага. Таким образом, для q начальное приближение мы будем брать равным двойке. Перейдём к начальному приближению для P. На частично автокорреляционной функции единственный сезонный лаг, значимо отличающийся от нуля — это лаг 12. Значит P мы возьмём равным единице, для начала. Что касается p — в начале при маленьких лагах на частично автокорреляционной функции есть несколько значимо отличающихся от ноля. Возьмём, допустим, p равным четырём. Прекрасно. Давайте теперь с этим начальным приближением будем делать перебор. Переберём все значения параметров p, P и q, Q от нуля до вот этих приближений, которые мы подобрали по графикам автокорреляционных функций. Всего таких моделей будет 60. Давайте просто настроим все их и посчитаем для каждой значение информационного критерия Акаике, выберем ту модель, у которой это значение будет минимальным. Это делает следующий кусок кода. Сезонная модель ARIMA настраивается с помощью функции SARIMAX из пакета statsmodels. Если эта функция у вас не будет работать, вам нужно будет обновить пакет statsmodels, так чтобы у вас была его версия выше седьмой. Начиная с восьмой версии эта функция уже работает. Перед тем как делать перебор, давайте отключим Warning'и. Дело в том, что не все модели, которые мы будем перебирать, можно хорошо настроить. Часть из них будут расходящимися, и про все такие модели Python нам будет выдавать предупреждение о том, что сходимости не произошло. Отключим вывод этих предупреждений и будем просто печатать параметры каждой модели, которая не сошлась. Прекрасно. Этот код выполняется довольно долго. 60 моделей перебирается в течение примерно 20 секунд. Вот есть несколько комбинаций значений параметров, при которых сходимости не произошло. Давайте посмотрим на лучшие модели. Самый лучший результат, то есть результат с минимальным значением информационного критерия Акаике показала вот такая модель: С p = 2, q = 1, P = 0 и Q = 1. Если мы посмотрим на всякий случай на несколько следующих по AIC'у моделей, мы увидим, что эти модели хоть и близки по значению информационного критерия, но параметров в них больше. Таким образом, мы действительно можем убедиться в том, что наша лучшая модель с самым маленьким Акаике не станет немножко незначительно хуже, если мы её чуть-чуть упростим. То есть никакая простая модель, более простая модель здесь в топ не входит. Модель на пятом месте — достаточно простая. Параметров в ней на один меньше, но значение информационного критерия Акаике у неё уже больше на три единицы. Давайте посмотрим на нашу лучшую модель. Используем метод Summary и посмотрим, что наша функция из statsmodels нам настроила. Мы получили модель SARIMAX с параметрами (2, 1, 1) (0, 1, 1). Сезонный период мы фиксировали и задали равным 12. Что ещё здесь есть полезного в этом выводе? Здесь есть значение статистики критерия Льюнг — Бокса при каком-то автоматически выбранном Q и соответствующий достигаемый уровень значимости — мы видим, что достигаемый уровень значимости достаточно большой. То есть, по всей видимости, остатки модели не автокоррелированы. Вот всё, что в этом блоке выводится, вся информация, она касается именно остатков. Ну что здесь ещё можно посмотреть интересного? Пожалуй, всё остальное не представляет большого интереса. Давайте сделаем визуальный анализ остатков нашей модели. Вот так они выглядят. На первый взгляд кажется, что всё в порядке. В этих остатках не видно никакого тренда, никакой сезонности, они довольно-таки похожи на шум. Вот так выглядит автокорреляционная функция этих остатков, и мы видим, что здесь нет никакой существенной структуры. Да? Некоторые лаги действительно значимо отличаются от нуля. Но эти лаги находятся достаточно далеко, то есть эти лаги — большие. Ну, естественно, что какие-то лаги, когда вы строите автокорреляционную функцию, могут отличаться от нуля чисто случайно, просто в силу эффекта множественной проверки гипотез. Поэтому об этом можно не беспокоиться. Тем более вот здесь отличие от нуля возникает при лаге 22 — это лаг не сезонный, следовательно, можно закрыть на это глаза. Проверим свойства остатков с помощью формальных критериев. Критерий Стьюдента проверяет гипотезу несмещённости и её не отвергает с достигаемым уровнем значимости примерно 0,26. Критерий Дики-Фуллера уверенно отвергает гипотезу нестационарности. Таким образом, мы получаем, что остатки не смещены, стационарны и неавтокоррелированы. Следовательно, наша модель достаточно хороша. Давайте посмотрим, насколько хорошо эта модель описывает данные. Вот здесь синяя линия — это исходный ряд. А красное — это то, что предсказывает нашу модель в этом месте. Мы видим, что действительно модель и данные достаточно похожи друг на друга. Ну всё. Давайте теперь построим прогноз. Прогноз делается с помощью функции predict. Не забудем применить обратное преобразование к преобразованию Бокса-Кокса, потому что модель, которую мы подобрали, она не знает о том, что исходный ряд был преобразован. И всё в ней подбирается на ряд после преобразования Бокса-Кокса. Вот. Ну и вот результат нашего прогнозирования. Здесь синее — это информация, которая у нас была. Красное — это прогноз на три года вперёд. Этот прогноз выглядит достаточно адекватным. Он передаёт то, что мы знаем о сезонности, глядя на предыдущий кусок ряда, и в нём, в принципе, нет тренда. Ну, это тоже можно понять, потому что тренд имел достаточно сложную структуру, и похоже, вот в тот момент, в который мы делаем предсказание, очень сложно знать заранее, будет ли средний уровень ряда дальше повышаться или понижаться. Прогноз достаточно адекватный.

В этом видео мы познакомимся с регрессионным подходом к прогнозированию и обсудим задачи, в которых использование именно этого подхода позволяет добиться существенного улучшения точности ваших прогнозов. Перед вами ежемесячные данные по потреблению электричества в Турции. На графике очень хорошо видна годовая сезонность, но видны на нем также и еще какие-то странные падения. Вот эти падения соответствуют месяцам, на которые выпадают праздники по исламскому календарю. Исламский календарь примерно на 11 дней короче григорианского. Поэтому праздники, которые по нему определяются, попадают все время в разные места стандартного григорианского года. Поэтому вот такие падения невозможно учесть с помощью стандартной сезонности с периодом 12. Это плохая новость. Хорошая заключается в том, что мы точно знаем всегда, на какой именно месяц в каждом году выпадет вот такого рода праздник. Поэтому мы можем сформировать бинарный признак, в котором единички будут соответствовать месяцам с праздниками, а нули — всем остальным. Вот такие признаки можно каким-то образом попытаться встроить в нашу модель типа ARIMA. Делается это следующим образом: мы считаем, что значение ряда y определяется линейной комбинацией каких-то признаков x, таких признаков будем брать k штук. То есть, фактически y задается в первую очередь линейной регрессией, но вот остатки этой линейной регрессии моделируются моделью ARIMA, которой мы все это время занимались. Такого рода модель, которая комбинирует линейную регрессию и ARIMA, называется regARIMA, или ARIMAX. Давайте разберем еще один пример, когда такого рода модель очень полезна. Это ситуации, когда вы имеете дело с рядами со сложной сезонностью. Например, если вы посмотрите на потребление электричества не по месяцам, а по дням, вы будете иметь дело с рядом, в котором есть, во-первых, недельная сезонность, во-вторых, годовая, ну и, наконец, опять те же самые праздники по исламскому календарю. К сожалению, ARIMA очень плохо работает с рядами со сложной сезонностью. Проблем здесь несколько. Во-первых, при длинных сезонных периодах в сезонных моделях ARIMA становится просто слишком много параметров, и часто по ряду невозможно их все оценить. Во-вторых, ARIMA явно задает значение ряда как функцию от значения этого же ряда, например, один сезонный период назад. Странно ожидать, что если вы имеете дело с дневным рядом, то его значение определяется ровно значением в эту же дату прошлого года. Скорее всего, просто значение ряда в какой-то окрестности текущей даты похоже на значение ряда в этой же самой окрестности этой даты в прошлом году. Наконец, еще одна, большая довольно проблема, заключается в том, что длина года не целая. Равна она, например, на 365 дням в точности, а 365,25. Если вы имеете дело с недельными данными, то длина года тоже не 52 недели ровно, а 52,18. И вот это уже проблема, с которой ARIMA работать не может совершенно никак, потому что в нашем ряде нет измерений с индексом 52,18, мы не можем это измерение поставить внутрь ARIMA. Решить эту проблему можно в рамках регрессионного подхода. Давайте для ARIMA оставим только самый короткий из всех имеющихся сезонных периодов, а все более длинные будем учитывать с помощью регрессии на специальным образом построенные признаки. Признаки эти вот такие: возьмем Фурье-гармоники, то есть синусы и косинусы с периодами, пропорциональными длине наших сезонных периодов, то есть, например, синусы и косинусы с периодами 365,25; 365,25/2 365,25/3 и так далее. Возьмем какое-то количество этих гармоник и просто подставим их как регрессионную компоненту в регрессионную ARIMA. Вообще говоря, можно придумать еще много вещей, которые можно подставлять в регрессионную компоненту. Можно брать вот эти самые гармоники по длинным периодам сезонности. Для коротких периодов сезонности можно брать индикаторы. Например, для дней недели можно в явном виде задать индикатор понедельника, индикатор вторника и так далее и просто в явном виде подставить их в регрессионную ARIMA и в явно недельную сезонность уже никак больше не учитывать. Кроме того, имеет смысл использовать индикаторы праздников. Часто также оказываются полезными индикаторы пред- и постпраздничных дней. В регрессионную компоненту можно добавить и тренды, которые мы пытались использовать в самом начале, когда только думали, а какими способами вообще можно прогнозировать временные ряды — линейный, квадратичный, какой угодно. Кроме того, в качестве регрессионных признаков можно использовать скользящие средние значения ряда за предыдущие периоды. Например, в каждой точке вы считаете среднее за прошлый месяц или прошлую неделю, и вот именно такие признаки подставляете в регрессионную ARIMA. Часто оказывается, что если вы взяли много хороших признаков, хорошо подумали и сделали на эти признаки регрессию, делать поверх этой регрессии ARIMA уже не нужно. Выигрыш в качестве за счет вот этой авторегрессионной добавки оказывается незначительным, практически незначимым. Я в своей практике сталкивался с этим достаточно часто. Кроме меня, об этом рассказывают, например, сотрудники «Фейсбука» на конференциях. Они внутри используют именно такую регрессионную систему прогнозирования своих показателей. Кроме того, именно такой регрессионный подход к прогнозированию используется, например, в майкрософтовской системе Azure. Никаких специфических методов прогнозирования временных рядов внутри нее нет. Специфические методы прогнозирования временных рядов хороши, когда у вас есть один, несколько или максимум несколько десятков любимых рядов, которые вы прогнозируете постоянно. На каждый из этих рядов вы можете посмотреть глазами, тщательно подобрать хорошую модель, проанализировать качество этой модели, посмотреть на остатки, перестроить и так далее. Вот это все ручной труд, и часто возможности для такого ручного труда нет. Например, нет ее в задаче массового прогнозирования. Представьте, что вам нужно спрогнозировать дневные продажи товаров в магазинах. У вас есть продажи, остатки этих товаров, цены на товары, информация о скидках, промоакциях, об иерархии товаров, иерархии расположения торговых точек, в которых эти товары продаются, и так далее. Ваша задача — это построить прогнозы продаж всех товаров во всех магазинах. Ясно, что таких временных рядов слишком много для того, чтобы их можно было спрогнозировать вручную. На помощь вам может прийти регрессионный подход. Если вы хорошенько сконструируете признаки, которые будут содержать всю имеющуюся у вас информацию, и используете на этих признаках какую-то регрессионную модель, далеко не обязательно линейную, может быть, более сложную, которая будет позволять признакам взаимодействовать друг с другом, то вы можете получить уже таким способом достаточно хорошее решение. Итак, в этом видео мы поговорили про регрессионный подход к прогнозированию временных рядов. Мы узнали, что в моделях класса ARIMA можно учитывать какие-то внешние факторы, на которые параллельно с тем, как строится модель ARIMA, делается регрессия. Кроме того, мы поговорили о том, что при хорошем подборе вот этих внешних факторов часто оказывается, что строить поверх этого авторегрессионную модель уже не нужно. Таким образом, мы свели задачу прогнозирования временного ряда к тому, что мы лучше всего умеем и любим решать — задачу обучения с учителем. Тем не менее, важно помнить две вещи. Во-первых, для того чтобы этот регрессионный подход работал, необходимо при конструировании признаков явно учитывать временную природу данных. Во-вторых, даже если вы построили какую-то достаточно хорошую обычную регрессионную модель, если у вас есть возможность, попробуйте поверх нее наложить авторегрессию или еще какую-то из моделей временных рядов, о которых мы в этом курсе не говорили. Возможно, это поможет вам улучшить качество ваших прогнозов.
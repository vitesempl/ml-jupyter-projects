В этом видео мы поговорим про задачу классификации изображений. Классификация изображений — это задача, когда нужно картинки разложить на несколько категорий. Например, бинарная классификация, когда нужно разложить на два класса, например картинки, сделанные в помещении и вне помещений, или мультиклассовая классификация, когда нужно разложить картинки на множество категорий, например определить породу собак. Существует такая база изображений, которая называется ImageNet, в ней содержатся 10 миллионов изображений из Интернета. Картинки достаточно сложные, разнообразные, и они вручную размечены на принадлежность к тому или иному классу. На этих картинках мы можем видеть несколько примеров из этой базы. Нужно отметить, что в базе есть ошибки и спорные случаи. Например, вот эта картинка отмечена как «вишня», и если ответить, что на картинке далматинец, то это будет неправильно. Так вот, На этой базе ImageNet периодически проводятся соревнования по классификации, и в задаче классификации участвует миллион картинок из данной базы. Нужно для каждой картинки из этого миллиона ответить на вопрос, к какому из тысячи классов она принадлежит. И можно давать больше одного ответа, и если в первой пятерке будет правильный ответ, то считается, что мы ответили правильно. До 2012 года лучший результат на этом соревновании показывали методы с количеством ошибок 25 %. Начиная с 2012, лидерство захватили глубокие нейронные сети, и первый же результат был 16 % ошибок, то есть количество ошибок снизилось почти в 2 раза. Можно сказать, что именно в 2012 году произошла революция в компьютерном зрении. Сначала нейронные сети победили в этом соревновании, а потом они все больше и больше задач компьютерного зрения захватывали и показывали, что нейронные сети работают гораздо лучше, чем традиционные подходы. Что такое нейронные сети, было разобрано в предыдущих лекциях. Мы с вами сосредоточимся сейчас на нейронных сетях, которые используются именно для классификации изображений. Есть несколько ключевых отличий, одно из них заключается в сверточных слоях. В прошлом видео мы разбирали, как свертка используется для обработки изображения, здесь то же самое, только свертка применяется не к картинке, а к выходам предыдущего слоя. Соответственно, каждый слой состоит из банка фильтров. Помимо сверточных слоев используется такая процедура, как пулинг. Пулинг выбирает из нескольких элементов один, остальные выбрасывает. Например, можно использовать max-пулинг, то есть выбирается элемент с максимальным значением. Другой трюк, которые применялся в 2012 году — это применение dropout'а. Dropout используется для того, чтобы обнулить часть выходов предыдущего слоя. Это такой метод регуляризации, чтобы сеть не переобучалась на одних и тех же выходах. Несмотря на то что многие считают dropout очень неинтуитивным способом регуляризации, и тем не менее работает, как показала практика, он очень хорошо. Еще один трюк, которые был применен для обучения на базе ImageNet — это дополнение обучающих данных. Чем больше данных, тем лучше себя чувствуют нейронные сети, поэтому можно использовать разнообразные подходы для пополнения коллекции. Например, в работе 2012 года использовались методы вырезания кусочка картинки так, чтобы класс не изменялся. Также вносились цветовые шумы, производилось зеркальное отражение и использовались другие изменения, которые не влияли на содержание картинки, но при этом обучали и позволяли сети добиться инвариантности к таким изменениям. Собственно, вот так выглядела та самая знаменитая сеть, которая победила в этом конкурсе, которую придумал и сделал аспирант Хинтона Крижевский в 2012 году. Сеть состоит из пяти сверточных слоев, двух полносвязных слоев и выходной слой, состоящий из тысячи выходов. Тысяча выходов — это столько, сколько классов в задаче классификации, то есть тот выход, который имеет максимальное значение, кодирует класс, к которому, по мнению нейронной сети, принадлежит картинка. Данная сеть, как я уже говорил, достигнула 16.5 % ошибок, после этого появилось много других архитектур, которые улучшили этот результат. Но первым заметным улучшением было не изменение архитектуры, а использование ансамблей. Идея очень простая: давайте обучим несколько нейронных сетей, на каждую картинку будет применять каждую из этих сетей, а результат усреднять. Такая простая операция позволяет повысить точность и уменьшить число ошибок с 16.5 % до 11.7 %. В 2014 году группа из Оксфорда предложила новую архитектуру, которая состояла из 19 слоев, большая часть из которых были сверточные, причем все сверточные слои состояли из маленьких сверток размера 3 x 3. И данная сеть позволила им улучшить результат и снизить ошибку, и существенно снизить ошибку. Следующая архитектура — так называемая GoogLeNet. GoogLeNet состоит из компонент, которые представлены на этой картинке. В чем идея использовать данную компоненту? На каждом слое мы используем свертку не фиксированного размера, а несколько сверток разного размера. Это позволяет реагировать на сигналы разного масштаба и существенно улучшает качество работы. Вот так выглядит полностью GoogLeNet, а вот сравнительная таблица результатов и эволюции ошибки. То есть мы видим, что VGG и GoogLeNet существенно снизили ошибку до размера порядка 7.5 % соответственно. И наконец, следующая архитектура, которая состояла аж из 152 слоев — это так называемые residual neural networks, и лучший результат на данный момент был достигнут с помощью нейронных сетей вот такой архитектуры. Ключевым элементом этой сети является связь, которая пропускает несколько слоев и передает выходы предыдущего слоя напрямую на выход этих нескольких слоев. Интересный момент, что такое изменение позволило полностью отказаться от методов регуляризации, таких как dropout, и позволила сделать сети глубиной 152 слоя. Так вот, лучший результат на данный момент — это меньше 4 % ошибок, то есть в 2012 было 16, сейчас — меньше 4, то есть количество ошибок уменьшилось больше, чем в 4 раза. Мы видим, что за последние 4 года совершен огромный скачок в задаче решения классификаций изображений. И этот скачок произошел благодаря развитию нейронный сетей и глубокому обучению. Помимо задачи классификации, нейронные сети активно применяются почти во всех задачах компьютерного зрения. И об этих задачах мы поговорим в следующих видео.

В прошлом видео мы поговорили о том, как решаются задачи классификации изображений с помощью глубоких нейронных сетей. Давайте теперь обсудим, как решать такие задачи на практике. Представим, что у нас появилась такая необходимость, нужно классифицировать картинки. Прежде всего, нужно собрать базу изображений, про которые мы заведомо знаем, к какому классу они принадлежат. После этого нам нужно определиться с алгоритмом, которым мы будем классифицировать изображения, и при необходимости как-то эти картинки предобработать. Чуть позже мы поговорим о том, как это можно сделать. Ну и, собственно, после этого необходимо обучить нейронную сеть. Обсудим сначала, какие бывают библиотеки. Библиотек, на самом деле, огромное множество, часть из них перечислена на этом слайде, поговорим про каждую из них и обсудим плюсы и минусы. Библиотека torch7 написана на C++, все взаимодействие с клиентским кодом происходит через Lua. torch7 существует достаточно давно, и очень много готовых реализаций для разнообразных задач. Tensorflow. Относительно новая, очень удобная библиотека, из минусов: как раз из-за того, что она новая, очень часто возникает ситуация, что исторические реализации сделаны на других библиотеках, на tensorflow приходится что-то дописывать. С другой стороны, это делать часто очень просто, поэтому можно просто реализовать то, чего нет. Библиотека theano. Тоже существует достаточно давно, очень популярна в академических кругах. Ученые любят использовать ее для иллюстраций своих статей и для быстрых экспериментов. Из минусов: она достаточно низкоуровневая, и требуется много сил и опыта, чтобы понять, как с помощью нее работать с сетями. То есть она на самом деле про тензорные вычисления, а не про нейронные сети, и нужен просто некоторый опыт, чтобы с ней работать. Поэтому очень часто работают не непосредственно с theano, а используют некие обертки вокруг нее. Две из них — это keras и lasagna, и они как раз позволяют работать с theano в более удобном виде. Ну и, наконец, последняя библиотека, упомянутая на этом слайде — это caffe, это одна из первых библиотек для работы со сверточными нейронными сетями, она написана на C++, и из ее плюсов: то, что очень часто ее используют для продакшн-задач. Потому, что она на C++, потому, что часть про исполнение и применение нейронных сетей, она достаточно хорошо отделима. При выборе библиотеки стоит обращать на разнообразные факторы, приходится учитывать любовь разработчиков к тому или иному языку программирования: кто-то предпочитает Python, кто-то — Lua, ну и, наконец, хороший способ — просто попытаться посмотреть, кто решал похожую задачу и на каком фреймворке, и брать эту реализацию за основу. Поэтому это очень часто тоже определяет выбор библиотеки: если что-то уже готово на torch7, зачем пробовать что-то другое? В принципе, переключения между этими фреймворками не такие сложные, идеология у них похожа, поэтому если разобраться, как работает один из них, то другим воспользоваться тоже можно. Кроме того, существуют конвертеры моделей между этими фреймворками, это тоже облегчает переходы. Соответственно, выбирать библиотеку нужно, исходя из задач. Если никаких нет других предпочтений, я бы рекомендовал воспользоваться tensorflow. Из плюсов tensorflow: у него очень хорошая и богатая документация, очень много туториалов, поэтому он прекрасно подходит именно для знакомства с библиотеками про нейронные сети. Из плюсов еще у tensorflow достаточно хороший и простой python api, а само ядро библиотеки написано на С++. Поэтому, опять же, если говорить про внедрение в продакшн, есть отделимая часть, которая только про исполнение модели. Почему я говорю про внедрение в продакшн? Очень часто решение задачи классификации, оно разделяется на две части: мы подбираем модели, обучаем классификаторы, а потом уже обученные классификаторы куда-то внедряются, и для исполнения вот этих моделей, на самом деле, все библиотеки обучения нейронных сетей, они не нужны, нужна только та часть про исполнение. В некоторых библиотеках эту часть легко отделить, или можно взять целиком библиотеку, и она никак не влияет на производительность, а в некоторых библиотеках возникают некоторые проблемы. tensorflow здесь удобно в этом смысле сделана. Второй момент, который стоит обязательно учесть при решении практической задачи: нужно прежде всего посмотреть, не решал ли кто-то задачу до этого, и нет ли вообще готового решения. Готовое решение можно искать в так называемом зоопарке моделей, например, для библиотеки caffe есть единый репозиторий таких моделей, и можно просто попытаться найти там, что уже готово. То есть там есть несколько моделей, обученных для ImageNet, причем с лучшими результатами на момент обучения, есть другие прикладные задачи. Поэтому, возможно, ничего придумывать не нужно, и ваша практическая задача уже решена кем-то. Тогда берем готовую модель и используем ее на практике. Одна из самых часто используемых моделей — это модель, обученная оксфордской группой под названием VGG, ее устройство мы обсуждали в предыдущем видео, вот она есть готовая в том же зоопарке моделей. Из ее плюсов: у нее очень простая структура, она наиболее кроссплатформенная между библиотеками, поэтому поддерживается, скорее всего, любой библиотекой нейронной сети, которую мы будем использовать на практике, и у нее достаточно хорошие результаты. Она не самый лучший результат показывает на коллекции ImageNet, но входит в тройку. Есть готовая VGG-модель для библиотеки caffe, и, как я уже говорил, из этой библиотеки есть конвертеры в любую другую модель. Вернемся к нашей задаче. У нас стоит задача сделать классификацию на какие-то классы, которых нет в исходном ImageNet. Коллекцию мы собрали, и теперь у нас есть разные варианты. Можно взять нашу коллекцию и обучить нейронную сеть с нуля, так же, как это делали для решения задачи ImageNet. Но это сделать не так просто. Для этого нужно, во-первых, собрать очень большую коллекцию, это часто невозможно, потому что разметить миллион картинок — это очень трудоемкое занятие. Другой вариант — взять предобученную модель, из того же зоопарка моделей, например, взять VGG и дообучить ее на наших данных. Что значит дообучить? Опять же, тут есть несколько вариантов. Под дообучением можно понимать следующее: мы берем один из последних полносвязных слоев, выбрасываем самый последний слой, который отвечает за классы на ImageNet, заменяем его слоем с тем количеством классов, которые есть у нас, и дообучаем только превращение последнего полносвязного слоя в слой с выходом, который отвечает на вопрос, к какому классу принадлежит картинка. Плюс такого подхода в том, что это сделать очень просто, здесь достаточно небольшого числа картинок, чтобы произвести такое обучение, никакие большие мощности для этого не нужны, это можно делать на средненьком ноутбуке. И наконец, несмотря на то, что это достаточно простая процедура, мы обучаем только последний слой, это работает очень хорошо во многих случаях. Пример того, как дообучить последний слой с помощью библиотеки tensorflow, можно посмотреть по этой ссылке. Другой вариант: можно взять Уже готовую модель, обученную на коллекции ImageNet, проинициализировать нашу модель этой модели, опять же заменить последний слой и дообучать уже не только последний переход от полносвязного слоя к ответу, но и всю сеть целиком. Это более дорогостоящая операция, нужно больше вычислительных мощностей, но так как сеть уже предобучена на большой базе, это все равно намного быстрее и гораздо проще делается, чем обучать сеть с нуля. Выбор между этими вариантами зависит от задачи, от размера базы, которая у вас есть, и от желания получить то или иное качество. Но повторюсь, дообучение последнего слоя очень часто дает хорошие результаты, несмотря на то, что вычислений времени на эту операцию нужно гораздо меньше, чем на дообучение сети с нуля. Другой пример практической задачи, который использует предобученные нейронные сети, это поиск изображений. Мы можем взять VGG, или в данном случае мы поговорим про самую первую архитектуру AlexNet и будем считать, что один из последних слоев описывает изображение. Какие слои мы можем взять? Мы можем взять пятый сверточный слой, шестой полносвязный или седьмой полносвязный. И следующий вопрос, когда мы ищем изображение, картинки описываются вектором признаков одного из этих слоев. Теперь вопрос: как нам картинки сравнить, чтобы определить, похожа она или нет? Самый простейший вариант: просто сравнивать их по евклидовому расстоянию. Давайте посмотрим на пример. Здесь я представил несколько результатов работы поиска похожих. Самая левая картинка — это картинка-запрос. Справа идут, соответственно, ответы. Здесь представлены примеры того, какие результаты выдаются, если брать в качестве вектора, описывающего картинку, пятый, шестой или седьмой слой. Видно, что приемлемые результаты получаются в данном случае, только если брать седьмой слой. На втором и третьем месте мы видим результаты фотографии той же двери. Это достаточно сложный пример, поэтому не очень хорошо работает. Но тем не менее мы видим вот такие результаты. Соответственно, по ссылке можно найти подробное описание, из каких соображений стоит выбирать, какой слой использовать для поиска изображений, как сравнивать полученные вектора признаков между собой, и увидеть, какие комбинации работают лучше в тех или иных ситуациях. Хочется отметить следующий момент: мы использовали выходы последних слоев нейронной сети для дообучения классификатора для разнообразных задач, мы использовали эти же выходы для решения задач поиска изображений. Более того, мы обучали сеть изначально на коллекции ImageNet, а применяли на совершенно других коллекциях, в том числе коллекциях другой природы. Как показывает практика, эти методы хорошо работают, даже если применять данные подходы к картинкам совершенно другим, например, к картинкам из компьютерной графики. То есть, в ImageNet компьютерной графики нет или ее там очень мало, но тем не менее картинки ищутся достаточно хорошо при использовании этой сети. Что это всё означает? Эти факты говорят о том, что нейронные сети, предобученные на большой базе разнообразных изображений, достаточно хорошо описывают эти картинки, то есть, вот, предполученные признаки очень хорошо эти картинки описывают, и это достаточно фундаментальный и полезный результат. Это означает, что это представление можно использовать в совершенно разнообразных задачах. А еще это означает, что нейронные сети хорошо работают. В следующем видео мы посмотрим на другие задачи компьютерного зрения, и как нейронные сети помогают их решать.

[БЕЗ_ЗВУКА] В этом видео мы поговорим про то, как с помощью компьютерного зрения распознавать и отличать лица. Можно задачу распознавания лиц разделить на две подзадачи. Задача верификации лиц, когда нам показывают две фотографии и нужно ответить на вопрос, один и тот же человек на этих фотографиях, или разные. И задача, собственно, распознавания людей из базы, когда у нас есть некая база лиц, например, база злоумышленников, и по фотографии человека нам нужно понять, есть ли он в этой базе, и если есть, то кто. Мы сначала сосредоточимся на задаче верификации. На самом деле, задача распознавания из базы — она вытекает из задачи верификации. Если мы научимся хорошо решать первую, то вторую решим тоже. В любом случае, для того чтобы хорошо решить обе этих задачи, нам нужно очень хорошее представление лиц в цифровом виде. Собственно то, о чем мы говорили на предыдущих видео, что нейронные сети позволяют получить хорошее представление изображений. Теперь нам нужно эти знания применить для лиц. Как мы уже говорили, для решения любой практической задачи компьютерного зрения и, вообще говоря, машинного обучения, нам нужна размеченная база. В мире существует несколько публичных размеченных баз лиц. Чаще всего алгоритмы сравнивают между собой на базе изображений из Интернета, Labeled faces in the wild. Данная база содержит 13 000 изображений, фотографии сделаны не в тепличных условиях, это просто фотографии из Интернета. Есть другая база, она содержит гораздо больше фотографий, она содержит пять миллионов картинок и 672 000 разных людей. Вторая база несравнимо больше и гораздо ближе к реальности, но она появилась недавно, поэтому не все алгоритмы успели предоставить свои результаты на ней. Поэтому по-прежнему удобно сравниваться по первой базе, а вторую мы отложим на потом. Так вот, что вообще представляет из себя задача верификации? Насколько сложно вообще ее решить? Вот мы видим две пары изображений, на одной из них разные люди, на другой один и тот же человек. На самом деле, не все люди могут сразу ответить правильно на вопрос, где один и тот же человек, а где разные. Картинки представлены в таком плохом качестве не потому, что мы пытаемся вас сейчас обмануть и усложнить задачу. Они действительно в таком качестве, потому что когда мы берем фотографии людей из Интернета и вырезаем из них лица, они получаются достаточно маленькими. И уже видны артефакты сжатия и ресайза. Это вот ровно те картинки, которые видит нейросеть перед тем, как отвечает на вопрос, что это за человек. Почти все алгоритмы классификации и распознавания лиц можно разделить на несколько фаз. Сначала нам нужно лицо найти и вырезать, потом развернуть его таким образом, чтобы оно было примерно в одном и том же положении на различных фотографиях, чтобы было проще использовать алгоритмы классификации. Потом мы генерируем из полученной картинки цифровое представление лица, и осталось только эти цифровые представления как-то сравнить между собой. Давайте подробнее поговорим про каждый из этих этапов. Детекция лица. Мы уже упоминали, что есть разнообразные методы детекции, один из самых первых успешных методов используем каскады Хаара, это сейчас не самый лучший и не самый качественный метод, существует много других. В том числе для этого можно использовать нейронные сети. Но достаточно хорошим компромиссом качества и скорости, и удобства использования является метод, когда извлекаются из картинки так называемые дескрипторы hog, и с помощью алгоритма машинного обучения svm отвечает на вопрос, является ли данная картинка лицом или нет. Существуют методы выделения особенностей лица, то есть когда мы берем лицо и находим особые точки, такие как кончик носа, уголки рта, края глаз и так далее. Имея такие особые точки, мы можем тем или иным способом развернуть лицо. Выровнять лицо можно несколькими способами. Можно развернуть картинку в плоскости и сделать некие двухмерные преобразования. А можно попытаться построить трехмерную форму лица и сделать так, как будто человек смотрит напрямую в камеру. До появления нейронных сетей качество выравнивания было одним из ключевых параметров алгоритма распознавания лиц. Раньше побеждали именно те методы, которые делали качественные 3D-представления, разворачивали лицо, умели дорисовывать вторую половинку лица, если на картинке изображен только профиль, но нейронные сети достаточно качественно умеют работать на не до конца выровненных лицах. Поэтому требование к этому этапу работы всего алгоритма, оно снизилось. Более того, методы, которые используют более простые, но при этом опасные методы, такие как простые повороты в плоскости, они выигрывают. Это происходит в том числе из-за того, что сложные методы выравнивания не только позволяют повернуть лицо, но и вносят какой-то шум. То есть если мы немного неправильно найдем особые точки на лице, то метод выравнивания, чем он более сложный, тем больше вероятность того, что будет внесена ошибка. Если мы используем для выравнивания простой поворот и изменение масштаба, тогда нам для выполнения данной операции достаточно двух точек. Эти две точки можно взять, например, из центра глаз. Когда мы нашли и выровняли лицо, после этого мы можем работать непосредственно с картинками и использовать уже неоднократно использованную схему классификации с использованием глубоких нейронных сетей. На данном слайде мы видим похожую на AlexNet архитектуру, которая используется для классификации. В данном случае классы — это просто люди. После того как мы нашли и выровняли лицо, можем решать задачу распознавания лиц как обычную задачу классификации изображения. В данном случае классы — это просто разные люди. Именно так и поступили авторы статьи. Они взяли архитектуру, похожую на архитектуру AlexNet, она состоит из нескольких сверточных и полносвязных слоев. Собрали базу разнообразных людей, состоящую из нескольких миллионов фотографий, и обучили такую сеть. После того как сеть была обучена, выходы последнего полносвязного слоя были взяты в качестве описания картинки и были использованы для решения задачи верификации уже на нашей базе Labeled Faces in the Wild. Вопрос: как можно сравнивать два цифровых представления? Опять же, до появления нейронных сетей это было важный компонентом всей цепочки этого метода. И были придуманы различные сложные способы, как сравнивать такие дескрипторы. В случае нейронных сетей достаточно хорошо работает простое Евклидово расстояние. То есть если Евклидово расстояние больше определенного порога, значит это люди разные. И вот те методы сравнения с использованием машинного обучения, которые были придуманы раньше, они либо вообще не дают никакого улучшения, либо дают очень небольшое улучшение, если представление создано с помощью нейронной сети. Это интересный факт, который означает, что нейронные сети позволяют его сильно упростить весь pipeline. В описанной в статье результатом работы стала точность распознавания 97,35 %. Это было первое улучшение качества на данной базе с помощью нейронных сетей. и оно уменьшило количество ошибок в несколько раз. До этой работы лучшие результаты были порядка 92%. Что было дальше? Например, авторы из Гонконга предложили использовать похожий pipeline и похожую нейронную сеть и добились качества 99,47%, но сделали они это с помощью использования аж 200 нейронных сетей. То есть 200 разных сетей применялись к лицу, результаты некоторым образом объединялись и усреднялись, и получили такое внушительное качество. Но нужно отметить, что 200 раз применять нейронную сеть, несмотря на то, что она достаточно маленькая — это несколько сложная процедура. То есть гораздо проще все-таки применять одну, хоть и большую, нейронную сеть. Еще один хороший результат был получен группой из Оксфорда, они показали, как одной нейронной сетью добиться хорошего результата. Данный результат был получен с помощью аккуратного выбора протокола обучения. И они собрали относительно небольшую базу, она в 2 раза меньше, чем база Фейсбука, состояла из 2 млн. картинок, и при этом они получили качество 98,95%. Более того, они это качество еще улучшили с помощью как раз обучения сравнения дескрипторов. И получили результат 99,15%. Давайте вспомним вообще про... как устроен весь pipeline распознавания, то есть многие методы детектируют лицо, выравнивают лицо и потом обучают нейронную сеть. Казалось бы, что мешает заставить нейронную сеть проделать все эти шаги внутри себя? Именно так и поступили сотрудники компании Google. Они взяли огромную базу, состоящую из 200 млн. изображений, и обучили на ней сеть без предварительной обработки картинок и без предварительного вырезания и выравнивания лиц. И получили качество 98,87%. Но несмотря на то, что база огромная, и, казалось бы, нейронная сеть должна все эти выравнивания выучить сама, тем не менее, даже на этой базе выравнивание очень сильно помогает, и в случае, если проделать то же самое обучение на такой большой базе с выравниванием, качество будет еще больше, и можно считать, что это качество практически стопроцентное. Давайте еще раз посмотрим на таблицу с результатами. Тут важно смотреть не только на качество, но и на размер базы, которая используется при обучении. Чем больше база, тем сложнее ее собрать. Например, результат, полученный с базой в 200 млн. изображений, конечно, поражает воображение, но повторить его достаточно сложно. А с другой стороны, результат группы из Оксфорда — тоже очень достойный, при этом использовалась относительно небольшая база. Соответственно, можно считать, что на базе картинок Labeled Faces in the Wild, состоящей из 13000 изображений задача распознавания решена достаточно хорошо, с почти стопроцентным качеством. Другой пример использования полученного представления при обучении таких классификаторов — это поиск похожих лиц. Мы можем точно так же, как в задаче поиска похожих изображений, взять выходы последних слоев нейронной сети и использовать их для поиска. В случае с... Если в базе есть точно такой же человек, то мы можем найти именно его. В случае, если в базе этого человека нет, мы просто будем находить похожих в том или ином смысле людей. Сейчас существует несколько сервисов, работающих по этому принципу, и результатами их работы можно воспользоваться и посмотреть. Чтобы лучше понять, как устроены представления лиц с помощью нейронных сетей, можно визуализировать облако векторов на плоскости. Сделать это можно, например, с помощью алгоритма tsne. Он работает по следующему принципу: он располагает на двумерной плоскости вектора таким образом, чтобы на плоскости они были тем ближе, чем ближе они в многомерном пространстве исходном. Мы видим несколько сгущений на данной плоскости. Поэтому мы можем приблизить эти сгущения и посмотреть, как они выглядят вблизи. Соответственно, одно из сгущений — это люди в кепках, другое большое сгущение — это Джордж Буш, и еще один пример — это люди в темных очках. Интересно, что данные сгущения, они никак не помогают классифицировать людей. То есть темные очки — это скорее некий факт, который может присутствовать у разных персон. Тем не менее, нейронная сеть при обучении на него обратила внимание и считает, что люди в солнечных очках, они должны располагаться в этом представлении ближе. Это означает, что признаки, использованные для данной визуализации, неидеальны, и, возможно, произошло переобучение, и есть пространство для улучшения качества. В данном видео мы поговорили про задачу распознавания лиц. Как мы уже увидели, произошел большой прогресс, за последние несколько лет качество на одной из баз улучшилось многократно. Более того, мы видим, что на базе Labeled Faces in the Wild получены результаты почти со стопроцентной точностью. Это означает, что данная коллекция исчерпала себя, и алгоритмы теперь уже нужно сравнивать на другой коллекции. Ровно для этого будет использована коллекция MegaFace, про которую я упоминал в начале, и собственно, challenge на ближайшие годы для алгоритмов компьютерного зрения — добиться хорошего качества там. А если хорошее качество будет получено уже на этой большой и разнообразной базе, то это будет означать, что распознавание лиц будет очень хорошо работать в огромных коллекциях: таких, как социальные сети, изображения с уличных камер или камер в метро.

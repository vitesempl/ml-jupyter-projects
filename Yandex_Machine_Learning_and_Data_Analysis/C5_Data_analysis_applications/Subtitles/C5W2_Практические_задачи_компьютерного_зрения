[БЕЗ_ЗВУКА] В этом видео мы разберем еще несколько практических задач, и начнем с задачи детекции объектов. До этого мы разговаривали с вами про задачу классификации, когда нужно про картинку целиком сказать, к какому классу она принадлежит. В случае детекции объектов нам нужно не только сказать, к какому классу принадлежит картинка, но и найти, где на картинке данный объект расположен. Как это можно делать? Один из первых, традиционных подходов — скользящее окно. Мы уже обсуждали скользящее окно в контексте фильтрации изображений, здесь примерно то же самое. У нас есть некое окно, которое перемещается по картинке, к каждому такому окну мы можем применить классификационную нейронную сеть, которая предобучена на тех классах, объекты которых нам нужно детектировать, и, таким образом, если классификационная сеть говорит, что в данном окошке объект есть, то он и помечается соответствующей рамкой и классом. Но в этом подходе есть определенный недостаток: чтобы пройти скользящим окном, да еще и на разных масштабах, по изображению, нужно многократно применить классификационную нейронную сеть. А это означает, что данный процесс будет очень медленным. Поэтому были придуманы разнообразные эвристики, как данный процесс ускорить. Один из очевидных способов: давайте применять не тяжелую классификационную сеть, а некий более легкий классификатор, который будет отбрасывать те окна, в которых явно нету объектов, которые нам интересны. Такой подход предложен в статье, которая называется R-CNN. Использовался метод предложения гипотез про окна объектов, который называется Selective Search, и рассматривались альтернативы, а после этого на предложенных окнах запускалась классификационная сеть. Метод достаточно простой и до сих пор используется как некий baseline задачи детекции объектов. Но, несмотря на то, что метод достаточно хорошо себя показал, есть пространство для его улучшения. Собственно, та же группа авторов предложила метод под названием Faster R-CNN, и заключался он в следующем: а давайте для предложения гипотез про окна использовать не какой-то внешний классификатор, а использовать нейронную сеть не только для классификации, но и для гипотез про есть ли в данном окне объект. Вторая инновация, которая была здесь сделана: гипотеза говорилась не только про класс объекта в окне, но и нейронная сеть уточняла расположение объекта внутри окна, то есть выдавался не только класс, но и рамки прямоугольника, который ограничивает данный объект. Идея объединить предсказание объекта, его положение и класс в одной сети оказалась достаточно успешной, и данный метод сейчас является лучшим по предсказанию объектов. Аналогичную идею использовать единую нейронную сеть для предсказания класса объекта и ограничивающего прямоугольника высказал Джозеф Редмон и группа соавторов, и они назвали свой метод YOLO. В чем преимущество YOLO? Он еще более простой, нежели Faster R-CNN, картинка делится на несколько ячеек, в каждой ячейке классификатор применяется отдельно, и после этого строится предсказание, где находится объект и где находится ограничивающий прямоугольник. Работает это очень быстро, и в данной таблице мы можем увидеть результаты сравнения. Например, Faster R-CNN показывает лучший результат по качеству, но при этом скорость работы порядка 7 кадров в секунду. В то же время метод YOLO работает с качеством на 10 % хуже, зато скорость работы достигается порядка 150 кадров в секунду. Соответственно, этот метод можно использовать в реальном времени с большим запасом для детектирования объектов. Соответственно, мы видим, что существуют разные подходы для детекции объектов, и в их выборе можно использовать разные требования как к качеству, так и к скорости работы, и в ближайшее время стоит ожидать многочисленных применений таких детекторов в реальных приложениях. До этого мы обсуждали с вами нейронные сети, которые по картинке выдают некие параметры: либо класс объекта, либо координаты ограничивающего прямоугольника. Существует другой класс нейронных сетей, так называемые генеративные нейронные сети, которые из векторов признаков или неких параметров умеют генерировать изображения. Интересный пример был рассказан в работе, которая представлена на слайде. На вход нейронной сети подавалось положение объекта, его класс и с какой стороны мы на него смотрим, а нейронная сеть должна была сгенерировать данный объект. В частности, в качестве таких объектов использовались стулья, и выглядело это следующим образом. На данной картинке мы видим в самом левом и в самом правом столбце стулья из коллекции, а промежуточные стулья, они сгенерированы с помощью нейронной сети, их в коллекции не было. Мы видим, что все промежуточные результаты, они в том или ином виде похожи на стул. Если бы мы делали простое усреднение, то картинки были бы размазанные, и ничего общего со стульями не было. Это означает, что нейронная сеть в процессе обучения осознала форму стула и использует данные знания для генерации картинок. Давайте посмотрим несколько примеров, как такие нейронные сети можно использовать в различных приложениях. Задача семантической сегментации. Изначально мы рассматривали задачу классификации, когда мы говорили что-то про картинку целиком. В сегодняшнем видео мы обсудили задачу детекции объектов, когда мы находим на картинке конкретные объекты и говорим про них, а можно пойти дальше и про каждый пиксель на изображении сказать, к какому классу он принадлежит. В данной картинке класс закодирован цветом, это фотография с улицы какого-то европейского города. Мы видим такие объекты дорожной инфраструктуры, как, собственно, дорога, тротуар, велосипедисты, трамвай, люди, дорожные знаки. Собственно, задача — найти все такие классы на изображении. Есть несколько методов, которые решают данную задачу. Один из таких методов — полностью сверточные сети. Что это значит? Мы, когда говорили про нейронную сеть, она чаще всего состоит из нескольких сверточных слоев, а потом идут несколько полносвязных слоев. На самом деле, нам почти ничего не мешает заменить последние полносвязные слои на сверточные слои. В чем прелесть сверточных слоев? В том, что у нас не фиксирован размер входной картинки, а выходная картинка будет пропорциональна входной. Итак, когда мы используем нейронную сеть, которая состоит только из сверточных слоев, то выход данной сети будет просто пропорционален входу. Например, если мы используем архитектуру, похожую на AlexNet, и заменяем последние полносвязные слои на сверточные, то выход будет в 32 раза меньше, чем вход. Если мы возьмем достаточно большую картинку, выход будет содержать достаточно много информации, после этого нам можно будет использовать простые алгоритмы повышения размерности и получить изображение, которое, разрешение которого равно разрешению входа. После того, как у нас нейронная сеть такой архитектуры появилась, нам ничего не мешает в явном виде решать задачу семантической сегментации, то есть на входе — картинка размера фиксированного, на выходе картинка такого же размера, но вместо исходных пикселей — номера классов, к которым принадлежит каждый пиксель. Мы знаем обучающую выборку и в явном виде такую нейронную сеть можем обучать. Но в чем проблема такого подхода? Выход нейронной сети намного меньше, чем необходимое разрешение, и увеличение размерности в 32 раза, на самом деле, достаточно сильно испортит качество. Поэтому авторы подхода предлагают следующее решение: давайте использовать выходы не только последнего слоя, но и промежуточные выходы. Они меньше чем вход не в 32 раза, а, соответственно, в 16 и 8 раз. Агрегируя все эти выходы в единый ответ, мы можем получить достаточно хорошее качество, и данная нейронная сеть, она в некотором смысле эмулирует применение сети на разных масштабах. Соответственно, чем раньше мы забираем выход, тем на большем масштабе мы его применяем ко входу. Другой пример метода, который решает задачу семантической сегментации — это так называемый Segnet. Что сделали авторы? Они взяли обычную архитектуру, которая уменьшает размерность, развернули ее. Но главный вопрос: как делать увеличение размерности? Когда мы размерность понижаем, мы используем max-pooling, то есть мы выбираем из окрестности 2 x 2 максимальное значение и используем только его. Соответственно, каждый max-pooling уменьшает нам размерность в 2 раза, несколько max-pooling'ов уменьшают размерность соответственно. Как повышать размерность? Есть несколько методов, один из них — просто запоминать индекс максимума, который мы брали при max-pooling'е, пробрасывать эти индексы до обратных max-pooling'ов и выбирать именно значения с таким же индексом. Соответственно, вся эта конструкция работает достаточно хорошо и показывает, на самом деле, результаты даже более качественные, чем полностью сверточная нейронная сеть. Соответственно, существуют разнообразные эвристики, как улучшать данный подход, но в целом кажется, что нейронные сети такой природы достаточны интересны, и с помощью них можно решать не только семантическую сегментацию, но и множество других задач. Мы посмотрели несколько примеров использования нейронных сетей для детекции объектов и семантической сегментации, а в следующем видео мы обсудим задачи стилизации.

[БЕЗ_ЗВУКА] Давайте рассмотрим задачу стилизации изображения. Задача заключается в том, чтобы перенести стиль с картины художника на фотографию. Группа из университета Тюбингена предложила алгоритм генерации таких картинок. В нем ключевую роль занимает предобученная нейронная сеть. Опять они использовали VGG, как и во многих других задачах компьютерного зрения, и здесь предобученная нейронная сеть фактически выступает в качестве оценки того, насколько сгенерированная картинка похожа на картину художника по стилю и на фотографию по содержанию. И саму картинку генерировали с помощью алгоритма оптимизации. То есть у нас в данном случае веса нейронной сети зафиксированные, а меняется именно эта картинка. Получались достаточно интересные результаты, но проблема заключалась, как обычно, в производительности. Для того чтобы сгенерировать одно изображение, уходили десятки секунд, а то и минуты, в зависимости от разрешения входного изображения. Вот пример данной стилизации: некоторые люди считают, что это Ван Гог, на самом деле это не Ван Гог, а фотография рыжего мужчины, стилизованная с помощью картины «Автопортрет Ван Гога». Группа из Калтеха предложила, как ускорить данный алгоритм. Тут для генерации изображения используются полносвёрточные нейронные сети, те самые, что мы использовали для семантической сегментации, и про которую рассказывали в прошлом видео. Для оценки, насколько сгенерированная картинка похожа по стилю на картину художника и по содержанию на фотографию автора, используется опять предобученная VGG. Данный метод намного быстрее, потому что в процессе обучения создается такая полносвёрточная нейронная сеть, которая для генерации картинки применяется один раз, в отличие от метода Гатис, когда нужно было использовать оптимизацию для создания картинки. Так вот, если использовать для оценки только стиль — насколько стиль похож на картину, то данный метод позволяет генерировать текстуры. Вот несколько примеров того, что получается. Если же к оценке ошибки стиля добавить оценку ошибки содержания, то можно опять создавать стилизованные изображения. Вот несколько примеров, иногда это отличается от того, что предложили Гатис, но в любом случае оно работает на порядки быстрее. В данном видео мы рассмотрели нейронные сети, которые применяются не только для того чтобы понимать, что изображено на картинке, но и для того, чтобы создавать новые изображения. На мой взгляд, это достаточно интересное применение, которое воплотилось в различных практических приложениях.

[БЕЗ СЛОВ] Задача распознавания китов была предложена в качестве соревнования на сайте www.kaggle.com и заключалась в том, чтобы сделать распознавание лиц для китов. Зачем это нужно? В мире осталось очень мало гренландских китов, их меньше чем 500 особей, за ними внимательно следят и отслеживают состояние их здоровья и пути миграции. Следят за ними с помощью фотографий, сделанных с самолетов, и специалисты умеют отличать гренландских китов друг от друга по характерному рисунку из белых наростов на голове. Но процедура «отличания» и узнавания китов достаточно трудоемкая. Это умеют делать только несколько специалистов, и это отнимает очень много времени. Поэтому создатели конкурса предложили участникам разработать автоматическую процедуру с помощью тех или иных методов классификации. Как мы видим, задача очень сильно похожа на задачу распознавания лиц. Поэтому для ее решения можно использовать тот же самый pipeline по детекции лица, в данном случае головы кита, выравниванию изображения и применению, собственно, нейронных сетей. Примерно такой подход предложили победители соревнования. На данном слайде мы можем увидеть, как устроен процесс предобработки изображения. То есть сначала находится голова кита, это делается с помощью нейронной сети, которая натренирована отличать голову от фона. После этого другая нейронная сеть находит начало и конец головы, и после этого, зная эти две точки, мы можем развернуть изображение таким образом, чтобы в кадр попадала голова, направленная в одну сторону. Вот несколько примеров того, как выглядят предобработанные фотографии с головами китов. Видно, что по таким изображениям гораздо проще понимать и сравнивать китов друг с другом. Собственно, после этого был использован стандартный алгоритм классификации с помощью нейронных сетей. Вот архитектура, которую использовали авторы. Как мы видим, она очень похожа на VGG, и авторы попробовали несколько дополнительных трюков, которые позволили им улучшить результат. Один из таких трюков — увеличение скорости обучения. Обычно, когда обучают нейронные сети, используют метод уменьшения скорости обучения, когда график ошибки выходит на плато, скорость обучения уменьшают. Иногда это приводит к тому, что обучение продолжается. Авторы поступили по-другому. Видимо, уменьшение скорости обучения пользы не приносило, они увеличили скорость обучения. Как видим из графиков, иногда это помогало продолжить обучение. Очень часто соревнования на kaggle сводятся к тому, чтобы попробовать множество разных методов, и убедиться в том, работают они или нет. И интересно, что у авторов победного решения не заработало. Они пробовали вырезать голову кита без обучения, они пробовали другие методы обучения, но в итоге им пришлось часть голов разметить вручную и отметить точки начала и конца головы. То есть изначально этих данных в обучении не было. Еще у авторов не заработал метод под названием spatial transformer networks — это нейронная сеть, которая сама пытается обучить преобразование, чтобы качество классификации улучшилось. Видимо они хотели избежать вот этого препроцессинга в виде вырезания головы, но это не сработало. Другой пример — это использование очень глубоких сетей со скитконнекшинами. Как мы помним, данный метод очень хорошо работает в задаче классификации MichNet, у авторов почему-то пользы не принесло. И, наконец, авторы пытались попробовать триплеты. Напомню, что это метод, когда на вход нейросети подается три картинки, две из них одного класса, третья — другого класса, и задача нейронной сети сделать так, чтобы две картинки одного класса были ближе к друг другу, чем картинка другого класса. Эти методы достаточно хорошо работают для задачи распознавания лиц, поэтому интересно, что они не заработали в задаче распознавания голов китов. Но это часто бывает на практике, что методы, которые работают для одних задач, не работают для других. Поэтому и интересно разобрать подобного рода подходы для решения практических задач. И это означает, что ничего, кроме того, чтобы попробовать много разного нам не остается для того, чтобы получить хороший результат в реальности.

[БЕЗ_ЗВУКА] В задачах компьютерного зрения качество обучающей выборки зачастую важнее качества самих алгоритмов машинного обучения. Данное утверждение верно не только для алгоритмов компьютерного зрения, но и для задач анализа данных в целом. В данном видео мы поговорим о том, как быстро и просто собрать коллекцию изображений. В интернете огромное количество различных изображений. Многие из них снабжены текстовым описанием. Это означает, что мы можем воспользоваться текстовым поиском по изображениям для того, чтобы найти картинки нужного нам класса. Если мы введем в поиске по изображениям «машина», то мы получим выдачу, состоящую из машин. Приведу несколько примеров. Например, группа из Оксфорда для того, чтобы успешно обучить свой классификатор распознавания лиц, собрала собственную базу лиц, состоящую из знаменитостей. Они взяли большой список знаменитостей, задали его в поиск по картинкам и получили на каждый текстовый запрос большое количество картинок. Но далеко не все ответы поисковой системы хорошие. Но вместо того, чтобы размечать каждую картинку в отдельности, можно размечать запросы. То есть например, если существуют однофамильцы, и по выдаче по имени и фамилии знаменитости выдаются они вперемешку, то можно просто выбросить этот запрос. Аналогично часто по известным знаменитостям хороших картинок много, по малоизвестным знаменитостям вначале идут хорошие фотографии, а потом начинаются ошибки. Такие запросы тоже достаточно легко отфильтровать. Можно взять только первые несколько картинок. Мы в выборку эту знаменитость добавили, все остальные картинки удалить. Соответственно, удалить хвост запроса — гораздо более простая операция, чем смотреть на все картинки в отдельности. Таким образом данной группе удалось собрать базу, состоящую из двух миллионов лиц, что достаточно много. Аналогично поступили исследователи при создании базы достопримечательностей. Идея заключалась в том, что давайте дообучим нейронную сеть на достопримечательностях и посмотрим, насколько это улучшает качество поиска изображений по сравнению с использованием простой предобученной сети. Эта база собиралась похожим методом. Был взят большой список достопримечательностей, и выброшены запросы, которые содержали мусор. Например, существуют рестораны, которые называются в честь достопримечательностей. И иногда поисковая система выдает картинки интерьеров этих ресторанов вместо самих достопримечательностей. Соответственно, такие запросы можно выбросить и тоже достаточно быстро и просто собрать большую базу. Другой способ сбора и разметки изображений — это системы краудсорсинга. Существуют разные системы, которые позволяют простые задания раздавать людям. Например, Amazon Mechanical Turk и Яндекс.Толока. Тоже очень дешево можно разметить огромные массивы изображений, это очень удобно. Соответственно, можно, конечно же, использовать комбинацию: что часть базы мы получим с помощью метода запросов в поиск картинок, часть базы мы можем получить с помощью краудсорсинга, и таким образом можно, на самом деле, сформировать некую процедуру итеративного построения базы. Для первых экспериментов нам нужна небольшая, пусть шумная, база. Мы обучаем классификатор, классификатор выдает определенные результаты на новых картинках, которых у нас нет в базе, и их можно загрузить как раз-таки в системы краудсорсинга. Краудсорсеры размечают нам новые данные, находят ошибки, и мы эти размеченные данные доливаем в нашу исходную размеченную базу. Процедуру можно повторять многократно и таким образом наращивать базу. В контексте взаимодействия человека и алгоритмов стоит упомянуть про следующий класс задач, когда человек приходит на помощь алгоритму компьютерного зрения, чтобы исправить его ошибки. Например, алгоритм выдает определенную степень уверенности в задаче модерации. Там, где алгоритм уверен, это используется в системе, там, где алгоритм не уверен, такие данные поступают на ручную модерацию. Таким образом здесь компьютерное зрение используется для того, чтобы снять нагрузку с модераторов, и небольшое число модераторов размечало огромное количество изображений. Другой пример использования человеческого труда для улучшения качества системы — это, например, мобильное приложение Camfind. Оно позволяет сфотографировать любой предмет и получить ответ, что это такое. И работает оно в реальном времени, и задержки буквально десятки секунд. Данное приложение показывает достаточно высокий уровень качества ответа на вопрос, что изображено на картинке, и для человека, который не знает, что на самом деле там не только алгоритмы, но и люди, это выглядит, как некое чудо. На самом деле создатели приложения долго работали над тем, чтобы люди могли быстро и качественно отвечать и описывать изображения, и качественно проработали интерфейс так, чтобы человек мог быстро это делать. И впечатления действительно очень хорошие. И это позволило авторам приложения собрать большую базу и тоже ее использовать в своих нуждах. Соответственно, такие гибридные системы помогают улучшить качество исходного алгоритма, помогают доразмечать базу и еще раз повышать качество автоматической части. И очень часто они действительно используются на практике именно в такой постановке. И наконец еще один метод пополнения базы — это синтетические данные. Современная компьютерная графика позволяет генерировать реалистичные миры. Очень часто графические сцены выглядят более реалистично, чем снятые в реальности. Соответственно, возникает очевидная мысль: а давайте такие сцены использовать для того, чтобы обучать те или иные классификаторы. И так, конечно же, делают. Например, есть база под названием Synthia. Был взят искусственный город, и с помощью 3D движка Unity сгенерированы отрендеренные картинки и семантическая разметка. Эта база позволила существенно увеличить существующие базы для семантической сегментации, и удалось заметно повысить качество обучения. Но использовать синтетические данные надо достаточно аккуратно, потому что может возникнуть ситуация, что синтетические данные отличаются от реальных, и нейронная сеть хватается именно за эти отличия. И сгенерировать достаточно качественно данные, чтобы таких отличий не было, очень сложно. И были случаи, когда синтетические данные ну никак не помогают улучшить качество основного алгоритма. И затраты на создание качественной системы синтетической генерации, они больше, чем на сбор реальных данных с помощью того или иного инструмента. Синтетика хороша, но только там, где реальные данные очень сложно разметить. В этом видео мы обсудили несколько методов сбора больших баз для анализа изображений. Хочется отметить, что наличие таких баз очень часто являлось триггером для запуска исследований по той или иной области. Например, коллекция ImageNet. Благодаря ImageNet фактически началось современное развитие нейронных сетей. Можно привести примеры про задачи распознавания лиц, детекции объектов и семантической сегментации. Во всех этих задачах начался прогресс, когда появились качественные коллекции. Такие базы очень часто являются конкурентным преимуществом. Корпорации делятся своими методами решения задач машинного обучения, выкладывают библиотеки в open source. А вот с данными гораздо сложнее, то есть получить данные, которые есть у той или иной компании, почти невозможно. И наконец хочется отметить тот факт, что увеличение размера и качества базы — это часто самый простой способ улучшить качество решения практической задачи. Вместо того, чтобы усложнять алгоритмы, использовать ансамбли, усреднять результаты различных обучений, гораздо проще взять и увеличить выборку. И я советую не забывать этот факт и всегда иметь его в виду, когда решаем практические задачи.
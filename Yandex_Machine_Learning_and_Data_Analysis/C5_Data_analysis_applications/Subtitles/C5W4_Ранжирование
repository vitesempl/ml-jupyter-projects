Мы начинаем урок, посвященный задаче ранжирования. Это задача, которая имеет много общего с известными нам задачами регрессии или классификации, но при этом имеет ряд интересных особенностей, о которых мы и будем говорить в этом уроке. Итак, в чем состоит задача ранжирования? У нас есть выборка, состоящая из l элементов: x1, ..., xl — все это какие-то объекты, имеющие признаковые описания. Здесь никаких отличий нет. Отличие — в целевой переменной, в ответах. Если раньше у нас был свой ответ для каждого объекта в задачах обучения с учителем, то теперь ответы — это некоторые пары из i-тых и j-тых объектов, для которых известно, что i-тый объект меньше, чем j-тый объект. Набор таких пар и является целевой переменной, является ответом в данной задаче. Что нам нужно сделать? Нам нужно построить некоторую модель a, которая принимает на вход объекты, но при этом требования к ней другие. Если раньше модель должна была предсказать конкретный ответ для конкретного объекта, то теперь модель должна быть устроена так, что если i-тый объект меньше j-того, то и значение модели на i-том объекте будет меньше, чем значение модели на j-том объекте. То есть выходы ее должны быть такими, что по ним легко восстановить порядок. Нам не важно, какие именно по величине эти ответы, главное, чтобы они были правильно расположены относительно друг друга. В этом и заключается главное отличие задачи ранжирования от всего остального. Где это нужно? Самый главный пример применения модели ранжирования — это, конечно, ранжирование поисковой выдачи, например в Яндексе. Нам даются пары запрос-документ, где запрос — это некоторые ключевые слова, которые ввел пользователь в поисковую строчку, документы — это все документы, которые есть в поисковом индексе или отобранные некоторым способом. Наша задача — научиться восстанавливать порядок на этих парах, причем порядок задан только для пар, у которых один и тот же запрос. То есть нам нужно уметь ранжировать документы для одного запроса. Порядок задается асессорами — это специальные люди, которым на вход даются такие пары, и их просят оценить релевантность данного документа данному запросу, то есть то, насколько хорошо данный документ отвечает на данный запрос. Дальше на основе этих оценок, которые могут быть как числовыми — релевантность можно оценивать в числах, — так и попарными, то есть асессор может непосредственно отсортировать документы, которые ему предложены на данный запрос. Нам требуется данный порядок уметь восстанавливать, уметь восстанавливать порядок документов для конкретного запроса. Еще один пример применения ранжирования — это задача рекомендаций, в которой нам даются пары пользователь и товар, и нужно уметь ранжировать товары для данного пользователя так, чтобы они максимизировали некоторую метрику. Опять же порядок задается только для одного пользователя на основе того, например, какие предпочтения он имеет, какие товары он покупал, а какие нет, или какие оценки он поставил тем или иным товарам. Эта задача тоже часто применяется на практике. У задачи ранжирования есть некоторое количество особенностей. Во-первых, объекты не являются независимыми — целевая переменная, ответы зависят от пар объектов, и это необходимо учитывать при решении. В этой задачи гораздо более сложные метрики качества, чем в ранжировании или классификации. Обычно они даже оказываются дискретными, поскольку им важны не конкретные значения модели, а порядок, который данная модель задает. И еще одна проблема, о которой мы не будем говорить сейчас, но которая тоже важна — это то, что в данной задаче важно правильно сформировать выборку. Например, сходу непонятно, что именно отдавать на разметку асессорам, какие именно пары из запросов и документов. Аналогичный вопрос — про рекомендации. Сразу непонятно, как формировать, как извлекать предпочтения пользователей из данных. В следующем видео мы поговорим о наиболее важном аспекте задачи ранжирования — о том, как измерять качество решения этой задачи.

[БЕЗ_ЗВУКА] В этом видео мы обсудим конкретные метрики качества ранжирования. Напомню, в задаче ранжирования нам даны объекты, и на некоторых парах этих объектов задан порядок. Известно, что один объект меньше другого. И требуется построить модель a, которая данный порядок будет хорошо восстанавливать. Введем несколько обозначений, и начнем мы с простой постановки, в которой ответы у нас дискретные, даже бинарные. То есть известно, что данный документ релевантен данному запросу или нерелевантен данному запросу. Везде далее для простых будем рассматривать именно на примере задачи ранжирования поисковой выдачи, когда есть запросы и документы, но все эти рассуждения хорошо обобщаются и на другие случаи задачи ранжирования. Итак, мы считаем, что есть запросы и документы, и для каждой пары запрос-документ или для некоторых пар известно значение y ответа — 0 или 1: релевантен данный документ запросу или нерелевантен. И пусть есть некоторая модель a, которая принимает на вход запрос q и документ d и оценивает релевантность данного документа данному запросу. Если модель выдала релевантности, мы можем по ним отранжировать документы, собственно, по релевантности данному запросу. Будем обозначать как dqi — i-й по порядку релевантности с точки зрения модели документ для запроса q. После того как мы ввели обозначения, можно задать нашу первую метрику ранжирования. Это будет точность на первых k документах, Precision@k. k является здесь параметром — то, для скольких первых документах мы хотим измерять качество. Например, если мы измеряем качество поисковой выдачи и на первой странице выдачи у нас десять документов, нам может быть интересно смотреть именно на точность среди первых десяти документов, на точность на уровне 10. Определяется она очень просто. Это доля релевантных документов среди первых k с точки зрения модели. Эта метрика полезная, мы хотим, чтобы было как можно больше релевантных документов среди первых k, но при этом у нее есть один недостаток — она никак не учитывает позиции релевантных документов среди первых k. Например, если k = 10 и среди этих десяти документов пять релевантных, то для данной метрики неважно, где они находятся — среди первых пяти документов или среди последних пяти документов. Но понятно, что мы хотим, чтобы они были как можно выше среди первых k. Это можно решить, если немного модифицировать данную метрику и определить среднюю точность, average precision. Данная метрика тоже измеряется на уровне k, и при этом формула ее выглядит вот так. Мы суммируем точности на первых i документах среди всех i от 1 до k для тех позиций, для тех i, на которых находятся релевантные документы. Это достигается путем умножения на y. После этого мы делим на количество релевантных документов среди первых k. Можно показать, что данная метрика уже зависит от порядка. Она будет достигать максимума, если все релевантные документы находятся в самом верху ранжированного списка. Если же они будут смещаться ниже, значение данной метрики будет ухудшаться. Порядок она уже учитывает, и это лучше, чем обычная точность на первых k документах. Заметим, что и точность, и средняя точность вычисляются для конкретного запроса q. Если у нас большая выборка, которая размечена для многих запросов, мы хотим усреднить после этого значение метрики «средняя точность» по всем запросам. Это делается по данной формуле. Средняя точность по всей выборке запросов вычисляется как усреднение средней точности по всем запросам q из Q множества запросов. Второй подход к измерению качества ранжирования — это метрика DCG. Она задается для более сложной ситуации, в которой оценки релевантности y могут быть вещественными, то есть если есть некоторая шкала релевантности. Документ не просто релевантен или нет, а есть разные градации. Все остальные обозначения остаются такими же. В этом случае метрика DCG вычисляется по вот такой формуле. В ней мы суммируем по всем позициям от первой до k-й, где k — это некоторый уровень, который тоже является параметром. Суммируем мы дроби. В числителе стоит 2 в степени истинная релевантность данного i-го документа по порядку минус 1. То есть, чем более релевантен документ на этой позиции, тем больше будет наш числитель. В знаменателе стоит логарифм позиции. Знаменатель, таким образом, штрафует за то, где именно находится документ. Если документ очень релевантен, но находится на слишком далекой от верха списка позиции, штраф будет большим. Если документ релевантен и находится вверху списка, штраф будет маленьким. Данная метрика, таким образом, учитывает и релевантность, и опять же позицию документа. Ее максимум будет достигаться, если все документы находятся в самом топе списка. Данную метрику принято нормировать, чтобы ее значения можно было интерпретировать и смотреть на них, и воспринимать их как значения от 0 до 1. Для этого нужно поделить значение DCG на данной модели и данной выборке на максимальное значение DCG на уровне k для данной выборки. Максимальное значение, как мы уже обсудили, достигается на идеальном ранжировании, если все релевантные документы находятся в самом верху списка. При этом они должны быть отсортированы еще и по значению релевантности, по y, который может быть разным, у нас там целая шкала. Итак, мы обсудили два подхода к измерению качества ранжирования — это точность и DCG. При этом точность в базовом варианте не учитывает порядок документов. Чтобы она учитывала, нужно перейти к средней точности. Метрика DCG позволяет учитывать шкалу релевантности, ситуацию, в которой могут быть разные степени релевантности документа запросу. И при этом она также учитывает позиции, на которых находятся релевантные документы. В следующем видео мы поговорим о том, с помощью каких моделей можно ранжировать документы и как с помощью моделей можно оптимизировать те метрики, которые мы обсуждали в этом видео.

[БЕЗ_ЗВУКА] В этом видео мы обсудим подходы к решению задачи ранжирования, а именно какие методы могут использоваться для ее решения. Всего выделяют три подхода: pointwise — поточечный, pairwise — попарный и listwise — списочный. Мы приведем по одному примеру метода из каждого подхода, чтобы вы понимали, чем они отличаются и какие у них особенности. Первый, самый простой подход — это поточечный. В нем мы забываем о том, что целевая переменная задается на парах объектов, и пытаемся непосредственно для каждого объекта предсказывать оценку его релевантности. Например, если мы говорим о задаче ранжирования поисковой выдачи, то асессор поставил каждому объекту, каждой паре «запрос — документ» некоторую оценку y. Ее мы и будем предсказывать. При этом мы никак не учитываем, что на самом деле нам важна не конкретная оценка, а порядок, который ей задается. Тем не менее, данный подход простой в том смысле, что его можно решать известными нам методами. Например, с помощью линейной регрессии и среднеквадратичной ошибки. Мы умеем решать эту задачу и получим некоторую модель, которая предсказывает релевантность. Дальше по выходам этой модели можно пытаться ранжировать объекты. Неизвестно, хорошо это или плохо, но при этом с каким-то качеством задачу мы решим. Следующий подход — попарный, или pairwise. В нем мы все же вспоминаем, как устроена целевая переменная, и записываем функционал, который зависит от пар объектов. Мы суммируем по всем парам объектов таких, что x(i) < x(j), и штрафуем те пары, на которых, как оказалось, что оценка релевантности для i-го объекта больше, чем оценка релевантности для j-го объекта. Если это выполнено, то мы неправильно отранжируем данную пару, поэтому штраф вполне логичен. К сожалению, функционал оказывается дискретным, здесь стоит индикатор, и поэтому непосредственно его минимизировать не получится. Но при этом можно действовать так же, как мы действовали с классификаторами: можно оценить сверху данный функционал, можно считать, что разница между выходами модели на j-м и i-м объекте — это отступ, и задать некоторую гладкую функцию от отступа L(M), и суммировать значения данной функции по всем парам, для которых мы знаем порядок. Например, если мы выберем такую же функцию L, как и в логистической регрессии log (1 + e(−M) ), то мы получим метод, который называется RankNet. После этого можно решать задачу с помощью, например, стохастического градиентного спуска. Так и устроены попарные подходы: мы записываем функционал, но при этом сводим его к решению простыми методами, сводим к гладкому функционалу. Если записать один шаг стохастического градиента для метода RankNet, мы получим вот такую формулу, в которой мы еще и считаем, что модель у нас линейная. Мы ранжируем с помощью линейной модели. Формула получается не очень сложная и зависит от одной пары x(i) и x(j), для которой мы знаем порядок. Возникает вопрос: а можно ли как-то модифицировать данный метод, а именно данную формулу шага, чтобы оптимизировался не наш исходный функционал, который гладко оценивает долю дефектных пар, а, например, он оптимизировал NDCG? Ответ положительный. Оказывается, что если мы домножим градиент исходного функционала на то, на сколько изменится NDCG, если мы поменяем местами i-й и j-й объект — здесь это обозначается как ΔNDCGij, то при выполнении градиентного спуска с помощью данных шагов мы уже будем оптимизировать NDCG. Это эмпирический факт, он не доказан. Но при этом оказывается, что действительно на практике NDCG улучшается при решении задачи данным методом. Есть и более сложные подходы к решению задачи оптимизации NDCG, но при этом в них уже предпринимается попытка как-то работать с дискретным функционалом, а это гораздо сложнее. Это же самый простой подход, в котором удается это делать. Метод называется LambdaRank. Итак, мы обсудили три подхода: поточечный, попарный и списочный к решению задачи ранжирования. При этом на практике чаще всего используется попарный подход, поскольку, с одной стороны, он учитывает структуру задачи. В нем используется тот факт, что у нас ответы заданы на парах объектах. И при этом он не очень сложный, он сводит решение задачи к простому стохастическому градиентному спуску или другому оптимизационному методу, в отличие от списочного подхода, где уже приходится работать с дискретными функционалами.
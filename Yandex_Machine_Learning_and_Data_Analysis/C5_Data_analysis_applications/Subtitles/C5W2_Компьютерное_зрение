[БЕЗ_ЗВУКА] Всем привет! Меня зовут Антон Слесарев, я руководитель группы распознавания образов в компании «Яндекс», и последние несколько лет я занимаюсь компьютерным зрением. И ближайшие несколько лекций мы с вами как раз будем говорить про компьютерное зрение. Компьютерным зрением я занимаюсь в основном в практической области, использую его для решения индустриальных задач. Соотвественно, лекции мы тоже будем делать более практическими. Что такое компьютерное зрение? Компьютерное зрение — это достаточно широкое понятие, это область науки, которая занимается совершенно разнообразными задачами, связанными с анализом изображения и видео. Но можно все эти задачи считать, что они отвечают на один-единственный вопрос: что изображено на картинке? Несмотря на то что вопрос достаточно тривиальный, ответ на него не такой простой, как может показаться на первый взгляд. Чтобы оценить, насколько сложно отвечать на этот вопрос, давайте это попробуем сделать вместе. Вот мы видим картинку. Что на ней изображено? Мы можем говорить про сцену в целом. Мы понимаем, что картинка сделана на свежем воздухе, на улице. Она сделана где-то в азиатской стране, кто-то может узнать Пекин, что это центральная площадь. Мы можем говорить про конкретные объекты, которые мы видим на этом изображении. Мы видим автобус, портрет, крышу, небо. Мы можем пойти дальше и говорить про физические свойства отдельных объектов. Мы понимаем, что крыша наклонная, что автобус едет, что он твердый, на картине изображен Мао Цзэдун, и ветер дует справа налево — мы это можем понять по соответствующему движению флага. То есть смотрите, что происходит: для того чтобы ответить на вопрос, что изображено на картинке, мы не просто смотрим на картинку, мы используем свой весь жизненный опыт. Мы понимаем, что существует ветер, хотя на картинке его в явном виде увидеть нельзя. Мы знаем, что такое транспорт, и должны понимать про историю Китая, чтобы ответить на определенные вопросы. Соответственно, задача — не просто смотреть на пиксели, но и использовать знания. Другой пример. Что такое стул? Можно ответить первое, что пришло в голову: стул — это нечто с четырьмя ножками и со спинкой. Но, глядя на разнообразие стульев на этой картинке, мы можем понять, что это нет так. На самом деле, достаточно сложно описать стул в терминах формы. Стул — это некий концепт, то, на чем сидят. А теперь представьте, что нам нужно объяснить инопланетному существу, которое даже не знает, что такое сидеть, и сидеть не умеет, что такое стул. То есть, прежде чем объяснить и научить это существо по картинкам находить стул, неплохо бы это существо сначала, чтобы оно поняло концепцию «сидеть». И ровно это происходит, когда мы обучаем компьютер распознавать изображения. То есть в идеале, чтобы компьютер отвечал на вопрос про стулья так же хорошо, как человек, он должен концепцию «сидеть» понимать. В науке об искусственном интеллекте есть такое понятие, как ИИ-сложные задачи. То есть это класс задач, которые эквивалентны созданию искусственного интеллекта. Так вот, считается, что компьютерное зрение в общем и в постановке — вот в такой, что нужно ответить на вопрос, что изображено на картинке, и уметь отвечать на все вопросы про это изображение — эта задача эквивалентна созданию искусственного интеллекта. И мы так с вами убедились, что нужно действительно, помимо просто умения смотреть, нужно использовать весь свой жизненный опыт, образование и даже иногда интуицию, чтобы отвечать на вопросы про изображение. Поэтому, да, это действительно сложная задача. К сожалению, мы сейчас еще не умеем создавать искусственный интеллект, поэтому наука компьютерного зрения, она решает определенные подзадачи этой большой задачи. И про эти задачи мы как раз поговорим на ближайших лекциях.

[БЕЗ_ЗВУКА] Давайте разберём несколько примеров практических задач, которые работают с использованием технологий компьютерного зрения. Поиск изображений в Интернете. Есть несколько сервисов, которые позволяют искать картинки. Изначально такие сервисы используют текстовые запросы, чтобы давать пользователю возможность искать ту или иную картинку. Некоторое время назад во многих таких сервисах появилась возможность искать по загруженной картинке. Что это значит? Пользователь загружает изображение, и мы находим картинки, которые являются похожими в Интернете. На самом деле, работает это следующим образом: сначала индексируются изображения из Интернета, для них строится некое цифровое представление, из которых формируется структура данных, позволяющая быстро по ней искать. Для пользовательской картинки мы тоже делаем некое цифровое представление и с помощью данной структуры данных быстро находим дубликаты или похожие картинки. Задача сложная в инфраструктурном смысле, потому что картинок в Интернете очень много, их миллиарды, поэтому любые сложные методы сравнения использовать достаточно сложно из-за вопросов производительности. Ну вот сервисы такие существуют, все мы можем посмотреть, как они работают. Другой пример. Технология распознавания текста. Когда у нас есть картинка, нам нужно найти на ней текст и превратить его в настоящий текст. Используется это в разнообразных приложениях, один из таких удобных способов вводить текст в приложение-переводчик. То есть достаточно сфотографировать этикетку, текст распознается, переводчик её переведёт. Другой пример задачи — это биометрия. Нужно распознавать людей. Распознавать людей можно разнообразными методами. Можно использовать изображение лица, радужной оболочки глаза или отпечатки пальцев. Компьютерное зрение в основном занимается распознаванием лиц, соответственно, это всё с каждым годом работает всё лучше и лучше и во многих местах используется. Видеоаналитика. Нас всё больше и больше камер окружает, теперь всё больше устанавливается видеокамер на дорогах для того, чтобы регистрировать движение автомобилей. Всё больше видеокамер появляется в общественных местах, что позволяет отслеживать потоки людей и детектировать аномалии, то есть оставленные вещи, какие-то нелегальные действия и прочие моменты можно регистрировать. Соответственно, встаёт задача анализа всего этого огромного потока видеоинформации, и в этом нам снова помогает компьютерное зрение. Оно позволяет детектировать номер автомобиля, определять его марку, выяснять, совершались ли запрещённые манёвры, и многое, многое другое. Накоплен огромный массив спутниковых снимков, и с помощью этих данных можно решать совершенно разнообразные задачи. Можно улучшать карты, детектировать лесные пожары и множество других проблем, которые видны только со спутников. Соответственно, технологии компьютерного зрения тоже шагнули в последнее время далеко вперёд, и всё больше и больше ручной работы сейчас автоматизируется с помощью систем компьютерного зрения. Компьютерное зрение, оно не только позволяет распознавать, что изображено на картинке, но также позволяет улучшать и изменять изображение. Ну, в общем, всё, что можно сделать с помощью редакторов картинок — это тоже про компьютерное зрение. Задача 3D-реконструкции. У нас есть множество изображений, сделанных в данном городе, например, на этом видео мы можем увидеть, как взяли множество туристических изображений вокруг Колизея и восстановили его форму. Современные автомобили уже оснащены огромным количеством датчиков: это несколько видеокамер, радары, стереокамеры. И анализировать всю эту информацию как раз помогают методы компьютерного зрения. На основе них созданы системы предотвращения ДТП, столкновения с пешеходами и предупреждения водителя о разнообразных препятствиях. Помимо современных автомобилей, существует ещё область самоездящих автомобилей, которая активно развивается в последнее время, и мы надеемся, что рано или поздно самоездящие автомобили заменят существующие машины. И там компьютерное зрение используется для того, чтобы ориентироваться в пространстве. Мы рассмотрели несколько практических задач и теперь переходим к тому, чтобы обсудить методы, с помощью которых можно их решать.

Задачи компьютерного зрения можно условно разделить на простые и сложные. Сложные задачи отвечают на вопросы: что за объект на картинке, к какому классу она относится и чаще всего используют те или иные методы машинного обучения. Простые методы манипулируют непосредственно с пикселями, используют эвристики, и чаще всего не используют машинное обучение. Разделение условное, но тем не менее, мы сегодня в этом видео поговорим про задачи простого компьютерного зрения или «низкоуровневого» зрения. Важно отметить, что вот такие задачи простые и низкоуровневые, они очень часто используются как составной кирпичик более сложных задач распознавания. Например, можно картинку предобработать, чтобы потом машинное обучение проще распознавать, что на ней изображено. Давайте сначала обсудим, какие библиотеки можно использовать для работы с низкоуровневым компьютерным зрением. На самом деле есть одна самая популярная и известная библиотека opencv, в ней содержится огромное количество алгоритмов. Есть интерфейс как на c++, так и на python. Другой пример такой библиотеки — это skimage, который активно используется в скриптах на python. Мы в примерах будем использовать opencv. Ну на самом деле таких библиотек существует несколько, и у них есть свои плюсы и минусы. Чтобы понять, как манипулировать с изображением, прежде всего нужно понять, как картинки представляются в памяти компьютера. И если человек видит некие цельные картины и объекты, то в памяти компьютера это числа — картинка состоит из пикселей. Если речь про картинку без цвета, то каждый пиксель описывается некой яркостью. Для однобайтовых изображений эта яркость лежит в диапазоне от 0 до 255. Если в картинке есть еще и цвет, то каждый пиксель описывается тремя числами. Например, самая простая и понятная интуитивно тройка чисел — это яркости в красном, зеленом и синем канале. Они тоже лежат в определенном диапазоне для однобайтовых изображений, это от 0 до 255. Существуют и другие представления цвета, о них мы поговорим чуть позже. Соответственно, картинки — это некие матрицы чисел. В случае с серыми картинками — это матрица размера ширина картинки на высоту картинки. В случае цветных картинок появляется еще одна размерность и чаще всего она равна трем каналам. Если вы работали с библиотекой numpy, то вы знаете, как можно с этими матрицами работать. Соответственно, в библиотеке opencv для представления картинок используются представления матриц numpy. Это означает, что мы можем использовать встроенные арифметические операции, например, сложения. Но не все так просто. Если мы воспользуемся сложением из numpy, то это сложение не учитывает переполнение. А для картинок переполнение — это нелогичная операция. То есть если мы две картинки складываем, и яркость получается больше, чем 255, то чаще всего мы хотим, чтобы она и осталась 255, а не превратилась, например, в 4. Вот на данном слайде пример, как отличается сложение в numpy и в opencv. Как это выглядит на реальной картинке? Если мы возьмем вот это изображение, превратим его в серое изображение. Для этого мы воспользуемся такой командой из opencv, мы ее будем неоднократно видеть, она используется для преобразования цветовых пространств, в том числе и для преобразования из RGB в серые картинки. Соответственно, мы картинку перевели в серое, после этого мы прибавляем к ней какое-то число. Такое преобразование эквивалентно увеличению яркости картинки. Мы можем не прибавлять, а умножать на некий коэффициент, например... умножение на коэффициент, на самом деле оно увеличивает контраст картинки. Если умножить еще на большее число, то вот получаем такой эффект. Сейчас мы рассмотрели примеры, как меняется картинка... вот прибавление или умножение на некое число. На самом деле ровно так работают алгоритмы изменения яркости и контраста во многих популярных графических редакторах и в мобильных приложениях. Но мы можем использовать более сложные функции для изменения яркости и контраста. Приведу пример такого подхода, который называет эквилизацией гистограммы. Что такое гистограмма? Гистограмма — это представление картинки, которая отвечает на вопрос сколько пикселей той или иной яркости. На данной картинке мы видим график, гистограмму некоего изображения. Черным цветом обозначена кумулятивная гистограмма, которая отвечает на вопрос: сколько пикселей яркости меньше, чем значение x. Соотвественно, эквилизация гистограммы делает следующее: она растягивает гистограмму картинки таким образом, чтобы кумулятивная гистограмма была близка к линейной функции. Выглядит это следующим образом: вот эквилизация гистограммы, примененная к нашему изображению. Видно, что контраст улучшился, темные области стали темнее, яркие светлее. Чтобы произвести эквилизацию гистограммы, нужно применить некое преобразование к яркости пикселей, и это достаточно просто сделать, это хорошая задачка на алгоритмы. Можете попробовать написать такое преобразование. Приведу еще один пример простых арифметических операций с картинками. Представьте, что у нас стоит задача скомбинировать два изображения. Можно их на самом деле просто сложить, но может получиться проблема, потому что если на картинке два объекта друг на друга наложатся, то получится каша. Давайте сделаем так, что нам известно, где на одной картинке объект, а все остальное место покрыто фоном. Соответственно, мы можем эти два объекта накладывать таким образом, что там, где фон, мы берем второй объект. Там, где первый объект закрывается вторым, мы тоже используем второй объект. Но такое объединение, оно достаточно требовательно к качеству вырезания картинки. Если по краям мы не очень аккуратно вырежем фон, то будет видна такая некрасивая белая черта. То есть, например, на левой картинке такие проблемы можно заметить. С одной стороны, кажется, проблема достаточно сложная — научиться вырезать объект с фона аккуратно. Почему это сложно? Потому что фон неоднородный, и просто выбросить белые пиксели недостаточно. Но можно поступить другим образом: можно воспользоваться хитрым алгоритмом смешивания двух картинок и построить маску таким образом, что она тем больше, чем пиксель дальше от белого. Соответственно, там где у нас вот эти белые пятна — артефакты — у нас будут браться пиксели со второго изображения, и неаккуратное вырезание объекта будет не так заметно. Вот на данных картинках вы видите, как такое простое преобразование помогает избавиться от этой проблемы. Есть более сложные алгоритмы блендинга, когда перед нами стоит задача скопировать объект с неоднородным фоном и вставить его в другое изображение, Простые методы, которые смешивают цвета, не помогают. Существуют более хитрые методы, которые используют оптимизацию для того, чтобы определить, где объект, а где фон, и перенести свойства объекта без изменений, а свойства фона взять с картинки, в которую мы этот объект вставляем. Мы с вами упоминали цветовые пространства, и самое интуитивное и популярное — это представление цвета в каналах красного, зелёного и синего. Другой пример цветового преобразования — это HSV (Hue, Saturation, Value). Что в перевод на русский означает «тон, насыщенность и значение». Так вот, это пространство позволяет манипулировать с цветом и с насыщенностью цвета отдельно. Тон, он обозначает, какой цвет есть у данного пикселя. Он в данном случае закодирован числом от 0 до 360, как угол на этом цилиндре. А насыщенность характеризует, насколько насыщен этот цвет. То есть, если насыщенность 0, то у нас картинка серая. Как это цветовое пространство можно использовать на практике? Приведу такой пример, что мы сконвертируем картинку в это пространство, возьмём канал насыщенности и умножим его на некий коэффициент больше 1. Сконвертируем обратно в пространство RGB и вот такой эффект получим. То есть картинка стала более насыщенная, и цвета — более сочные. Приведу ещё один пример задачи, это задача детекции лиц. Задача детекции лиц достаточно сильно эволюционировала, применялись разнообразные методы, но одним из первых удачных методов были так называемые каскады Хаара. Что это такое? Мы можем из картинки вычленять достаточно простые признаки следующим образом. Мы берём несколько прямоугольников, вот они проиллюстрированы на картинке. Там, где белый прямоугольник, мы пиксели берём со знаком «+», там, где чёрный — «−». Все эти пиксели суммируются, и получаем одно число. Соответственно, у лица есть некоторые характерные паттерны, с помощью алгоритма обучения AdaBoost мы выбираем такие прямоугольники и назначаем им соответствующие веса, и каскад такого рода фильтров Хаара отвечает на вопрос, есть ли в данном прямоугольнике лицо или нет. Каскады Хаара — это не самый лучший метод, который сейчас существует, сейчас существуют более качественные алгоритмы детекции лиц. Но тем не менее, он достаточно простой, и его очень легко найти готовым к использованию. Соответственно, когда не стоит задача очень хорошего качества, зато нужно быстро и просто получить такой детектор, каскады Хаара из OpenCv — отличный вариант. Ещё одна задача, которую достаточно просто решить, это задача сегментации. Существует огромное количество методов сегментации, но часть из них можно очень просто сделать, например, отрезав пиксели выше какого‐то порога и назначив их одному объекту, а пиксели ниже порога — к фону. Вот на данной картинке нужно разделить монеты и фон. Видно, что монеты намного более тёмные, чем фон. Соответственно, достаточно просто подобрать такую границу, что все монеты окажутся ниже этой границы. Вот кусочек кода из OpenCv, который позволяет это сделать. На самом деле, это можно сделать многим числом разнообразных способов. В этом видео я привёл несколько примеров «низкоуровневого» зрения. Отдельный большой класс задач такого рода — это фильтрация изображений. Именно про это мы поговорим в следующем видео.

[БЕЗ_ЗВУКА] В этом видео я расскажу про важный класс преобразования изображений — линейные фильтры. Линейные фильтры решают широкий класс задач, таких как поиск границ, уголков, удаление шумов. Проще всего объяснить, что такое линейная фильтрация на конкретном примере. Представьте, что нам нужно посчитать среднее в окне три на три для каждого пикселя. Это среднее можно записать в следующем виде. То есть мы берем окрестность каждого пикселя, суммируем значения и вычисляем среднее. Данное выражение можно переписать следующим способом. И мы таким образом можем получить выражение для так называемой свертки. Здесь f — это изображение, двухмерная функция, которая характеризует картинку. Индексы k и l — это координаты пикселя, а f — яркость этого пикселя, а функция h — это так называемое ядро свертки. В данном случае это матрица три на три, состоящая из единиц. Так вот, данное выражение является определением свертки, и в случае, если ядро свертки — это такая матрица, то мы получаем как раз скользящее среднее. В OpenCV результат данной свертки можно получить следующим выражением, а картинка получается более размытая. Другой пример размытия изображения осуществляется с помощью свертки с гауссовской функцией. Результат этого размытия мы можем видеть на этом изображении. С помощью сверток можно детектировать границы на изображениях. Если свернуть картинку с такими ядрами, то мы получим соответственно вертикальные и горизонтальные границы. Если объединить результаты этих сверток, то мы получим все границы. Такие ядра являются частью преобразования Превитта, и это самый простой способ находить границы. На самом деле, существует достаточно много разнообразных методов поиска границ. Они используются в различных условиях, и в зависимости от задачи нужно выбирать тот или иной способ. Другой пример линейной фильтрации — это корреляция. Корреляция очень похожа на свертку, но записывается немного в другом виде. Корреляция в отличие от свертки используется для того, чтобы характеризовать меру похожести двух изображений. Это может быть использовано для поиска объектов. Например, у нас есть пример-объект, который нужно найти на картинке. В данном случае это лицо футболиста, и это лицо присутствует на большой картинке, а слева мы видим результат применения корреляции этого маленького изображения с лицом к большой картинке. И мы видим, что там, где яркое белое пятно, там действительно находится лицо. Соответственно, можно использовать эту корреляцию с разнообразными параметрами. Можно, например, нормировать, по-разному ее считать, есть разнообразные вариации, и опять же в зависимости от задачи можно применять ту или иную вариацию. Очень простой способ, как детектировать объект на изображении, если у нас есть их точная копия. В этом видео мы поговорили про линейную фильтрацию. Важно отметить, что линейная фильтрация — это важная часть нейронных сетей, и потом мы увидим, что самые важные компоненты глубоких нейронных сетей как раз состоят из сверток. Поэтому важно получить интуитивное понимание, что такое свертка, для чего она используется, и в следующем видео мы увидим, как сверточные нейронные сети помогают решать более сложные задачи компьютерного зрения.


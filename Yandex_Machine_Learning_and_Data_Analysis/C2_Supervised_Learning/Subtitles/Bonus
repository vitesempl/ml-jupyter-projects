[БЕЗ_ЗВУКА] Привет! Если вы смотрите это видео, скорее всего, это значит, что вы дошли до конца второго курса нашей специализации. Поздравляю! Вы проделали большую отличную работу, вы узнали много нового. В следующих курсах вас ждут еще новые знания, а также большая работа по их закреплению. Мы будем их активно прорабатывать в большом количестве практических задач. А пока мы записали для вас это бонусное видео, для того чтобы подогреть ваш интерес к будущим курсам. В этом видео я хочу вместе с вами проанализировать следующие данные. Рассмотрим 25 тысяч рецензий, которые оставляют пользователи фильмам на сайте imdb — это большая кинобаза. Для каждого фильма в выборке может быть несколько рецензий, но их всегда не больше 30. Кроме текста рецензий, у нас есть бинарные метки, которые посчитаны по оценкам, которые выставлены пользователями фильмам. Если пользователь ставит фильму меньше 5, то бинарная метка равна 0. Если больше либо равно 7, то 1. Шкала рейтингов на imdb — десятибальная, то есть единица у нас соответствует фильмам, которые пользователям, скорее, понравились, а нули — тем, которые пользователям не понравились. Полные данные вы можете найти на сайте Kaggle. Пока давайте загрузим выборку и посмотрим, на что она похожа. У нас есть три поля: эти id-рецензии, бинарная метка и ее текст. В нашей выборке классы сбалансированы, то есть у нас поровну рецензий положительных и отрицательных. На бинарную метку рецензии мы и хотим обучить классификатор, то есть мы хотим каким-то образом понимать по тексту рецензии, понравился ли пользователю фильм. Давайте сразу разобъем выборку на обучение и контроль и подумаем, что делать дальше. Для обучения классификатора нам нужны признаки, а сейчас все, что у нас есть — это текст. С текстом работать не понятно как, потому что на текстах мы не можем считать функцию потерь, мы не можем ее минимизировать, мы не можем определять расстояния между текстами, текст — это очень странный объект. Поэтому чтобы обучать на нем классификатор, нам нужно каким-то образом по нему сгенерировать признаки. Давайте для этого используем векторизацию с помощью TF-IDF — это метод, который для каждого уникального слова, встречающегося во всей базе текстов, создает некий признак, определяющий каким-то образом важность слова в конкретной рецензии. На протяжении следующих курсов мы еще не раз будем говорить о работе с текстами, и вы еще узнаете подробно о том, что такое TF-IDF. А пока давайте просто на признаках, которые он генерирует, попробуем обучить некоторые классификаторы. Начнем с обычной логистической регрессии. На полученных с помощью TF-IDF векторизованных данных просто настроим логистическую регрессию и посчитаем качество классификаций. Точность составляет 88 %, а площадь под кривой — примерно 96 %, это очень неплохой результат. Проблема здесь, однако, заключается в том, что количество признаков, которые нам выдал векторизатор TF-IDF, очень большое — их почти 67 тысяч. А объектов в нашей обучающей выборке всего примерно 19 тысяч. Модель, которая получается на выходе из логистической регрессии — плотная, поэтому каждый признак вносит какой-то вклад в классификацию рецензии. Такую модель, с таким огромным количеством признаков, очень сложно интерпретировать. Давайте попробуем построить что-то попроще, будем делать отбор признаков. Для начала попробуем LASSO. Возьмем регуляризацию L1 и возьмем параметр регуляризации примерно такой, чтобы признаков отбиралось где-то около 100. Вот при C = 0.15 мы получаем, что отбирается 113 признаков. Качество классификации при этом немного снижается. Точность упала до 81 %, а площадь под кривой — до 90. Давайте попробуем еще один способ отбора признаков, который называется stability selection. Он заключается в том, что мы много раз делаем LASSO с одним и тем же параметром регуляризации на случайных подвыборках наших исходных данных. А затем для каждого из признаков, которые у нас есть, вычисляем некий score, который тем больше, чем чаще этот признак в LASSO на случайном подмножестве отбирался. Давайте проведем stability selection, выбрав параметр регуляризации таким образом, чтобы положительный score, то есть признаки, которые мы считаем полезными по итогам обучения, был тоже примерно у 100 признаков. Вот если мы возьмем C = 13, мы получим на нашем разбиении, на обучение-контроль, 121 полезный признак. Давайте теперь только на них и настроим логистическую регрессию. Мы получаем точность порядка 82 % и площадь под кривой порядка 91 % — результат достаточно неплохой. Но можно еще лучше. Давайте вместо того чтобы признаки отбирать, будем их синтезировать. Построим 100 новых синтетических признаков, каждый из которых будет зависеть от всех 67 тысяч исходных. Сделаем это с помощью метода главных компонент. На этих 100 полученных признаках давайте настроим логистическую регрессию — мы получаем существенное увеличение качества по сравнению с обычным отбором признаков. Точность у нас составляет теперь 86 %, а площадь под кривой — примерно 93 %. Получается, что после всего лишь 100 полученных таким образом признаков, мы получаем качество классификаций не слишком хуже, чем по всем 67 тысячам — достаточно неплохой результат. Давайте еще попробуем на этих 100 новых признаках обучить случайный лес. Интересно, что качество классификаций на случайном лесе получается хуже, чем у логистической регрессии. Точность составляет всего 83 %, а площадь под кривой — примерно 90. Это происходит потому, что признаки, которые дает метод главных компонент, оптимальны именно для линейных классификаторов, поэтому логистическая регрессия показывает результаты лучше, чем случайный лес — сложный, нелинейный, медленно работающий метод. В третьем курсе мы будем рассматривать методы понижения размерности, похожие на метод главных компонент. Кроме него вас ждут разные методы кластеризации, матричные разложения, методы поиска аномалий и визуализация данных — много-много всего интересного. Оставайтесь с нами! До встречи в следующем курсе.
Мы начинаем урок, посвященный метрикам качества. В нем мы поговорим о том, как измерять качество алгоритмов в классификации регрессии и какие аспекты качества могут возникнуть в тех или иных задачах. И давайте сначала обсудим, где могут использоваться метрики качества в машинном обучении. Первое применение — это функционалы ошибки, которую мы оптимизируем при обучении алгоритма на обучающей выборке. С этим мы уже много раз сталкивались. Мы использовали, например, среднеквадратичную ошибку, или долю неправильных ответов, или говорили про логистическую функцию — понятие и классификация. Также вы можете обучать алгоритм, используя один функционал, одну метрику качества, а вот проверять его качество на отложенной выборке или на кросс-валидации с помощью другой метрики, например, если вы знаете, что в вашей задаче много выбросов, то нужно использовать какую-то метрику, которая слабо штрафует за ошибки на таких выбросах. Далее, когда вы выбрали параметры и гиперпараметры алгоритма, и у вас есть финальная модель, которую вы собираетесь использовать, то вы можете захотеть измерить еще какую-то, третью метрику качества, которая отражает ценность, например, для бизнеса вашей модели. Скажем, если вы решаете задачу медицинской диагностики, то есть строите модель, которая будет определять: болен или нет пациент тем или иным заболеванием, то вы можете интересоваться: какую долю всех больных пациентов ваша модель сможет обнаружить, сможет понять, что у них есть проблема. Дайте поговорим о том, какие метрики качества бывают в регрессии. Наше видео именно об этом. И первая метрика, о которой мы поговорим, с которой мы уже много раз сталкивались — это среднеквадратичная ошибка, она вычисляется очень просто: мы вычисляем отклонения, прогнозы нашего алгоритма от истинного ответа на каждом объекте выборки, возводим в квадрат это отклонение и усредняем по всем объектам обучающей или какой-то другой выборки. Преимущество этого функционала в том, что его легко оптимизировать. Если мы используем линейную модель, то у него даже есть аналитическое решение, у этой задачи оптимизации. Но при этом есть и проблема: данный функционал возводит отклонение в квадрат. Таким образом, если отклонение сильное, если этот объект — выброс и ответ на нем не очень логичный, то штраф за отклонение, соответственно, на этом объекте будет очень сильный. Таким образом алгоритм может настроиться на выборосы, может дать хороший ответ на тех объектах, на который не имеет смысла настраиваться. Похожий функционал качества — это средняя абсолютная ошибка. В ней мы вычисляем модуль отклонения прогноза от истинного ответа и усредняем это по всем объектам обучающей выборки. Этот функционал немного сложнее. Его тяжелее оптимизировать из-за того, что у модуля производная есть не везде, в нуле она отсутствует. Но при этом здесь считается модуль отклонения, а не квадрат, и поэтому штраф за сильное отклонение гораздо меньше. Это функционал гораздо более устойчив к выбросам. У среднеквадратичной ошибки есть одна модификация — коэффициент детерминации, которая позволяет интерпретировать свое значение. Давайте сначала обсудим, как он задается. Основная часть коэффициента детерминации, или коэффициента R квадрат, — это дробь, у которой в числителе стоит сумма квадратов отклонений прогнозов алгоритма от истинных ответов, то есть практически среднеквадратичная ошибка, только без усреднения, просто сумма. В знаменателе стоит сумма квадратов отклонений истинных ответов от среднего истинного ответа, вычисленного по всем... по всей обучающей выборке. При этом средний истинный ответ мы обозначаем как y с верхней чертой. После того как эта дробь посчитана, мы вычитаем ее из 1. И получаем коэффициент детерминации. У этого коэффициента есть одна интересная интерпретация: он показывает, какую долю дисперсии во всем целевом векторе y наша модель смогла объяснить. Иными словами, какую долю разнообразия ответов наша модель смогла объяснить или предсказать. Как я уже говорил, коэффициент детерминации можно интерпретировать. Давайте разберемся, как именно. Оказывается, что для разумных моделей — что такое разумная модель, скажем чуть позже — коэффициент детерминации находится между 0 и 1, в отрезке от 0 до 1. При этом, если он равен 1, то это идеальная модель, которая идеально угадывает ответы на обучающей выборке. Если коэффициент детерминации равен 0, это означает, что его качество совпадает с оптимальным константным алгоритмом. Оптимальный константный алгоритм — это тот, который на всех объектах возвращает средний ответ по всей обучающей выборке, то есть y с верхней чертой, который мы вводили на прошлом слайде. Если коэффициент детерминации находится между 0 и 1, то можно говорить о том, насколько он лучше, чем константная модель, и насколько он хуже, чем идеальная модель. Например, если он равен 0,2, то, скорей всего, он не очень хороший, ближе к константной модели. Если же коэффициент детерминации алгоритма равен 0,9, скорей всего, это хороший алгоритм, который близок к оптимальному. Коэффициент детерминации может быть меньше 0, если алгоритм работает хуже, чем константный, это те алгоритмы, которые никогда не нужно рассматривать. Пока что мы говорили о метриках качества, которые симметричные, которые одинаково штрафуют как за недопрогноз, так и за перепрогноз, то есть как за завышение, так и за занижение прогноза. При этом бывают задачи, где эти ошибки имеют разную цену. Давайте разберем простой пример: представим, что мы торгуем ноутбуками одной и той же марки. И хотим предсказывать, каков будет спрос на эти ноутбуки в следующем месяце. Если наш прогноз будет занижен, то есть мы предскажем спрос ниже, чем он будет на самом деле, это очень плохо. Во-первых, мы потеряем лояльность клиентов, они будут приходить к нам за покупками, но мы не сможем продать им этот ноутбук, потому что у нас они закончились, клиенты, скорее всего, разочаруются в нас. Также мы теряем потенциальную прибыль — мы могли бы заработать, продав эти ноутбуки, но нам нечего было продать. Поэтому недопрогноз, заниженная прогнозная задача — это плохо. Если же будет иметь место перепрогноз, завышенный прогноз, то мы удовлетворим всех клиентов, но при этом у нас будут остатки ноутбуков, у нас останется несколько ноутбуков непроданными. Это не очень плохо. Да, мы потратим деньги на хранение, но ноутбуки — это довольно компактные вещи, поэтому они не займут много места. Итак, в этой задаче функция потери должна быть несимметричной, мы должны сильнее штрафовать за недопрогноз, чем за перепрогноз. В этом случае хорошо подходит квантильная ошибка, квантильная функция потерь. Давайте разберемся, как она задается. Она представляет собой сумму по всем объектам обучающей выборки вот таких сложных выражений. Давайте поймем, что они означают. Здесь стоит отклонение прогноза алгоритма от истинного ответа: yi-тое − a(xi-того), и это отклонение домножается либо на число τ (тау), если имеет место недопрогноз, то есть если прогноз меньше истинного ответа, либо на число τ − 1, если имеет место перепрогноз, то есть ответ алгоритма, прогноз, больше истинного ответа. τ — это некоторый параметр данного функционала, который варьируется от 0 до 1. Если нарисовать зависимость ошибки, посчитанной данным образом, от отклонения yi-тое − a(xi-тое), то получим вот такую картину. Видно, что эта функция потерь действительно несимметричная. При этом если τ большое, если τ близко к 1, то мы сильнее боимся недопрогноза, мы сильнее боимся занизить прогноз, если τ близко к 0, мы боимся перепрогноза. Чтобы разобраться, почему эта функция потерь называется квантильной, давайте поговорим про вероятностный смысл, вероятностную интерпретацию этих функционалов. Представьте следующую ситуацию: в нашей выборке один и тот же объект x с одним и тем же признаковым описанием повторяется n раз. Это... такая ситуация вполне может возникнуть в ряде задач. При этом ответы на этих n повторах разные, они немного отличаются друг от друга, обозначим их через y1, ..., yn. Такое может возникнуть, например, при измерении роста человека. Человек один и тот же, но при этом результат конкретного измерения зависит от показателей, от шума прибора, которым мы измеряем рост, и от самого человека, он может выпрямиться или сгорбиться, например, и из-за этого рост получится немножко другим, чем в прошлый раз. Объект один и тот же, а ответы немного разные. При этом обратите внимание: наш алгоритм должен на одном и том же объекте возвращать один и тот же прогноз. Таким образом возникает вопрос: какой ответ алгоритма на объекте x оптимален для данной выборки y1, ..., yn с точки зрения того или иного функционала ошибки. Давайте разберемся! Оказывается, если мы используем среднеквадратичную ошибку, то оптимальным прогнозом будет просто средний ответ на этом объекте, то есть среднее по y1, ..., yn. Если мы используем среднюю абсолютную ошибку, то оптимальным прогнозом будет медиана, то есть мы считаем медиану по нашей выборке. Известно, что медиана более устойчива к выборосам, чем среднее. Если же мы используем квантильную регрессию с параметром τ, то оказывается, что оптимальным прогнозом будет τ-квантиль. Это очень логично. Если τ — большое, мы боимся недопрогноза и будем брать большую квантиль, будем завышать прогноз, будем брать его выше, чем среднее значение y-ков. Если же τ — маленькое, и мы боимся перепрогноза, то мы будем брать маленькую квантиль, специально занижать прогноз, делать его ниже, чем среднее. Итак, мы поговорили о том, какие метрики качества бывают в задачах регрессии. Поговорили про среднеквадратичную среднюю абсолютную ошибку и про коэффициент детерминации, который является интерпретируемой версией среднеквадратичной ошибки. Также мы обсудили квантильную функцию потерь, которая является несимметричной и может оказаться важной в ряде задач. А в следующем видео мы поговорим о том, как измерять качество в задачах классификации.

[БЕЗ ЗВУКА] В этом видео мы начнем разговор о том, как можно измерять качество в задачах классификации. И, на самом деле, мы уже знаем некоторый ответ на этот вопрос. Мы использовали долю неправильных ответов, чтобы обучать линейные классификаторы. Она считается очень просто. Мы для каждого объекта выборки выясняем, дает ли алгоритм правильный ответ или нет, и если дает неправильный ответ, то записываем единичку, если правильный — то нолик, и усредняем эти нолики и единички по всем объектам выборки. Так вышло, что в задачах классификации метрики принято выбирать так, чтобы их нужно было максимизировать, тогда как в регрессии метрики были такие, что мы их минимизировали, например среднюю квадратичную ошибку или квантильные потери. Чтобы максимизировать долю неправильных ответов, нужно ее немножко модифицировать и превратить в долю правильных ответов, или accuracy на английском. Она вычисляется точно так же: мы усредняем по всем объектам выборки индикаторы того, что на данном объекте алгоритм выдает правильный ответ. Это очень простая метрика качества, которая широко используется, но при этом у нее есть две проблемы. Давайте поговорим о них подробнее. Проблема первая связана с несбалансированными выборками. Давайте рассмотрим простой пример. Пусть в выборке 1000 объектов, из них 950 относится к классу −1, и 50 — к классу +1. И при этом рассмотрим константный алгоритм a(x), который на всех объектах, абсолютно всех объектах возвращает ответ −1. Этот алгоритм бесполезен, не имеет смысла его использовать ни в каких задачах. Он не восстанавливает никакие закономерности в данных. При этом его доля верных ответов на данной выборке будет равна 0,95 или 95 %. Это очень много, но не соответствует нашим ожиданиям. Понятно, что проблема именно в несбалансированности. В том, что одного из классов сильно больше, чем другого. Чтобы бороться с этой проблемой, имеет смысл измерять долю объектов самого крупного класса в данной выборке. Обозначим это через q₀. В нашем случае самый крупный класс — это −1, и доля объектов этого класса равняется как раз 95 %. Это означает, что доля правильных ответов для разумных классификаторов будет лежать в интервале от q₀ до 1, от 0,95 до 1, а не от 1/2 до 1, как мы могли бы ожидать в случае с бинарной классификацией. Еще раз совет на случай, если вы настроили некоторый классификатор и получили большую долю верных ответов — посмотрите на баланс классов. Возможно, дело не в том, что вы построили хороший классификатор, а в том, что просто одного из классов сильно больше, чем другого, и из-за этого легко получить высокую долю верных ответов. Вторая проблема, которая имеется в доле верных ответов — это то, что она никак не учитывает разные цены разных типов ошибок, тогда как цены действительно могут быть разными. Давайте разберем простой пример. Рассмотрим задачу кредитного скоринга, в которой нужно для клиента банка, который просит кредит, понять, выдавать ему кредит или не выдавать, вернет он этот кредит или не вернет. И представим, что у нас есть две модели. Первая модель говорит, что нужно выдать кредит ста клиентам. При этом если мы их выдадим, то из них 80 вернут деньги, а 20 не вернут. Вторая модель более консервативная. Она говорит, что нужно выдать кредит всего 50 клиентам, и если мы это сделаем, то из них 48 вернут кредит и всего 2 не вернут. Непонятно, какая из этих моделей лучше. Вторая модель более консервативная. Если мы воспользуемся ей, то практически все клиенты вернут кредиты, но при этом многим мы кредиты не дадим, хотя они вернули бы деньги. Мы не заработаем. Первая модель рискует сильнее, она выдает кредиты большему количеству человек, мы заработаем больше, но при этом и будут некоторые потери, связанные с тем, что 20 клиентов кредит не вернут. И в зависимости от того, каковы потери от невозврата кредита, можно отдать предпочтение либо одной модели, либо другой. Таким образом, нужны какие-то дополнительные метрики качества, которые позволяют учесть цену той или иной ошибки. Об этом будем говорить в следующем видео. Итак, мы поговорили про основную метрику качества классификации, долю верных ответов, и обсудили, что у нее есть две проблемы. Первая связана с неадекватными значениями в случае с несбалансированными выборками, а вторая — с тем, что данная метрика качества не умеет учитывать цены ошибок. А в следующем видео мы поговорим о том, как можно учитывать разные цены ошибок при разных типах ошибок классификации.

В этом видео мы поговорим о точности и полноте, метриках качества классификации, которые позволяют учитывать разные цены ошибок. В прошлом видео мы выяснили, что цены ошибок действительно могут быть разные. Например, в случае с кредитным скорингом непонятно, что лучше: выдать кредит плохому клиенту, который не вернёт кредит, или не выдать кредит хорошему клиенту, который мог бы вернуть этот кредит. То, какая ошибка лучше или хуже, какая важнее, какая нет, зависит от конкретной стратегии банка. Цена этой ошибки может варьироваться. Доля верных ответов неспособна учитывать цены разных ошибок. Чтобы рассуждать о том, у какой ошибки какая цены, удобно ввести матрицу ошибок, которая производит некоторую классификацию типов ошибок. Она состоит из двух строк и двух столбцов. Строка зависит от того, какой ответ выдаёт наш алгоритм, наша модель. Первая строка соответствует объектам, которых наша модель относит к классу +1. Вторая строка соответствует объектам, которых наша модель относит к классу -1. Столбец зависит от того, к какому классу на самом деле относится объект. Если объект относится к классу 1, он попадает в первый столбец. Если объект относится к классу -1, он попадает во второй столбец. Когда алгоритм относит объект к классу +1, будем говорить, что алгоритм срабатывает, он делает срабатывание. Итак, если алгоритм сработал, отнёс объект к классу +1, и объект действительно относился к классу +1, это верное срабатывание или True Positive. Если алгоритм сработал, но объект не относился к первому классу, на самом деле он из класса -1, то это ложное срабатывание или False Positive. Если алгоритм выдаёт ответ -1, будем говорить, что он пропускает объект. Итак, если имеет место пропуск, но при этом объект относится к классу 1, то это ложный пропуск или False Negative. Если же алгоритм пропускает объект, и, действительно, этот объект относится к классу -1, то это верный пропуск или True Negative. Таким образом, у нас есть два вида ошибок: ложные срабатывания и ложные пропуски. И для каждой из них нужна своя метрика качества, чтобы как-то измерить, какое количество таких ошибок мы допускаем. Давайте будем разбирать наши метрики на двух примерах, на примере двух моделей. Будем считать, что у нас выборка состоит из двухсот объектов, из которых сто относится к классу 1, и сто относится к классу -1, при этом первая модель относит к классу 1 сто объектов, из которых 80 — это верное срабатывание и 20 — это ложное срабатывание. Вторая модель срабатывает на пятидесяти объектах. Из них 48 — это верное срабатывание, а 2 — это ложное срабатывание. Первая метрика, о которой мы поговорим — это точность или precision. Она показывает, насколько мы можем доверять классификатору в случае, если он срабатывает. В случае, если он относит объект к первому классу. Формально точно задаётся как отношение числа верных срабатываний к общему числу срабатываний, то есть число верных срабатываний плюс число ложных срабатываний. True Positive плюс False Positive. Давайте посчитаем точность в нашем примере. В случае с первой моделью, она срабатывает на ста объектах, и из них 80 действительно относятся к первом классу. Значит, нам нужно 80 поделить на сто. Получаем 0.8. Точность первого алгоритма = 0.8 или 80 процентам. Вторая модель срабатывает на пятидесяти объектах, и из них 48 — это верные срабатывания. Её точность равняется 48 поделить на 50 или 0.96. Её точность гораздо выше, она равняется 96 %. Если вторая модель срабатывает, то мы можем быть с большой долей вероятности уверены, что это срабатывание верное. Вторая метрика — это полнота или recall. Она показывает, как много истинных объектов первого класса алгоритм выделяет, на скольки из них он срабатывает. Формально она задаётся как отношение числа верных срабатываний к общему числу объектов первого класса выборки, то есть число верных срабатываний плюс число ложных пропусков. Посчитаем полноту для наших двух моделей. К первому классу относится сто объектов. И первая модель срабатывает на 80 из них, значит её полнота равна 0.8 или 80 %. Вторая модель срабатывает лишь на 48 положительных объектах. Таким образом, её полнота равняется 48 поделить на сто или 0.48. Вторая модель очень точная, но из-за этого страдает её полнота, она выделяет далеко не все объекты первого класса. Давайте разберём два примера того, как можно пользоваться точностью и полнотой в совокупности. Первый пример про кредитный скоринг. Представьте, что руководство банка решило, что, если среди всех выданных кредитов не более 5 % будут ошибочными, то есть лишь 5 % из них не вернут, то такая схема не будет убыточной. Эти невозвращённые кредиты не дадут нам слишком много убытков. Таким образом, мы получаем ограничение на точность в 0.95. Точность должна быть ≥, чем 0.95. И при таком ограничении мы будем максимизировать полноту, то есть стараться выдать кредиты как можно большему количеству хороших заёмщиков. Второй пример про медицинскую диагностику. Представьте, что мы сделали модель, хотим сделать модель, которая определяет: есть или нет то или иное заболевание у пациента. При этом наш заказчик требует, чтобы среди всех протестированных пациентов мы выделили как минимум 80 % тех, которые действительно имеют это заболевание. Таким образом, мы получаем ограничение, что полнота должна быть не меньше, чем 80 %. И при этом ограничении мы будет максимизировать точность, то есть пытаться сделать как можно меньше число ложных срабатываний. Наконец, обратите внимание, как точность и полнота работают на несбалансированных выборках. Представьте, что у нас есть выборка, в которой сто объектов первого класса и более десяти тысяч объектов отрицательного класса, -1 класса. При этом у нас 10 верных срабатываний, 20 ложных срабатываний и 90 ложных пропусков. Доля верных ответов на данной выборке равняется 99 %. Скорее всего, это число ни о чём не говорит. Чтобы понять, что плохого с данным алгоритмом, нужно померить точность и полноту. Давайте измерим точность. Всего алгоритм срабатывает на тридцати объектах, и из них лишь 10 — это верные срабатывания, значит точность равна 33 %. Видно, что алгоритм делает слишком много ложных срабатываний — 66 %. Далее полнота. Всего в выборке сто объектов первого класса, из их них лишь на 10 алгоритм срабатывает. Таким образом, полнота равняется 10 %. Видно, что у него также много ложных пропусков. Он пропускает 90 % объектов первого класса. Благодаря точности и полноте мы можем видеть, что не так с этим алгоритмом и что можно пытаться улучшить. Итак, мы с вами ввели матрицу ошибок и на её основе определили две метрики качества: точность и полноту. Точность измеряет, как много у нас ложных срабатываний, а полнота — как много ложных пропусков. И можно отдавать предпочтение одной или другой в зависимости от специфики задачи. Также мы выяснили, что точность и полнота могут быть очень полезными в случаях со сбалансированными выборками. В следующем видео мы поговорим о том, как можно объединить точность и полноту в одну метрику качества.

[заставка без звука] В этом видео мы поговорим о том, как объединить точность и полноту в одну метрику качества классификации. В прошлый раз мы выяснили, что точность показывает, насколько мы можем доверять классификатору в случае, если он срабатывает. То есть в случае, если он относит объект к первому классу. Полнота же измеряет, как много объектов первого класса наш классификатор выделил, на скольки из них он сработал. При этом есть задачи, где имеет место ограничение на одну из этих метрик, например, точность должна быть не меньше 95 %. И при этом мы будем оптимизировать другую метрику, например, полноту. Но при этом, точность и полнота хороши сами по себе, например, тем, что они более выразительны на несбалансированных выборках. И у нас может просто возникнуть желание максимизировать и точность, и полноту одновременно, но, при этом максимизировать две метрики, это не очень удобно. Лучше сначала объединить их в одну. Давайте выясним, как это правильно сделать. Первый подход, который мы обсудим, это арифметическое среднее. Просто сложим точность и полноту и поделим на 2. Чтобы визуализировать данный подход к их усреднению, мы будем рисовать линии уровня. По оси x мы будем откладывать точность, по оси y — полноту, и рисовать линии уровня, то есть линии, на которых арифметическое среднее принимает одно и то же значение. Давайте разберём простой пример. Представьте, что у нас есть алгоритм, у которого точность равна 10 %, а полнота — 100 %. На самом деле, это может быть выборка, в которой всего 10 % положительных объектов и алгоритм, который абсолютно на всех объектах выдаёт ответ +1, константный алгоритм. Понятно, что он бесполезен. Среднее арифметическое точности и полноты в этом случае = 55 %. А вот другой алгоритм. У него точность и полнота = 55 %. Этот алгоритм гораздо лучше предыдущего, но при этом среднее арифметическое снова = 55 %. Эти два алгоритма лежат на одной линии уровня. Это очень плохо. Константный и разумный алгоритмы получают один и тот же показатель. Чтобы устранить эту проблему, приходит в голову следующая идея. Раз мы хотим одновременно максимизировать и точность, и полноту, давайте максимизировать минимум из них. В этом случае линии уровня будут выглядеть как-то так. Видно, что они сильнее концентрируются в правом верхнем углу, то есть там, где находится алгоритм с точностью и полнотой, = 1. Данный подход с взятием минимума из точности и полноты решает проблему, которую мы обсуждали чуть раньше. Если взять алгоритм с точностью 5 % и полнотой 100 %, то минимум будет = 5 %. При этом есть другой нюанс. Рассмотрим два алгоритма, оба из которых имеют точность 40 %, но при этом полнота первого = 50 %, а полнота второго = 90 %. Понятно, что второй алгоритм лучше. При такой же точности он даёт более высокую полноту, но при этом и минимум и там, и там = 40 %. Они снова лежат на одной линии уровня, хотя этого не должно быть. Чтобы устранить проблему, давайте попробуем сгладить минимум. Это можно сделать с помощью гармонического среднего или F-меры. Чтобы её посчитать, нужно вычислить дробь, в числителе которой стоит произведение точности и полноты, умноженное на 2, а в знаменателе сумма точности и полноты. Если мы рассматриваем два алгоритма, оба из которых имеют точность 40 %, и при этом первый имеет полноту 50 %, а второй — 90 %, то у первого F-мера = 44 %, а у второго — 55 %. Второй оказывается на линии уровня, которая ближе к правому верхнему углу, ближе к идеальному классификатору. При этом, если вы хотите отдать предпочтение либо точности, либо полноте, можно воспользоваться расширенной версией F-меры, который имеет параметр β. Она вычисляется по такой страшной формуле. При этом, если вы возьмёте β = 0.5, то важнее окажется полнота. Дело в том, что если вы зафиксируете полноту и будете менять точность, то данная F-мера будет меняться довольно гладко. Если же вы зафиксируете точность и будете менять полноту, изменения будут очень резкие. Таким образом, полнота важнее в этом случае. Если же взять β = 2, то ситуация поменяется. Важнее окажется точность. Поскольку при фиксированной полноте изменение точности будет гораздо сильнее приводить к перемене F-меры. Итак, мы обсудили, что лучший способ объединения точности и полноты в одну метрику, это F-мера, которая представляет собой сглаженную версию минимума из точности и полноты. При этом, если вы хотите отдать предпочтение либо точности, либо полноте при усреднении, можно воспользоваться параметром β в F-мере. В следующем видео мы поговорим о том, как измерять качество оценок принадлежности тому или иному классу.

[ЗАСТАВКА] В этом видео мы поговорим о том, как измерять качество оценок принадлежности к классу. И давайте начнем с того, что разберемся, что это за оценки принадлежности. Дело в том, что многие алгоритмы классификации устроены следующим образом: на самом деле, сначала вычисляется некоторое вещественное число b(x), и далее оно сравнивается с некоторым порогом t. Если оно больше порога, то относим объект к положительному классу, если меньше порога — то к отрицательному классу. Таким образом, b(x) выступает как некоторая оценка уверенности классификатора в том, что объект относится к единичному классу — классу +1. Примером может служить линейный классификатор. В нем мы вычисляем скалярное произведение вектора весов на вектор признаков и дальше сравниваем его, например, с нулем. Если оно больше нуля, то относим объект к одному классу, если меньше нуля — то к другому классу. Здесь в качестве оценки принадлежности выступает скалярное произведение. И, действительно, мы обсуждали, что если есть два объекта, у обоих скалярное произведение больше нуля, но при этом на первом оно больше, чем на втором, это означает, что в принадлежности первого к этому классу алгоритм уверен больше. Итак, зачастую нужно измерить качество именно оценки принадлежности b(x), потому что порог будет выбран заказчиком позже. Например, мы оцениваем вероятность возврата кредита всеми клиентами банка, и дальше банк уже будет выбирать порог, в зависимости от своего желания рискнуть или, наоборот, желания делать консервативную выдачу кредитов. Вот еще одна причина, по которой может понадобиться измерять качество именно оценки принадлежности. Представьте, что мы занимаемся кредитным скорингом и построили некоторую функцию b(x), которая оценивает вероятность того, что клиент x вернет кредит. Далее мы построили классификатор следующим образом: взяли данную вероятность, и если она больше 1 / 2, то будем выдавать клиенту кредит, если меньше 1 / 2, то не будем выдавать ему кредит. И при этом получилось, что точность = 10 %, полнота = 70 %. Это очень плохой алгоритм. Точность в 10 % означает, что 90 % клиентов, которым мы выдадим кредит, не вернут его. Банк такое явно не примет. При этом не понятно, в чем дело: в том, что мы плохо выбрали порог, и нужно было взять его, например, не 1 / 2, а, скажем, 9 / 10, или же в том, что сама оценка b(x) — плохая, и как бы мы ни старались с порогом, невозможно с ее помощью построить классификатор, который будет давать высокую точность. Именно для этого и нужно измерять качество самих оценок b(x). Мы разберем два способа, и первый из них основан на кривой точности-полноты. По оси y будем откладывать... по оси x будем откладывать полноту, по оси y — точность. И точка в этих осях будет соответствовать конкретному классификатору, то есть выбору конкретного порога, по которому мы отсекаем оценку принадлежности b(x). Давайте на примере разберем, как строится кривая точности и полноты. Пусть у нас есть выборка, в которой шесть объектов, из них три относятся к классу 1, три — к классу 0. И они имеют вот такие оценки принадлежности к классу 1. Сначала возьмем порог, при котором ни один объект не будет отнесен к классу 1. В этом случае и точность, и полнота, будем считать, что они равны нулю. Ставим точку (0, 0). Далее чуть-чуть уменьшаем порог так, чтобы ровно один объект с максимальной оценкой был отнесен к классу 1. В этом случае точность будет равна 100 %, полнота будет равна 1 / 3, поскольку мы выделяем один из трех положительных объектов. Ставим следующую точку. При дальнейшем уменьшении порога мы два объекта отнесем к первому классу, и оба будут верными срабатываниями — точность все еще равна 100 %, полнота увеличивается до 2 / 3. Далее, когда мы три объекта отнесем к первому классу, то точность уменьшится, поскольку третий относится к негативному классу, на самом деле, — точность станет равна 2 / 3, — полнота останется такой же. Уменьшаем порог еще сильнее — точность уменьшается, полнота остается такой же. Когда мы отнесем пять объектов к первому классу, точность окажется равной 3 / 5, а полнота будет 100 %, поскольку мы уже выделили все объекты первого класса. Наконец, когда мы все объекты отнесем к классу... классу 1, то получим, что точность равняется 1 / 2, полнота равняется 100 %. Получается вот такая кривая. В реальных задачах, где объектов тысячи и десятки тысяч, кривая точности-полноты выглядит как-то так. Заметим, что стартует она всегда из точки (0, 0). Финальная точка этой кривой находится по координатам 1 и r, полнота равняется 100 %, а точность равняется доли объектов первого класса во всей выборке, которую мы обозначаем как r. Если у нас имеется идеальный классификатор, то и существует такой порог, при котором и точность, и полнота — 100%, то кривая пройдет через точку (1, 1). Чем ближе к этой точке она пройдет, тем лучше наши оценки. Таким образом, площадь под этой кривой может быть хорошей мерой качества оценок принадлежности к классу 1. Введем эту метрику. Будем называть ее AUC — PRC, или площадь под precision-recall-кривой. Второй способ измерить качество — это ROC-кривая, она строится немножко в других осях. По оси x откладывается доля ложных срабатываний, или False Positive Rate. Она считается как отношение числа ложных срабатываний к общему размеру отрицательного класса, то есть False Positives + True Negatives. По оси y будем откладывать долю верных срабатываний, или True Positive Rate. В числителе стоит количество верных срабатываний, в знаменателе — размер первого класса, то есть True Positive + False Negative. Разберем на том же примере, как строится ROC-кривая. Сначала выбираем порог, при котором ни один объект не относится к первому классу. Получаем точку (0, 0) — число... доля верных срабатываний, доля ложных срабатываний равны 0. Далее, когда мы один объект отнесем к классу 1, доля верных срабатываний увеличится на 1 / 3, доля ложных срабатываний останется нулевой. При дальнейшем уменьшении порога доля верных срабатываний увеличится до 2 / 3, доля ложных срабатываний — все еще 0. Отнесем три объекта к классу 1. В этом случае доля верных срабатываний все еще равна 2 / 3, доля ложных срабатываний — 1 / 3. Уменьшаем еще сильнее — доля верных срабатываний остается такой же, доля ложных срабатываний увеличивается до 2 / 3. Далее, доля верных срабатываний увеличивается до 1, доля ложных срабатываний останется 2 / 3. И, наконец, когда все объекты отнесем к классу 1, доля и верных, и ложных срабатываний будет равна 1. В случае с большой выборкой ROC-кривая выглядит как-то так. Она стартует из точки (0, 0) и приходит в точку (1, 1), при этом если есть идеальный классификатор, то его доля верных ответов будет равна 1, доля ложных срабатываний будет равна 0, то есть кривая пройдет через точку (0, 1). Опять же, чем ближе кривая к этой точке, тем лучше наши оценки, и площадь по этой кривой будет характеризовать качество оценок принадлежности к первому классу. Эта метрика называется AUC — ROC, или площадь под ROC-кривой. Давайте разберемся, в чем особенности площади под ROC-кривой и площади под кривой точности-полноты. Начнем с ROC-кривой. Вспомним, что она измеряет долю верных срабатываний и долю ложных срабатываний. При этом доля ложных срабатываний делится на размер негативного класса, доля верных срабатываний делится на размер положительного класса. За счет того, что эти величины делятся на объемы классов, площадь под ROC-кривой не зависит от баланса классов. Если свойства объектов выборки останутся такими же, но лишь изменится соотношение классов, площадь под ROC-кривой не изменится. Площадь под ROC-кривой для идеального алгоритма равна 1, площадь под ROC-кривой для худшего алгоритма, то есть того, который выдает случайные ответы, находится в районе 1 / 2. При этом у площади под ROC-кривой есть много интересных интерпретаций, которые помогают объяснять ее другим людям. Например, она равняется вероятности того, что если вы выберете случайный положительный и случайный отрицательный объект из выборки, то положительный объект получит оценку принадлежности выше, чем отрицательный объект. Перейдем теперь к площади под precision-recall-кривой, она зависит от точности и полноты. При этом в точности нормировка производится не на размер положительного класса, а на число срабатываний алгоритма. Таким образом, если соотношение классов изменится, то изменится и точность, значит и площадь под precision-recall-кривой зависит от соотношения классов. При этом площадь под precision-recall-кривой проще интерпретировать, если выборка сильно несбалансированная. Давайте разберем это на примере. Представьте, что мы построили такие оценки принадлежности, что максимальные оценки — у 50 тысяч объектов отрицательного класса. Далее идут 100 объектов положительного класса. И далее — 950 тысяч объектов отрицательного класса. У нас очень большой отрицательный класс — миллион объектов, и маленький положительный — 100 объектов. И при этом, при такой сортировке, при таком упорядочивании, 100 объектов положительного класса оказались довольно далеко от верха — сначала идет 50 тысяч отрицательных объектов. Понятно, что такая сортировка нас не устраивает — положительные объекты находятся слишком далеко. При этом площадь под ROC-кривой равняется 95 %, площадь под precision-recall-кривой — 0,1 %. Почему-то площадь под ROC-кривой получилась большой, это может ввести в заблуждение. Давайте разберемся, почему так вышло. Чтобы понять, давайте рассмотрим одну точку в пространстве ROC-кривой. Возьмем порог, при котором к первому классу будут отнесены 50 тысяч объектов негативного класса и 95 объектов позитивного класса. Понятно, что это не очень хороший классификатор — у него слишком много ложных срабатываний. Их будет 50 тысяч, при этом верных срабатываний — 95. Доля верных срабатываний равна 95 %, доля ложных срабатываний равна всего 5 %, поскольку в ней нормировка производится на размер всего отрицательного класса. А 50 тысяч — это очень мало, по сравнению с миллионом объектов во всем отрицательном классе. Понятно, что эта точка лежит близко к точке с координатами (0, 1), и поэтому ROC-кривая очень похожа на идеальную — площадь под ней близка к 1. При этом точность и полнота этого алгоритма гораздо лучше отражают ситуацию. Полнота равняется 95 %, а точность — меньше 1 %, поскольку слишком много ложных срабатываний. Таким образом, площадь под кривой точности-полноты гораздо лучше отражает ситуацию в данном примере с несбалансированными выборками. Итак, мы обсудили, что зачастую в машинном обучении нужно измерять качество модели еще до того, как мы выбрали порог, нужно измерять качество оценок принадлежности к первому классу. Для этого подходят такие метрики, как площадь под кривой точности и полноты и площадь под ROC-кривой. При этом площадь под ROC-кривой не зависит от баланса классов и гораздо лучше интерпретируется. А площадь под кривой точности и полноты гораздо выразительнее в случае дисбаланса классов. На этом мы заканчиваем урок, посвященный метрикам качества, а дальше продолжим говорить о линейных моделях.
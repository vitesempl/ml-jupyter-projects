Мы начинаем урок, посвященный линейным моделям. В нем мы поговорим о том, как они устроены в задачах классификации и регрессии, как их обучать и с какими проблемами можно столкнуться при использовании этих моделей. А начнем мы этот урок с видео, в котором обсудим, как выглядят линейные модели в задачах регрессии. Давайте сначала вспомним некоторые обозначения, которые мы ввели в прошлом уроке. Буквой X красивая мы обозначаем пространство всех объектов, то есть все возможные объекты, для которых может понадобиться делать прогнозы. А буквой Y красивая обозначаем пространство ответов, то есть все возможные ответы, которые могут иметь наши объекты. Маленькой буквой x обозначаем сам объект, то есть то, для чего нужно делать предсказания. Объект описывается признаками, всего их d штук, и они как-то характеризуют этот объект с помощью чисел или чего-то другого, понятного компьютеру. Большой буквой X обозначается обучающая выборка, то есть наборы из l пар, объект xi-тая и ответ yi-тая на этом объекте. а(x) — это алгоритм или модель, то есть то, что делает предсказание, что предсказывает ответ y по объекту, по его признаковому описанию. Качество алгоритма a измеряется с помощью функционала ошибки Q, которая принимает на вход алгоритм и выборку, на которой измеряется качество этого алгоритма. Процесс обучения заключается в поиске такого алгоритма из семейства алгоритмов A красивое, который минимизирует функционал ошибки. Как я обещал, в этом видео мы обсуждаем задачу регрессии, то есть пространство ответов Y совпадает с множеством вещественных чисел. Ответом может быть любое вещественное число. Чтобы научиться решать задачу регрессии, нужно уметь отвечать на 3 вопроса: во-первых, как выглядит функционал ошибки, то есть как мы измеряем, насколько хорошо или плохо отрабатывает алгоритм на конкретной выборке; второе — это семейство алгоритмов, как оно устроено, как выглядит множество тех алгоритмов, из которых мы выбираем лучшие; и третье — это метод обучения, то есть как именно мы выбираем лучшие с точки зрения функционала ошибки алгоритм из семейства алгоритмов, из этого множества. В этом видео мы ответим на первые 2 вопроса, а о третьем будем мы говорить в следующих видео этого урока. Давайте для начала рассмотрим простой пример с предсказанием прибыли магазина. Пусть в этой задаче есть всего один признак — прибыль магазина в прошлом месяце, а предсказать нужно прибыль магазина в следующем месяце. Понятно, что прибыль — это вещественная переменная, то есть это задача регрессии. Если мы разместим точки обучающей выборки на таком графике, где по оси x находится признак, то есть прибыль в прошлом месяце, а по оси y находится целевая переменная или ответ, то есть прибыль в следующем месяце, то точки расположатся как-то так. Видно, что есть некоторая зависимость, чем больше была прибыль в прошлом месяце, тем больше будет прибыль и в следующем месяце. Можно провести прямую, то есть сказать, что зависимость более-менее линейная, и с помощью этой прямой пытаться предсказывать прибыль в следующем месяце по прибыли в предыдущем месяце. Видно, что в целом прямая угадывает тенденцию, она более-менее описывает зависимость между ответом и признаком. При этом, разумеется, она делает это неидеально, то есть в каждой точке есть некоторая ошибка — истинный ответ на каждом объекте несколько отклоняется от прогноза, но в среднем это ошибка не такая большая, возможно, она нас устроит. На самом деле понятно, что один признак — это не очень серьезно. Если признак всего один, мы можем, как это было сейчас в примере, просто нарисовать нашу выборку, зависимость ответа от признака, и пробовать руками восстановить зависимость. Гораздо сложнее и интереснее работать с многомерными выборками, которые описываются большим количеством признаков. В этом случае нарисовать выборку и понять, подходит ли там линейная модель или нет, нельзя. Можно лишь найти ее и посчитать ее качество и по нему как-то понять — хорошее оно получилось или нет, можно использовать здесь линейную модель или нельзя. Отмечу, что вообще нельзя придумать модель, которая идеально описывает ваши данные, идеально описывает то, как порождается ответ по признакам. Но при этом модели все равно бывают полезными, из них можно извлекать какую-то пользу, если ошибка, которую они допускают, не очень большая. Итак, мы подошли к тому, чтобы обсудить, как именно выглядит семейство алгоритмов в случае с линейными моделями. Линейная модель, линейный алгоритм для задачи регрессии выглядит вот так. Из чего он состоит? Мы берем все признаки объекта, здесь они обозначаются как xj-тая. xj-тая — это j-тый признак объекта, и складываем их с некоторыми весами в wj-тое, при j-том признаке стоит j-тый вес. Также мы прибавляем к этой сумме вес w0. Это свободный коэффициент, или еще его иногда называют сдвигом. Давайте обратим внимание, что сдвиг немножко портит вид модели, он делает его неоднородным. Чтобы устраниться, давайте добавим к данным еще один признак, константный, который на каждом объекте принимает значение 1. В этом случае вес при нем по смыслу будет совпадать со свободным коэффициентом или со сдвигом, и сам w0 будет больше не нужен, его роль будет играть вес при этом признаке. В этом случае признаков будет d + 1, и линейная модель будет выглядеть просто как сумма всех признаков с некоторыми весами. Обратите внимание, что по сути это скалярное произведение вектора весов на вектор признаков. Мы будем часто пользоваться этим обозначением в наших лекциях. Далее давайте обсудим, как измерять ошибку линейного алгоритма на обучающей выборке или на какой-то другой выборке. Давайте рассмотрим пример. Пусть у нас есть объект, (III) на котором равен 10. И посмотрим разные варианты того, что может предсказать наш алгоритм. Предположим, алгоритм от x выдает ответ: 11, этот ответ не совпадает с истинным ответом: 10 и отклоняется на 1. Наверное, это не очень сильное отклонение. Или, например, если ответ нашего алгоритма: 9. Его отклонение будет: −1, поскольку алгоритм ошибается в другую сторону, возможно, это тоже не очень плохо. А что, если алгоритм возвращает число 20? В этом случае отклонение от истины гораздо больше. Разница равна 10. Если же алгоритм возвращает 1, отклонение тоже большое, но в другую сторону. Оно равно −9. В общем-то здесь, понятно, проблема, по которой нельзя использовать отклонение, то есть а(x) − y, как некую меру ошибки. Меру ошибки, или функционал ошибки, мы хотим минимизировать. При этом минимизация отклонения приведет к тому, что алгоритм будет оптимально выдавать минус бесконечность на всех объектах, если мы захотим, чтобы отклонение было как можно меньше. Чтобы устранить проблему, первое, что приходит в голову — это взять модуль от этой разности, минимум модуля — это 0, и достигается он в том случае, если ответ алгоритма и истинный ответ совпадают. Это уже гораздо больше подходит нам, мы можем минимизировать модули отклонения ответов алгоритма от истинных ответов на всех объектах и тем самым настраивать наш алгоритм. Но у модуля есть большая проблема. Эта функция негладкая. У модуля нет производной в нуле, и из-за этого использование градиентных методов оптимизации может быть затруднительно. Чтобы решить и эту проблему давайте просто возведем в квадрат модуль. Квадрат разности — это все еще хорошая функция. Ее минимум равен 0 и достигается, если прогноз алгоритма и истинный ответ совпадают. И при этом квадрат является гладкой функцией, у него есть производная в каждой точке, поэтому его можно минимизировать теми методами градиентными, которые мы будем обсуждать далее. Мы приходим к функционалу ошибки, который называется среднеквадратичной ошибкой. В нем мы вычисляем квадрат отклонения ответа алгоритма от истинного ответа, а(xi-того) и от y-i-того. И суммируем, точнее усредняем, эти квадраты отклонений по всей обучающей выборке. Это и называется среднеквадратичной ошибкой. Обратите внимание, что подставляя сюда линейную модель, то есть вместо a(x) подставляя скалярное произведение w на xi-тое, мы получаем уже не функционал, а функцию, поскольку теперь наша ошибка зависит не от некой функции a(x), а от вектора весов w. И оптимизировать нужно именно по этому вектору весов, что уже гораздо проще. Итак, мы с вами обсудили, как выглядят линейные алгоритмы, или линейные модели, для задачи регрессии и договорились, что будем измерять их качества с помощью среднеквадратичного отклонения, среднеквадратичной ошибки. В следующем видео поговорим о том, как оптимизировать эту ошибку, как настраивать алгоритмы под этот функционал ошибки.

[БЕЗ_ЗВУКА] В этом видео мы поговорим о том, как обучать линейную регрессию, как настраивать ее параметры. В прошлый раз мы договорились, что измерять качество линейной модели мы будем с помощью среднеквадратичного функционала ошибки, который считает квадрат отклонения прогноза линейной модели от истинного ответа и усредняет эти квадраты отклонений по всем объектам обучающей выборки. Здесь параметрами являются веса при признаках. Всего у нас d признаков, весов, значит, тоже d, а значит у нас d неизвестных, d чисел, которые нам нужно настроить. При этом мы считаем, что среди признаков есть константный признак, значения которого на всех объектах равны 1, благодаря этому нам не нужно включать константные члены в нашу формулу. Но прежде чем мы перейдем к оптимизации этого функционала, давайте обсудим, как записать в матричном виде среднеквадратичную ошибку. Начнем мы с матрицы «объекты–признаки». Это матрица, в которой l строк, то есть столько, сколько объектов, и d столбцов, то есть столько, сколько признаков. В i-том j-том элементе этой матрицы записаны значения j-того признака на i-том объекте. Таким образом, мы получаем что в i-той строке этой матрицы записаны все признаки i-того объекта, а в j-том столбце этой матрицы записаны значения j-того признака на всех объектах. Также нам понадобится вектор ответов — это вектор y, i-тый элемент которого равен yi-тому, то есть истинному ответу на i-том объекте обучающей выборки. В этом случае мы можем записать в матричном виде среднеквадратичную ошибку, она будет выглядеть вот так. Обратите внимание, когда мы умножаем матрицу «объекты–признаки» X на вектор весов w, мы получаем вектор размера l, то есть такого размера, сколько у нас всего объектов, и i-тый элемент этого вектора — это и есть прогноз нашей модели, скалярное произведение вектора весов на значение признаков на i-том объекте. Вычитаем из этого вектора вектор y, получаем отклонение прогнозов алгоритма от истинных ответов, и, вычисляя евклидову норму, возводя ее в квадрат и после этого поделив на число объектов, получаем среднеквадратичную ошибку. Это то, что нам нужно минимизировать. Нам эта формула пригодится, например, для реализации на компьютере. Так очень удобно вычислять значение среднеквадратичной ошибки на всей выборке. Можно показать, что если взять градиент от этой функции, приравнять его к нулю, выразить вектор весов через все остальное, то можно получить аналитическое решение задачи минимизации среднеквадратичной ошибки. Оно будет выглядеть вот так. Чтобы найти оптимальный вектор весов, нужно умножить матрицу X транспонированное на X, обратить это произведение, умножить на матрицу X транспонированное и умножить на вектор ответов y. Конечно, очень хорошо, что решение записывается аналитически. В этом случае можно не заниматься оптимизацией, но у аналитического решения есть ряд очень серьезных проблем. Самая главная проблема состоит в том, что вам нужно обращать матрицу X транспонированное на X. Обращение это очень тяжелая операция. Матрица X транспонированное на X имеет размеры d на d, то есть число признаков на число признаков. Обращение такой матрицы требует порядка d в кубе операций, Если у вас тысячи или десятки тысяч признаков, обращение будет занимать очень много времени. Также при этом обращении могут возникнуть численные проблемы, если матрица X транспонированное на X устроена не очень хорошо. Поэтому гораздо более простым и удобным подходом является оптимизационный. Несмотря на то что решение можно записать аналитически, давайте все равно с помощью метода оптимизации искать его, а именно с помощью градиентного спуска. Можно показать, что среднеквадратичная ошибка — это выпуклая и гладкая функция. Из выпуклости следует, что у нее всего 1 минимум, а из гладкости следует, что в каждой ее точке можно посчитать градиент, и поэтому можно использовать градиентный спуск для оптимизации. Давайте подробно обсудим алгоритм градиентного спуска. Начинается он с того, что мы каким-то образом находим начальное приближение для вектора весов w с верхним индексом 0. Его можно искать самыми разными способами. Один из самых простых — это инициализировать все элементы вектора весов нулями. То есть w0... каждая компонента w0 — это ноль. Есть и другие подходы. Например, можно инициализировать случайными и не очень большими числами. Далее в цикле мы повторяем следующие операции. На t-той итерации цикла мы берем приближение с предыдущей итерации, то есть wt − 1, и вычитаем из него вектор градиента в этой точке, умноженный на некоторый коэффициент ηt, который называет шагом. Почему мы именно так изменяем вектор весов? Мы обсуждали в прошлом курсе, что градиент показывает в сторону наискорейшего возрастания функции, а антиградиент, то есть вектор градиента с минусом, показывает в сторону наискорейшего убывания. Таким образом, если мы хотим как можно сильнее уменьшить функционал ошибки Q, нам нужно изменять вектор весов именно в сторону антиградиента, что здесь и происходит. Коэффициент ηt (или шаг) нужен для того, чтобы регулировать, насколько далеко мы шагаем в сторону антиградиента. Дело в том, что оказывается оптимальным шагать не очень сильно, мы увидим с вами это чуть дальше. Эти градиентные шаги повторяются до тех пор, пока не наступит сходимость. Сходимость можно определять по-разному. В нашем случае мы ее определяем как ситуацию, в которой векторы весов от шага к шагу начали меняться не слишком сильно. То есть норма отклонения вектора весов на текущем шаге от вектора весов на предыдущем шаге, должна отличаться не более, чем на ε. В этом случае мы завершаем градиентный спуск. Если же изменение довольно большое, мы продолжаем его. Есть и другие подходы к определению сходимости. Например, можно сравнивать значение функционала ошибки между текущей итерацией и предыдущей, или использовать еще какие-то способы. Итак, мы с вами обсудили, как в матричном виде записать среднеквадратичный функционал ошибки для линейной регрессии, и выяснили, что у него есть аналитическое решение, которое тем не менее обладает рядом проблем, его довольно тяжело вычислить. Поэтому гораздо проще использовать градиентный спуск. Мы с вами обсудили, как он устроен и почему в нем шаг делается именно в сторону антиградиента. В следующем видео мы посмотрим, как выглядит применение градиентного спуска конкретно для задачи линейной регрессии.

[ЗАСТАВКА] В этом видео мы поговорим о том, как применять градиентный спуск для обучения линейной регрессии. И давайте начнем с простого примера, со случая, когда признак всего один. Эта ситуация называется парной регрессией. В этом случае линейная модель выглядит как a от х равняется w 1 умножить на x плюс w 0. То есть мы берем значение нашего единственного признака x, умножаем на некоторый вес, некоторый коэффициент w 1, и прибавляем свободный коэффициент w 0, который также называется сдвигом. Получается, что у нашей модели есть два параметра: w 1 и w 0. Их нужно настраивать. Функционал ошибки возьмем среднеквадратичный, то есть посчитаем квадраты отклонения прогноза модели от истинного ответа и усредним по всем объектам. Давайте рассмотрим, как будет работать в случае с парной регрессией градиентный спуск на примере конкретной выборки. Например, это может быть задача предсказания прибыли магазина в следующем месяце на основе его прибыли в предыдущем месяце. Выборка выглядит вот так. По оси x отложено значение единственного признака, по оси y отложено значение ответа. Если нарисовать функционал качества в осях w 0 и w 1, он будет выглядеть как-то так. То есть это некоторая функция параболического вида, у нее где-то есть минимум. Напомню, градиентный спуск заключается в том, что мы как-то инициализируем вектор весов и дальше до сходимости повторяем градиентный шаг. То есть вычитаем из текущего приближения вектора весов градиент функционала ошибки в этой точке с некоторым коэффициентом в этой точке [INAUDIBLE]. Сходимость наступает, когда вектор весов перестает меняться слишком сильно от одной итерации к другой. Чтобы запустить градиентный спуск, нам нужно вычислить градиент, то есть вектор частных производных функционала ошибки по всем его параметрам. У нас параметра два, w 1 и w 0. Мы не будем вдаваться в математические выкладки, можно показать, что частные производные записываются вот так. Можете проверить дома, что это действительно правда. Итак, чтобы посмотреть, как работает градиентный спуск на нашей выборке, будем рисовать две картинки. На левой картинке мы изображаем пространство параметров. По оси x отложен параметр w 0, по оси y параметр — w 1. Точка в этом пространстве обозначает конкретную модель. Выбирая конкретные места, мы получаем конкретную линейную регрессию. На правом графике мы изображаем нашу выборку в осях «признак — ответ» и алгоритм, который настроен, который соответствует точке на левом графике. Итак, если мы возьмем начальное приближение случайно, возьмем в его качестве некоторую точку в окрестности нуля, то получим некоторый не очень хороший алгоритм. Он совершенно не соответствует тому, какая зависимость есть в нашей выборке. Сделаем первый градиентный шаг. Он сдвинется вверх и немножко вправо, и мы видим, что после даже первого градиентного шага алгоритм гораздо больше соответствует истинной зависимости. Направление нашей прямой уже более или менее угадывает общую тенденцию в данных. Сделаем еще несколько градиентных шагов. Наша точка в пространстве параметра будет двигаться в том же направлении, а наша прямая, наш алгоритм, будет все ближе и ближе к нашему облаку точек, к нашему облаку объектов. После того, как мы сделаем 100 итераций, наша точка в пространстве параметров немножко завернет, а сам алгоритм будет уже очень неплохо апроксимировать, неплохо приближать данные. Видно, что модель после сотой итерации уже довольно неплохая. После того, как мы сделаем тысячу итераций, точка в пространстве параметров, то есть набор параметров, сдвинется еще сильнее в том же направлении и алгоритм станет еще лучше описывать данные. После двух тысяч итераций мало что изменится. Видно, что уже наступила сходимость, и мы получили довольно неплохой алгоритм, который соответствует зависимости между признаком и ответом. При этом, если посмотреть на график того, как менялось значение функционала ошибки по мере итерации, мы увидим, что это изменение было монотонным, начиналось оно в довольно высокой точки, затем уменьшалось, и в какой-то момент вышло на асимптоту. Очень важно в градиентном спуске понимать, как выбрать размер шага [INAUDIBLE]. Давайте немножко поговорим об этом. Вообще, нет никаких конкретных правил, конкретных рекомендаций, каким именно выбрать шаг для данной задачи. Выбор шага это искусство, но при этом есть некоторые соображения, которые могут помочь. Если взять длину шага слишком маленькой, то градиентный спуск будет очень не спеша, но верно шагать в сторону минимума, как на этой картинке. Видно, что шаги по мере приближения к минимуму становятся все более и более маленькими, нужно довольно много итераций, чтобы градиентный спуск сошелся с таким размером шага. Если же взять размер шага очень большим, то, конечно, градиент будет показывать в сторону минимума, но поскольку мы шагаем по нему слишком далеко, есть риск, что мы будем перепрыгивать точку минимума, и, более того, есть риск расхождения, то есть градиентный спуск будет уходить все дальше и дальше от точки минимума, что и происходит на этой картинке. Можно заметить, что если мы еще находимся очень далеко от точки минимума, то нет ничего плохого в том, чтобы делать длинные шаги, чтобы далеко шагать в сторону антиградиента. Если же мы уже сделали много итераций градиентного спуска и есть подозрения, что находимся близко к точке минимума, то шаги должны быть аккуратными, чтобы мы не перескочили минимум, чтобы мы не начали шагать не в ту сторону. Таким образом, возникает идея делать шаг переменным. Чем больше итераций мы сделали, тем меньше должен быть размер шага. Например, можно в этом случае для размера шага [INAUDIBLE] взять формулу k поделить на t, где t это номер текущей итерации, а k — некоторая константа. видно, что чем больше число итераций, тем меньше будет шаг, а константу k нужно как-то подбирать в зависимости от задачи, например, пробовать разные значения и посмотреть, когда сходимость есть, а когда нет. В случае с многомерной линейной регрессией подход будет тот же самый, нужно только по-другому расчитать градиент. Функционал в случае с многомерной линейной регрессией, как мы уже выяснили, записывается в матричном виде. Это будет норма, квадрат нормы отклонения вектора X w, то есть вектора прогнозов, от вектора y, то есть вектора истинных ответов. И потом еще это делится на l, на размер выборки. Нужно минимизировать этот функционал ошибки. Можно показать, что градиент этого функционала в точке w вычисляется по вот такой формуле. Нужно взять матрицу X, то есть матрицу «объекты — признаки», транспонировать ее, умножить на вектор отклонений X w — y, то есть на вектор ошибок алгоритма на каждом объекте обучения, и потом умножить все это на скаляр 2 поделить на l. Именно вдоль этого вектора нужно шагать на каждом шаге градиентного спуска. Итак, мы с вами обсудили, как будет выглядеть градиентный спуск для парной, то есть одномерной, и многомерной линейной регрессии, обсудили важность выбора шага. А в следующем видео мы поговорим о модификации градиентного спуска, стохастическом градиентном спуске, который хорошо подходит для настройки линейной регрессии.

В этом видео мы поговорим о стохастическом градиентном спуске, который особенно хорошо подходит для обучения линейных моделей. Итак, мы уже знаем, как работает обычный градиентный спуск. Мы начинаем с некоторой инициализации вектора весов, например, нулями или другими значениями, и дальше повторяем в цикле градиентные шаги. Градиентный шаг состоит в том, что мы вычитаем из текущего приближения вектора весов w (t − 1) вектор градиента, с некоторым коэффициентом ηt. Повторяя эти шаги до тех пор, пока не наступит сходимость, то есть пока вектор весов не начнет меняться слишком слабо. Давайте внимательнее посмотрим на то, как устроен градиентный шаг. Вектор градиента в векторной форме выглядит вот так. Если расписать j-ю компоненту этого вектора, то получим следующую формулу. В ней стоит суммирование по всем объектам обучающей выборки, по i от 1 до l, где мы суммируем следующие слагаемые, которые, по сути, показывают, как надо изменить j-й вес, чтобы как можно сильнее улучшить качество на объекте xi. А вся сумма показывает, как нужно изменить j-й вес, чтобы улучшить качество на всей обучающей выборке. Собственно, в этой формуле и состоит один из главных недостатков градиентного спуска. Здесь стоит суммирование по всей обучающей выборке. Если выборка большая, то один градиентный шаг будет занимать слишком много времени. Так мы приходим к модификации градиентного спуска, который называется стохастическим градиентным спуском. Его главная особенность в том, что на одной итерации мы вычитаем не вектор градиента, вычисленный по всей выборке, а делаем следующее. Мы случайно выбираем один объект из обучающей выборки, например, xi, и дальше вычисляем градиент функционала только на этом объекте, то есть градиент только одного слагаемого в функционале ошибки, и вычитаем именно этот градиент из текущего приближения вектора весов. Очень показательно посмотреть на график сходимости для градиентного спуска и стохастического градиентного спуска. В градиентном спуске мы стараемся на каждую итерацию уменьшить ошибку на всей выборке, и поэтому график получается гладким. По мере увеличения числа итераций ошибка уменьшается монотонно, поскольку мы уменьшаем ее на всей выборке. В случае же со стохастическим градиентным спуском, мы уменьшаем на каждую итерацию ошибку только на одном объекте, но при этом мы можем увеличить ее на другом объекте, поэтому график получается пилообразный. Мы на какой-то итерации можем увеличивать ошибку, но при этом в целом он уменьшается. И рано или поздно мы выходим на довольно неплохое качество, на довольно низкую ошибку. Итак, у стохастического градиентного спуска есть много преимуществ. Во-первых, в нем гораздо быстрее вычисляется один шаг, один градиентный шаг. Так же ему не требуется хранение всей обучающей выборки в памяти. Мы можем считывать по одному объекту из выборки и для каждого следующего объекта делать градиентный шаг. За счет этого стохастический градиентный спуск позволяет обучать линейные модели на очень больших выборках, которые не помещаются в память компьютера. Так же он подходит для онлайн обучения, ситуации, в которой мы получаем за каждый шаг только один объект, и должны как-то изменить модель, чтобы учесть этот объект. Итак, мы обсудили, что градиентный спуск требует суммирование по всем объектам обучающей выборки на каждой итерации, что может быть проблемой, если выборка большая. Стохастический градиентный спуск решает эту проблему, используя лишь один объект обучающей выборки на каждой своей итерации. При этом он имеет много преимуществ и позволяет, например, обучать линейные модели на очень больших выборках, которые не помещаются в память компьютера. В следующем видео мы поговорим о том, как применять линейные модели в задачах классификации.

[ЗАСТАВКА] В этом видео мы поговорим про линейную классификацию: то есть как применять линейные модели к задачам классификации. И будем говорить о самом простом виде классификации — бинарной классификации, где ответы принимают значения из множества −1 и +1, то есть всего 2 возможных значения. Как вы помните, чтобы работать с той или иной моделью, нужно уметь отвечать на 3 вопроса: первый — это как мы измеряем качество, как устроен функционал ошибки; второй — как устроено семейство алгоритмов, то есть то множество алгоритмов, из которого мы выбираем наилучший с точки зрения функционала; и третий — это как мы обучаем алгоритм, то есть выбираем лучший из семейства с точки зрения функционала ошибки. В этом видео мы поговорим о семействе алгоритмов, а в следующем — о том, как измерять их ошибки и как обучать эти алгоритмы. Мы уже говорили про линейную регрессию. Линейные классификаторы устроены очень похоже. В линейной регрессии мы складывали все признаки с весами, при этом вес при j-том признаке обозначали как wj-тое, и после этого суммирования проявляли еще свободный коэффициент w0, который также называется сдвигом. В случае с регрессией нас эта формула полностью устраивала, поскольку она принимала вещественные значения, теперь же алгоритм должен возвращать бинарные значения: −1 или +1. Чтобы добиться этого, можно просто взять знак от этого выражения, именно это и будет видом линейного классификатора. Заметим, что формула не очень однородная, в ней есть свободный коэффициент, чтобы убрать его, давайте просто добавим еще один признак выборки, константный признак, который на каждом объекте принимает значение 1, единичный признак. В этом случае свободный коэффициент уже не нужен, его роль будет выполнять вес при этом константном признаке, и формула приобретает такое значение. Заметим, что по сути такая взвешенная сумма признаков — это скалярное произведение вектора весов на вектор признаков, и значит итоговый вид линейного классификатора — это знак скалярного произведения w на x, этой формулой мы и будем пользоваться дальше. Давайте разберемся, какой геометрический смысл у линейного классификатора. В случае с линейной регрессией мы обсуждали, что это по сути приближение зависимости ответа от признаков с помощью прямой или гиперплоскости. Что же это будет в случае с классификацией? Для этого давайте запишем то, что стоит под функцией знака — скалярное произведение w на x, и приравняем к 0, получим такое уравнение. Давайте нарисуем вектор весов w и будем искать все такие точки x, которые удовлетворяют этому уравнению, то есть все такие точки, для которых скалярное произведение этой точки, этого вектора на w = 0. Равенство нулю скалярного произведения означает, что угол между этими векторами = 90 градусов, то есть что они перпендикулярны. Получается, что точки, удовлетворяющие этому уравнению — это все векторы, ортогональные вектору весов. Из аналитической геометрии известно, что это множество представляет собой плоскость. Получается, что уравнение задает плоскость, более того, с одной стороны от этой плоскости значение скалярного произведения будет больше 0, а с другой стороны от плоскости — меньше 0. Получается, что линейный классификатор проводит гиперплоскость в пространстве признаков, и все объекты, которые с одной стороны, относят к классу +1, а те, которые с другой стороны — к классу −1. В случае с двумя признаками это выглядит как-то так: у нас есть выборка, мы проводим разделяющую прямую, и все объекты, которые с одной стороны, относим к классу −1, все, которые с другой стороны, относим к классу +1. Заметим, что линейные классификаторы вычисляют значение скалярного произведения, которое имеет вещественное значение, а затем берет только знак, отбрасывая часть информации. При этом, наверное, само значение скалярного произведения тоже имеет смысл. Действительно, оказывается, что если мы возьмем модуль этого скалярного произведения и отнормируем его, то есть поделим на норму вектора весов, то это выражение будет равно расстоянию от точки x до гиперплоскости, которая задается вектором нормали, вектором весов w. Получается, что линейный классификатор сначала измеряет расстояние от точки до гиперплоскости со знаком и дальше смотрит лишь на знак, то есть на то, с какой стороны от гиперплоскости лежит эта точка. Так мы приходим к очень важному понятию в линейной классификации — к понятию отступа. Отступом называется выражение вида: скалярное произведение вектора весов на объект, умноженное на истинный ответ на этом объекте, который, напомню, равен +1 и −1. Какой смысл у этого выражения? Давайте обратим внимание: если скалярное произведение имеет положительный знак и истинный ответ равен +1 — это верная классификация и произведение скалярного произведения на истинный ответ будет больше 0. Если скалярное произведение меньше 0, и истинный ответ равен −1, то это тоже будет правильная классификация, и их произведение снова будет больше 0. Если же знак ответа и знак скалярного произведения противоположные, то классификация будет ошибочной и знак отступа будет меньше 0. Получается, что отступ — это некоторая величина, которая характеризует корректность ответа. Если отступ больше 0, то алгоритм дает корректный ответ, если отступ меньше 0 — алгоритм дает некорректный ответ. При этом само абсолютное значение отступа свидетельствует о расстоянии от точки до разделяющей гиперплоскости. Принято считать, что если точка находится рядом с разделяющей гиперплоскостью, то классификация неуверенная, наш алгоритм сомневается, к какому классу относить ее, если же точка находится далеко от разделяющей гиперплоскости, то классификация уверенная, при этом, если алгоритм прав, то он просто уверен в этом, все хорошо, если же алгоритм ошибается, и при этом отступ по модулю очень большой, это означает, что алгоритм очень сильно ошибается в классификации этого объекта, возможно, этот объект является выбросом и никак не вписывается в нашу модель, или же алгоритм не подходит для решения этой задачи. Итак, мы с вами обсудили, что линейный классификатор по сути строит гиперплоскость в пространстве признаков и с ее помощью разделяет 2 класса. Также мы ввели понятие отступа, знак которого позволяет понять — корректный ответ дает классификатор или нет на этом объекте, а абсолютное значение отступа говорит об уверенности классификатора в этом объекте. В следующем видео мы поговорим о том, как измерять качества, как измерять ошибку линейного классификатора и как его настраивать.

В этом видео мы поговорим о том, как измерять ошибку в задачах классификации и как обучать линейные классификаторы. В прошлый раз мы выяснили, что в задачах бинарной классификации линейный классификатор строит гиперплоскость, которая пытается разделить два класса. При этом те объекты, которые оказываются слева от нее, она относит к одному классу, а те, которые справа от нее, — к другому классу. В случае с регрессией измерить качество было довольно просто. Прогноз и ответ — это вещественные числа. Их бесконечно много, и мы требовали, чтобы они были как можно ближе друг к другу. При этом есть много способов измерить сходство двух вещественных чисел. Это квадратичное отклонение или абсолютное отклонение. Можно придумать и другие подходы к измерению сходства чисел. В случае с классификацией возникает вполне естественный подход. У нас ответов конечное число. Соответственно, можем требовать точного совпадения класса, предсказанного алгоритмом A(Xi), и истинного класса Yi. Соответственно, функционал, который мы получаем, — это доля неправильных ответов, доля ошибочных ответов. Он записывается вот так. Это сумма индикаторов того, что предсказанный класс A(Xi) не совпал с истинным классом Yi. И все это усредняется по всей обучающей выборке. Давайте вспомним, что в прошлый раз мы изучали понятие отступа, который позволяет понять, ошибается или нет алгоритм на данном объекте. Отступ на этом объекте задается как произведение истинного ответа Yi на скалярное произведение вектора весов W на вектор признаков Xi. Если отступ меньше нуля, то алгоритм ошибается на данном объекте. Соответственно, наш функционал долю неправильных ответов можно переписать, как среднее значение индикатора того, что отступ на (i) объекте меньше нуля. Давайте посмотрим, как выглядит функция, которая стоит под знаком суммы. Индикатор того, что отступ меньше нуля. По оси "Икс" отложим отступ Mi, отступ на этом объекте, по оси "Игрек" — значение функции потерь, значение индикатора. Мы видим, что эта функция пороговая. Она равна единице, если отступ меньше нуля, и нулю, если отступ больше нуля. Эта функция является разрывной, у нее разрыв в нуле. Из-за этого ее нельзя оптимизировать градиентными методами. Конечно, можно воспользоваться методами негладкой оптимизации, которые мы изучали в прошлом курсе, но они довольно сложные в реализации и не дают гарантии сходимости к локальному оптимуму. Поэтому давайте попробуем как-то изменить задачу, чтобы она стала гладкой. Для этого возьмем индикатор того, что отступ меньше нуля, нашу пороговую функцию потерь. Оценим сверху этот индикатор некоторой гладкой функцией "L с волной", которая также зависит от отступа M. То есть это должна быть такая функция, которая больше или равна единице, если отступ отрицательный, и больше или равна нуля, если отступ положительный. Далее, используя данную верхнюю оценку "L с волной", мы можем оценить весь функционал ошибки, весь функционал доли неверных ответов. Верхняя оценка на этот функционал будет выглядеть так: это среднее значение нашей гладкой функции потерь "L с волной" по всей обучающей выборке. Обратите внимание: в этом случае мы будем минимизировать не долю неправильных ответов, а среднее значение нашей гладкой функции потерь "L с волной". При этом мы надеемся, что если мы приведем к нулю данное среднее значение гладкой функции, то при этом прижмется к нулю и то, что она оценивает сверху, прижмется к нулю доля неправильных ответов. Но при этом, конечно же, нет никаких гарантий, что, минимизируя верхнюю оценку, мы будем точно минимизировать и то, что она оценивает, то есть долю неправильных ответов. Но при этом мы получаем очень удобную, хорошую гладкую задачу минимизации. Давайте рассмотрим несколько примеров таких гладких оценок. Например, это может быть логистическая функция потерь L(M), которая записывается как логарифм, под которым стоит единица плюс экспонента от минус отступа. Она используется в логистической регрессии, которую вы будете изучать позже в нашем курсе. Другие примеры — это экспоненциальная функция потерь или кусочно-линейная, которые используются в методе опорных векторов. Вот графики этих функций. Видно, что они все, действительно, оценивают сверху пороговую функцию потерь. При этом все они делают это по-разному. Какие-то имеют экспоненциальный рост, какие-то более медленный темп роста при уменьшении отступа. Давайте возьмем для примера логистическую функцию потерь и запишем функционал для нее. Он будет выглядеть вот так. Мы усредняем значение данной функции. Этот функционал будет гладким. Чтобы понять, как его оптимизировать, давайте поставим вместо отступа его определение. То есть Yi истинный ответ, умноженный на скалярное произведение вектора весов на вектор признаков Xi. Видно, что мы получили гладкий, хороший функционал, у которого легко посчитать градиенты по вектору весов W и осуществлять градиентный спуск или пользоваться любым другим вашим любимым методом оптимизации. Итак, что мы делаем при решении задачи классификации, при обучении линейного классификатора? Мы оцениваем сверху долю неправильных ответов, наш базовый функционал ошибки, с помощью некоторой гладкой функции потерь, например, логистической. И далее минимизируем эту гладкую функцию потерь с помощью любого метода оптимизации — стохастического градиентного спуска, градиентного спуска или чего-то еще. И при этом надеемся, что минимизации данного функционала будет также приводить к минимизации доли неправильных ответов. Кстати, обратите внимание: в случае с логистической функцией потерь, даже если все отступы стали больше нуля, все равно алгоритм градиентной оптимизации будет стремиться увеличивать отступы, то есть увеличивать уверенность классификатора в этих ответах. Это довольно хорошее свойство. Итак, мы с вами выяснили, что в задачах классификации есть вполне логичный функционал потерь — доля ошибок, при этом он негладкий, и нужно его оценивать сверху. И далее классификатор настраивается путем минимизации гладкой аппроксимации функционала ошибки. На этом наш урок про линейные методы заканчивается, и заканчивается первый модуль курса. А следующий модуль мы начнем с того, что обсудим проблему переобучения и методы борьбы с ней.


[ЗАСТАВКА] В машинном обучении есть два направления, в которых часто звучит слово «байесовский». Это байесовский классификатор, в том числе наивный байесовский классификатор и всё, что с ним связано, и байесовский вывод. В этом уроке мы будем говорить про первое, то есть про байесовскую классификацию. Мы оттолкнемся от практической задачи построения спам-фильтра, для которой изначально и использовался наивный байес. Сейчас, наверное, никому уже не придет в голову использовать наивный байесовский классификатор в этой задаче, уж скорее линейный классификатор на каких-нибудь хорошо придуманных признаках или композицию алгоритмов. Кроме того, наивный байес — явно не самый крутой алгоритм в плане качества работы, однако, он очень прост в реализации и достаточно быстро работает. Мы введем байесовский классификатор в сравнительно общем виде и увидим, что суть байесовского подхода к классификации заключается в том, чтобы оценить распределение классов и, глядя на эти распределения, классифицировать объект по его признакам. Это означает, что нужно уметь не только принимать разумное решение, зная распределение классов, но и уметь восстанавливать эти распределения. Вы узнаете, что существует более одного подхода к этой задаче, но самый частый из них — это использовать наивного байеса с параметрическим восстановлением одномерных распределений, поэтому остальные подходы мы рассмотрим обзорно. Вас, быть может, интересует, зачем знакомиться с байесовским классификатором, если он не дает достаточно высокого качества решения задачи классификации? Дело в том, что байесовский подход дает нам достаточно общий взгляд на задачи регрессии и классификации. Это взгляд с позиции теории вероятности, который позволяет лучше понять, что же происходит при решении задач обучения с учителем, ну то есть обучения на размеченных данных. Об этом мы поговорим в конце этого урока.

В этом видео мы начнем знакомиться с наивным байесовским классификатором, а оттолкнемся мы от практической задачи фильтрации спама. Фильтр спама – это просто классификатор на два класса: спам и не спам. Первые спам-фильтры использовали наивный байесовский классификатор, поэтому мы придем к нему постепенно, оттолкнувшись именно от этой задачи. Давайте посмотрим на примеры спамных писем. Отчетливо видно, что некоторые слова особенно часто встречаются в спаме. Отсюда возникает идея: давайте для каждого слова из коллекции текстов посчитаем количество писем с этим словом в спаме и количество писем с этим словом не в спаме и с помощью этих чисел оценим вероятность появления этого слова в спамном письме и в неспамном письме. Теперь, когда нам нужно для нового текста понять, является этот текст спамным или неспамным, мы можем просто оценить вероятность его появления в классе «спам» и вероятность его появления в классе «не спам» просто как произведение вероятностей появления всех слов, которые входят в этот текст. Конечно же, оценить эту вероятность просто как произведение можно лишь в том случае, когда вхождение разных слов в текст – это независимые события. Конечно, это очень наивное предположение, но с какой-то точностью оно выполняется, и можно попробовать им воспользоваться. Именно это наивное предположение и дает название классификатору. Теперь остается выбрать тот класс, для которого вероятность порождения данного текста больше. Это будет почти правильный алгоритм. На самом деле, мы же уже знаем текст, и нам нужно оценить вероятность класса при условии известного текста, а не наоборот, поэтому нам нужно перейти именно к этой вероятности, и классификатор должен максимизировать именно эту вероятность. Но как же эту вероятность оценить? Конечно же, на помощь нам приходит теорема Байеса. Так как априорная вероятность возникновения текста одинакова для всех классов, то она пропадет из-под знака максимума, таким образом, доработать наш классификатор окажется очень просто. Нужно лишь домножить те вероятности, которые мы уже оценивали, на априорные вероятности классов. Итак, на стадии обучения нам нужно оценить вероятности вхождения слов в класс «спам» и в класс «не спам». На стадии применения классификатора к текстам нам нужно оценить вероятность порождения этого текста просто как произведение вероятностей для каждого слова, входящего в текст, и выбрать тот класс, для которого вероятность его порождения, домноженная на априорную вероятность класса, будет максимальна. Что мы еще не учли? Мы работали только с текстом писем, но, наверное, заголовки и адрес отправителя тоже что-то значат. Кроме того, мы не учли следующую ситуацию. Допустим, какое-то слово никогда не встречалось в одном из классов. Тогда, как только мы его увидим в тексте, вероятность для этого класса сразу занулится, ведь там же произведение вероятностей, а вероятность конкретно для этого слова равна нулю. Может быть, это слишком поспешный вывод. Быть может, другие слова более значимы в этом случае. Кроме того, может быть еще более плохая ситуация. Допустим, у нас есть два слова, которые не входили в один класс и в другой класс. Тогда получится, что если оба эти слова встретились в тексте, вероятность одного класса и вероятность другого класса занулятся сразу обе, и мы не сможем выбрать. Эти вопросы мы еще обсудим в дальнейшем. Итак, мы познакомились с тем, как решали задачу фильтрации спама на заре развития Интернета. Оттолкнувшись от этой задачи, мы постепенно пришли к идее наивного байесовского классификатора. Несмотря на то, что метод классификации достаточно древний, он имеет свои плюсы: он прост в реализации и быстро работает. В следующем видео мы рассмотрим наивный байесовский классификатор в более общем виде, а также разберемся, как его можно применить для других задач классификации.

Давайте подробнее познакомимся с Байесовским классификатором. Итак, в задаче классификации нам нужно по известному вектору признаков x определить класс к которому принадлежит объект. Байесовский классификатор пытается выбирать такой класс, для которого максимальна вероятность класса при условии x. Как мы уже знаем, из теоремы Байеса следует, что такая стратегия — то же самое, что выбирать тот класс, для которого максимальна вероятность вектора признаков x при условии класса, домноженная на априорную вероятность класса. Как это можно представить? Ну, например, если априорные вероятности будут одинаковы у классов, это просто означает, что мы выбираем тот класс, плотность которого больше в точке x. Зачем же нам понадобилась теорема Байеса? Вероятность класса при условии x, если ее оценивать «в лоб», фактически оценивается долей класса среди объектов с набором признаков x. Но в то же время признаки очень часто вещественные, но или их просто довольно много, поэтому всевозможных комбинаций признаков существует просто безумно много. Что это означает? Это означает, что, наверное, вряд ли в обучающей выборке для каждой возможной комбинации признаков у нас будет сотня-другая примеров. Значит и оценивать «в лоб» у нас не получится. Здесь нас и спасает теорема Байеса. С помощью нее мы переходим к вероятностям x при условии класса. Если координаты вектора x вещественные, то это будет плотностью распределения x при условии класса. Именно эту величину и можно оценивать по обучающей выборке. Оценив ее на этапе обучения, дальше мы можем просто применять наш классификатор. Однако здесь мы сталкиваемся с проблемой нехватки данных. Ну, например, нужно нам оценить вероятность x при условии класса, а в обучающей выборке 100 тысяч точек, а вектор x имеет размерность 10 тысяч. Как же быть, ведь 100 тысяч точек в пространстве размерности 10 тысяч это очень мало. Ну подумайте, даже если бы вектор x был бинарным, то у него было бы 2 в степени 10 тысяч различных значений, но это намного больше, чем 100 тысяч точек. Поэтому восстановить плотность как функцию от многих переменных достаточно затруднительно. Итак, Байесовский классификатор — это классификатор, принимающий решения по очень простому принципу. Он выбирает тот класс, для которого максимальна вероятность признаков при условии этого класса, домноженная на априорную вероятность этого класса. Чтобы обучить Байесовский классификатор, нам нужно восстановить эти вероятности. Оценивать вероятность признаков при условии класса как функцию многих переменных может быть довольно затруднительно. Нам может существенно не хватать данных. В следующем видео мы обсудим, как же можно преодолевать эту проблему.

[БЕЗ_ЗВУКА] Начнем разбираться с задачей восстановления распределений. Итак, в прошлом видео мы обнаружили проблему нехватки данных. Ну, например, если у нас есть выборка из 100 тысяч точек, а признаков 10 тысяч, то нам откровенно не хватит этих точек для восстановления многомерного распределения внутри каждого класса, поэтому нужно что-то придумать. Первое решение достаточно простое: можно просто свести задачу восстановления плотности внутри класса от оценки функции многих переменных к оценке функции одной переменной. Например, это можно сделать с помощью наивного байесовского классификатора. Наивный байесовский классификатор — это байесовский классификатор, то есть классификатор, принимающий решение по принципу: выбрать класс, для которого максимальна вероятность P(x) при условии класса умножить на априорную вероятность класса, с «наивной» гипотезой. «Наивная» гипотеза заключается в том, что мы считаем, что плотность класса расписывается в произведение плотностей по каждому признаку. Понятно, что эта гипотеза выполняется только если признаки независимы, а это, как правило, неправда, но с какой-то степенью точности так предположить можно. Тогда для использования наивного байесовского классификатора нам остается лишь восстановить априорные вероятности классов и распределение каждого признака внутри класса. Ну первое сделать совершенно несложно. Априорную вероятность можно взять либо из каких-то внешних сведений, либо оценить как долю объектов этого класса в обучающей выборке, ну если, конечно, в ней эта доля примерно такая же, как в жизни. Если признаки бинарные, то оценить плотность признака при условии класса тоже достаточно просто. Ну даже здесь будет не плотность, а именно вероятность принять значение 1 и вероятность принять значение 0. И первую вероятность мы можем просто оценить как долю объектов в данном классе, у которых значение этого признака 1, а вторую — как долю объектов в данном классе, у которых значение этого признака 0. Рассмотрим пример: классификацию текстов. Классификация текстов можно по обучающей выборке составить словарь из слов и в качестве признаков использовать вхождение слов из словаря в текст: 1 — если входит, 0 — если не входит. Распределение в каждом классе можно восстановить так же, как было предложено сейчас для бинарных признаков, но просто доля таких случае в классе. Теперь можно применить наивный байесовский классификатор и решить задачу классификации текстов. Обратите внимание, получится не совсем то же самое, что было в примере с фильтром спама. Попробуйте разобраться, почему. Если значение признака никогда не встречалось в классе, то вероятность такого значения признака будет оценена нулем. Так как в наивном байесовском классификаторе мы берем произведение вероятностей, это приведет к занулению всего этого произведения. Один из возможных выходов из этой ситуации — это сглаживание вероятности. Например, его можно сделать следующим образом: можно в числителе и в знаменателе дроби, которой мы оцениваем вероятность, добавить некоторые константы таким образом, чтобы в сумме вероятности по-прежнему давали единицу. Ну а сами эти константы можно выбрать так, чтобы в отсутствии данных получалась какая-то определенная вероятность, например 1/2 или 1 поделить на количество классов, либо подобрать эти константы таким образом, чтобы качество алгоритма получалось наибольшим. Итак, проблема нехватки данных для восстановления многомерного распределения может решаться использованием наивного байесовского классификатора. В этом случае задача будет сведена к восстановлению N одномерных распределений. В случае бинарных признаков распределение можно восстанавливать простыми частотными оценками, и классификатор получается очень похожим на наш первый пример со спам-фильтром. В следующем видео мы обсудим случаи других признаков и другие возможные решения проблемы нехватки данных.

[БЕЗ_ЗВУКА] Продолжим развивать тему «Восстановление распределений». Мы оттолкнулись от проблемы нехватки данных и уже выяснили, что можно решать ее с помощью наивного байесовского классификатора, сводя задачу восстановления многомерной плотности к задаче восстановления многих одномерных плотностей. В предыдущем видео мы также рассмотрели случай бинарных признаков, знакомый нам по примеру со спам-фильтром. Но вот какая беда — не все признаки бинарные, бывают признаки, которые принимают больше двух значений, бывают вообще вещественные признаки, тогда наши формулы для восстановления вероятности уже не подойдут. Мы можем предположить, что распределение признаков похоже на какое-то стандартное — пуассоновское, экспоненциальное, нормальное. И попробовать восстановить его. В этом заключается метод параметрического восстановления распределений. Ну, действительно, нормальное распределение зависит всего от двух параметров: матожидания и дисперсии. Ну давайте возьмем, например, оценки максимального правдоподобия для этих параметров и с их помощью оценим параметры по обучающей выборке. Другой пример: распределение Бернулли. У этого распределения вообще один параметр: вероятность того, что случайная величина принимает значение 1. Этот параметр можно оценить просто долей случаев, в которых случайная величина равнялась 1. Получаем, что рассмотренные нами ранее оценки для бинарных признаков — это просто частный случай параметрического восстановления плотности, если рассматривать распределение Бернулли. Как можно выбрать распределение? Ну, если вы решаете задачу, связанную с текстами или какими-то другими разряженными дискретными признаками, то хорошо подходит мультиномиальное распределение. Если у вас непрерывные признаки с небольшим разбросом, то подходит нормальное распределение. Если у вас непрерывные признаки, но с выбросами, то можно попробовать распределение более «размазанное», нежели нормальное. При этом мы можем решать проблему с нехваткой данных не только с помощью наивного байесовского классификатора, мы можем развить тему параметрической оценки распределений и восстанавливать многомерное распределение, но искать решение действительно в каком-то узком классе, в котором решение будет определяться небольшим набором параметров. Ну, например, можно принять гипотезу о том, что распределение нормальное, и оценивать по выборке параметры многомерного нормального распределения. Ну, то есть вектор средних и матрицу ковариаций. При оценке многомерного распределения возникает все же больше параметров, чем в «наивном» подходе. Для нормального распределения, например, это будет n средних и n дисперсий в «наивном» подходе против вектора средних размерности n и матрицы ковариаций n х n в случае многомерного распределения. Оценка каких-то параметров может получиться неправильной из-за нехватки данных. Часто возникают различные неустойчивые операции. Ну, например, обращение матриц, которые почти вырождены. Другой подход заключается в том, чтобы оценивать распределение не в точке, а в ее окрестности, таким образом набирая больше примеров. Те примеры, которые ближе к точке, можно оценивать с большим весом, а те, которые дальше — с меньшим. Такой подход фактически представляет собой построение некоторой гистограммы и сглаживание ее. Мы поговорим об этом подробнее в дальнейшем. Проблема нехватки данных для восстановления распределения может решаться несколькими способами. Можно воспользоваться наивным байесовским классификатором и оценивать одномерные распределения. Можно зафиксировать класс, в котором мы будем искать наше распределение, то есть применить метод параметрического восстановления распределения. Можно использовать непараметрическую оценку плотности. Подробнее о восстановлении распределений мы поговорим в курсе «Поиск структуры в данных».

[ЗАСТАВКА] В этом видео мы немного по-другому посмотрим на байесовскую классификацию, а также обобщим всё на случай регрессии. Итак, байесовский классификатор выбирает класс таким образом, чтобы было максимальным произведение априорной вероятности класса на вероятность x при условии класса. Можно попробовать применить ту же самую формулу для случая регрессии. Но понятно, что затея не очень хороша, ну хотя бы потому, что вряд ли у нас получится восстановить распределение P(x|y). Действительно, y теперь вещественный и принимает очень много возможных значений. Если сделать шаг назад и попытаться максимизировать P(y|x), то это выглядит тоже странно, так как в этом случае мы просто смотрим на плотность y при условии x и пытаемся выбрать такой y, в котором у функции плотности максимум. Не очевидно, что это будет самым хорошим решением задачи регрессии. Кроме того, нам может захотеться по-разному штрафовать наш алгоритм за разные ошибки. Ну например, представьте, что вы решаете задачу классификации, пытаясь предсказать места, где будет найдено месторождение нефти. То есть у вас есть два класса: «есть нефть» и «нет нефти». И понятно, что в случае, когда нефти нет, спрогнозировать, что она есть — это более критичная ошибка, потому что бурение скважины очень дорого стоит и занимает довольно много времени. В случае регрессии штрафы возникают еще более естественно, потому что в этой задаче мы вообще редко угадываем правильный ответ. Наша задача — не угадать его, а минимально отклониться от него. Ну например, для этого часто используются квадратичные потери или сумма модулей отклонения от правильных ответов. Становится понятно, что нам нужен какой-то более общий подход. Пусть для объекта x мы делаем прогноз a(x). Неважно, у нас задача классификации или регрессии — будем рассматривать общий случай. Если правильный ответ на этом объекте y, обозначим величину ошибки алгоритма L(y, a(x)). Функцию можно задавать по-разному, в зависимости от задачи классификации или регрессии и в зависимости от ваших пожеланий по свойствам алгоритма. Например, в самом простом случае в задаче классификации можно использовать L(y, a(x)) просто равную индикатору того, что y не совпадает с a(x). Это всё приведет нас к уже знакомому нам классификатору, но это мы обсудим позднее. Для регрессии можно использовать функцию (y − a(x))². Рассмотрим так называемый функционал риска. Это просто матожидание наших потерь при условии известного x и в ситуации, когда алгоритм отвечает a(x). Можно просто строить ответы алгоритма таким образом, чтобы минимизировать ожидаемые потери. Распишем это для случая классификации. Матожидание расписывается в сумму возможных значений потерь с некоторыми весами. В качестве весов выступают вероятности P(y|x). Отсюда мы получаем явное выражение для классификатора через функцию потерь и вероятности. Такой классификатор называется оптимальным байесовским классификатором, потому что он минимизирует ожидаемые потери. Реальный классификатор, конечно, не будет оптимальным из-за того, что мы используем не настоящие вероятности и плотности, а наши оценки. Для задачи регрессии всё выглядит абсолютно так же с точностью до замены суммы на интеграл. Но обычно это всё используется скорее не для того, чтобы правда решать задачу регрессии, а для того чтобы проанализировать разные функции потерь, о чем мы еще поговорим позднее. Теперь попробуем посмотреть на то, насколько хорошо работает алгоритм не на конкретном x с конкретным ответом a(x), а в среднем. Ну то есть рассмотрим функционал, называемый функционалом среднего риска, который равен матожиданию функционала риска по всем x. Для определенности дальше будем рассматривать случай классификации и дискретных признаков. Остальные варианты (ну то есть вариант с непрерывными признаками или вариант с регрессией) будут абсолютно аналогичны с точностью до замены некоторых сумм на интегралы. В этой ситуации функционал среднего риска просто представляется взвешенной суммой возможных значений функционала риска, где в качестве весов выступают вероятности P(x). Нетрудно заметить, что эта сумма легко оценивается снизу, если вместо значений R(a(x), x) подставить минимальное возможное значение на данном x. И вот какое замечательное совпадение: оптимальный байесовский классификатор как раз минимизирует функционал риска. Это означает, что данная нижняя оценка достигается, и достигается она тогда, когда классификатор оптимальный байесовский. Таким образом, оптимальный байесовский классификатор минимизирует не только функционал риска, но и функционал среднего риска. Подведем итог: мы обсудили с вами проблемы обобщения байесовской классификации на случай регрессии и проблемы учета различных штрафов за различные ошибки. Также мы рассмотрели функционал риска и придумали байесовский классификатор в более общем виде с учетом штрафов. Кроме того, мы обобщили всё на случай регрессии и рассмотрели средний риск, характеризующий не поведение классификатора в каком-то конкретном x, а поведение в среднем, и выяснили, что оптимальный байесовский классификатор минимизирует и функционал среднего риска. Всё это дает нам более общий взгляд на задачи обучения на размеченных данных, которые мы научимся использовать в следующем видео.

[ЗАСТАВКА] Итак, уже в прошлом видео было анонсировано, что с помощью нового, более общего взгляда на байесовскую классификацию мы сможем понять еще много интересных вещей, вот и настал момент для этого. Но для начала давайте убедимся, что оптимальный байесовский классификатор в том виде, в котором мы его теперь записываем, при каких-то условиях переходит в байесовский классификатор, с которым мы были знакомы ранее. Это очень просто. Давайте просто рассмотрим ситуацию, когда потери представляют собой просто индикатор того, что ответ алгоритма не совпал с правильным, подставим это все в выражение для байесовского классификатора, получим взвешенную сумму возможных значений потерь с весами p(y) при условии x, но так как потери у нас – это просто индикатор, то мы получаем сумму всех вероятностей для всех y, кроме y = s. Эту сумму можно представить как сумму по всем y, из которой вычли p(s) при условии x. Понятно, что на всю сумму мы никак не влияем, выбирая s, а вот на вычитаемую величину влияем. И, конечно, чтобы все минимизировать, вычитаемая величина должна быть побольше, то есть ее нужно максимизировать. Это означает, что классификатор должен быть просто максимумом p(y) при условии x, ну, или от максимум p(y)*p(x) при условии y, если воспользоваться теоремой Байеса. Вот мы и получили то, что видели ранее. Оказывается, что все это можно использовать еще и для анализа разных функций потерь в задаче регрессии. Давайте, например, посмотрим на квадратичную функцию потерь. Теперь у нас будет не сумма по y, а интеграл, так как у нас задача регрессии, и y принимает вещественные значения, и всю эту величину нам нужно как-то минимизировать. Давайте просто запишем производную этой величины по ответу алгоритма и приравняем ее к нулю. Если расписать производную, то постепенно видно, что все выражение распадается на две части. В первой части у нас возникает интеграл от плотности p(y) при условии x под dy, этот интеграл, конечно, равен 1, это же плотность, и, таким образом, приравняв это все к нулю, мы получаем вывод, что прогноз алгоритма должен равняться интегралу от y*p(y) при условии x, то есть условному математическому ожиданию, математическому ожиданию y при условии x. Вот какой интересный смысл, оказывается, сокрыт в квадратичной функции потерь, она оценивает матожидание. Теперь рассмотрим абсолютное отклонение. Все получается абсолютно также, как было для квадратичной функции потерь, единственный нюанс заключается в том, что модуль у нас в нуле не дифференцирован, но эту точку легко вытянуть, потому что одна точка не повлияет на значение интеграла. В других же точках производная модуля будет равна либо 1, либо −1. Это можно записать с помощью функции сигнум. И теперь снова все распадается на две части, которые, как мы видим, совпадают с вероятностью того, что t больше y, и с вероятностью того, что t меньше y, конечно, при условии известного x. Это означает, что эти вероятности должны быть равны друг другу. Кроме того, так как мы предполагаем, что распределение у нас непрерывное, вероятность того, что t = y, равна 0. В таком случае мы получаем, что вероятность того, что t больше либо равно y, и вероятность того, что t меньше y, обе равны 1/2. Это означает, что в этом случае у нас оценивается 1/2 квантиль. Теперь рассмотрим задачу классификации, в которой мы хотим, чтобы ответ алгоритма выдавал какую-то хорошую, правдоподобную вероятность принадлежности объекта к классу 1. Будем считать, что у нас классы 0 и 1. Оказывается, если рассмотреть показанную на слайде функцию потерь, которая называется Log loss, можно получить нужный нам результат. Для этого опять запишем все так же, как и в предыдущие разы. Давайте обозначим вероятность того, что класс 1 при условии x – p, тогда, приведя подобные, получим следующее выражение, и его нам нужно минимизировать. Опять берем производную по ответу алгоритма, приравниваем эту производную к 0 и получаем нужный нам результат. Видим, что ответ алгоритма должен равняться вероятности p. Остается единственный вопрос: почему же все эти рассуждения про функции потерь будут работать на практике, ведь мы их проводим для байесовской регрессии, для байесовской классификации, а на деле мы можем использовать какой-нибудь другой классификатор или решать задачу регрессией как-нибудь по-другому? Но дело в том, что в байесовской классификации минимизируется функционал среднего риска. Оказывается, что ошибка на обучающей выборке – это просто некоторая эмпирическая оценка для среднего риска. Подведем итог. Мы выяснили, что принцип минимизации функционала среднего риска не только позволяет в более общем виде взглянуть на байесовскую классификацию и байесовскую регрессию, но и позволяет сделать некоторые интересные выводы о задачах обучения на размеченных данных. В частности, с помощью идей, связанных с функционалом среднего риска, можно проводить анализ функций потерь. Например, мы рассмотрели с вами квадратичную функцию потерь и выяснили, что она приводит к оценке матожидания; рассмотрели абсолютные отклонения и выяснили, что они приводят к оценке 1/2 квантиля. Кстати, подумайте, какая функция потерь приведет к оценке α-квантиля. Выяснили, что Log loss приводит к оценке вероятностей, и, кроме того, с помощью той же самой методики можно иногда обнаружить, что функция потерь неудачна. Например, если у вас классы 0 и 1, и вы хотите оценивать вероятности, и вы для этого решите использовать абсолютное отклонение, надеюсь, что будут получаться какие-то числа между 0 и 1, которые можно будет проинтерпретировать как уверенности. Выписав все то, что мы делали для квадратичной функции потерь абсолютных отклонений Log loss'a, вы увидите, что при таком подходе будут получаться ответы только 0 и 1. И действительно, таким образом можно неплохо анализировать поведение различных функций потерь.
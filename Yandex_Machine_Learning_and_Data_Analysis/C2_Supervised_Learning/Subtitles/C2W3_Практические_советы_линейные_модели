Мы начинаем урок, в котором обсудим различные особенности, с которыми вы можете столкнуться при применении линейных моделей к реальным задачам. И первый аспект, о котором мы поговорим, это масштабирование признаков. Давайте начнем с простого примера, на котором поймём необходимость масштабирования. Представьте, что нам нужно найти минимум простой функции w1²+ w2². В общем-то понятно, что минимум достигается в точке (0, 0), но давайте посмотрим, что будет, если мы воспользуемся градиентным спуском для минимизации этой функции. Её линии уровня выглядят как-то так. Это круги. Поскольку переменные в этой функции симметричны, можно поменять местами w1 и w2, то линии уровня тоже симметричные. Если вы решите запустить градиентный спуск из точки (1, 1), то вектор антиградиента будет смотреть влево и вниз, а его координаты равны (-2, -2). Этот вектор проходит через точку минимума (0, 0). Если вы подберёте правильный размер шага при этом антиградиенте, то уже на первом шаге градиентного спуска попадёте строго в точку минимума этой функции. Градиентный спуск будет хорошо работать на этой функции. Давайте теперь немного её изменим. Добавим перед слагаемым w2² коэффициент 100. В этом случае функционал будет выглядеть вот так. Он уже несимметричный. Перед переменной w2 стоит большой коэффициент. В этом случае линии уровня будут выглядеть вот так. Это уже эллипсы, сильно вытянутые вдоль оси x, поскольку перед второй переменной стоит большой коэффициент, изменение по ней при небольшом изменении w2 гораздо сильнее. Если мы, опять же, запустим градиентный спуск из точки (1, 1), то вектор антиградиента в этой точке будет иметь координаты -2 и -200, он будет смотреть практически строго вниз и проходить мимо точки минимума функции. Если вы сделаете шаг у этого вектора, то промахнётесь, и у вас есть шанс стать ещё дальше от минимума, чем вы были в начальном приближении. Градиентный спуск будет иметь большие проблемы, если вы запустите его на этой функции. Итак. Градиентный спуск работает хорошо, если линии уровня функции похожи на круги, как на этом примере. В этом случае, откуда бы вы ни начали, вектор антиградиента будет смотреть в сторону минимума функции и будет сходиться довольно быстро. Если же линии уровня вот такие, то градиентный спуск будет иметь проблемы. Направление антиградиента будет слабо совпадать с направлением в сторону минимума функции, и градиентный спуск будет делать много лишних шагов. Его сходимость будет медленная. И более того, есть риск расхождения градиентного спуска, если размер шага будет подобран неправильно. Вот ещё один пример. Представьте, что у вас есть некая заявка на грант, и вам нужно предсказать, будет ли выдан грант по этой заявке, будет ли она одобрена. И представьте, что у вас есть два признака. Первый признак говорит, сколько уже успешных заявок было у данного заявителя. Понятно, что если много его предыдущих заявок было одобрено, у него большой опыт, у него хорошо получается писать заявки, и данная, скорее всего, тоже будет одобрена. Второй признак — это год рождения заявителя. Масштабы у этих признаков очень разные. Число одобренных грантов — это, скорее всего, единицы, а год рождения — это тысячи. У них разный масштаб. И из-за этого линии уровня функции будут скорее выглядеть как вытянутые эллипсы, чем как круги. Именно различие в масштабе признаков приводит к тому, что линии уровня не похожи на круги. Чтобы бороться с этой проблемой, чтобы у градиентного спуска не было никаких плохих нюансов при применении к таким выборкам, признаки нужно масштабировать, то есть приводить к одному масштабу. Мы разберём два способа масштабирования. И первый из них называется нормализацией. Итак. Представьте, что мы хотим отмасштабировать j-тый признак. В этом случае нам нужно сначала вычислить две вспомогательные величины: среднее значение этого признака и стандартное отклонение этого признака. Для вычисления среднего мы просто суммируем значение этого признака на всех объектах обучающей выборки, и делим на размер выборки. Чтобы вычислить стандартное отклонение, мы суммируем квадраты отклонений значений этого признака на объектах обучающей выборки от среднего значения μj. И делим на число объектов обучающей выборки, после чего извлекаем корень. После этого нам известны среднее значение μj-тое и стандартное отклонение σj-тое. Теперь, чтобы отмасштабировать признак, мы берём каждое его значение, например на i-том объекте xij-тое, вычитаем из него среднее μj-тое и делим на стандартное отклонение σj-тое. После этих операций мы уберём сдвиги и различия в масштабах у всех признаков, и они будут иметь примерно одинаковый масштаб. Второй подход называется масштабированием на отрезок [0, 1]. В этом случае нам нужно тоже вычислить две вспомогательные величины, но немного другие. Это будут минимальное и максимальное значение данного признака на всей обучающей выборке. Минимальное значение обозначаем буквой mj-тое, максимальное значение буквой Mj-тое. После того, как они найдены, мы берём значение данного признака на конкретном объекте, вычитаем из него минимальное значение данного признака и делим на разность между максимальным и минимальным значением данного признака. После такого преобразования минимальное значение признака будет отображено в ноль, максимальное в единицу. Получается, что данный признак отмасштабирован на отрезок [0, 1]. Итак. Мы с вами обсудили, что различия в масштабах признаков — это очень плохо, применение градиентного спуска к таким выборкам может привести к его очень плохой сходимости или даже к его расхождению. Чтобы бороться с этим признаки нужно масштабировать. Мы обсудили два способа масштабирования признаков. Первый называется нормализацией, в котором мы вычитаем среднее и делим остаток на отклонение признака, второй — это масштабирование на [0, 1]. В следующем видео мы поговорим о том, как использовать в линейных моделях нелинейные признаки.

В этом видео мы поговорим о спрямляющих пространствах, которые позволяют восстанавливать нелинейные зависимости с помощью линейных моделей, и начнем с простого примера. Представьте, что мы решаем задачу регрессии, в которой есть всего один признак, который отложен по оси X, и по этому признаку нужно восстановить целевую переменную y, которая отложена по оси Y. Если мы попробуем применить линейную модель, то она получится вот такой. Видно, что она плохо подходит для решения задачи. Зависимость y от x явно нелинейная. Давайте теперь попробуем немножко модифицировать нашу модель. Добавим к исходному признаку x еще три признака: x², x³ и x⁴. Если мы над этими новыми признаками надстроим линейную модель, в которой будет уже 5 коэффициентов, а не 2, как было раньше, то получим вот такую модель. Видно, что она практически идеально описывает данные. Она очень хорошо решает задачу и при этом не переобучается. Получается, что мы перешли к новому признаковому пространству, в котором 4 признака, а не 1, в нем построили линейную модель, а в исходном пространстве эта модель уже нелинейная, и она очень хорошо описывает данные. А вот другой пример. Задача классификации с двумя признаками, x₁ и x₂, которые отложены по осям. Опять же видно, что разделяющая поверхность здесь вовсе не линейная. Если мы настроим линейный классификатор, он получится вот таким. Все объекты будет относить к красному классу. Это лучшее, что он может сделать, но понятно, что это никуда не годится. Опять же попробуем добавить новых признаков, а именно x₁², x₂² и x₁ * x₂, то есть квадратичные признаки. Если над ними построить линейную модель, то разделяющая поверхность в исходном пространстве будет вот такой. Она будет иметь форму окружности и очень хорошо разделять красные точки и синие точки. Опять же, в новом признаковом пространстве, имеющем большую размерность, мы построили линейную модель, и это соответствует построению нелинейной разделяющей поверхности в исходном двумерном признаковом пространстве. Таким образом, мы приходим к понятию спрямляющего пространства. Это такое признаковое пространство, в котором задача хорошо решается линейной моделью. Давайте разберем несколько примеров, как такое пространство можно отстроить. И первый пример — это добавление квадратичных признаков. Пусть объект описывается признаками x₁, ..., xd. Всего d признаков. Тогда добавим к этим признакам еще несколько, а именно квадраты исходных признаков x₁², ..., xd² и попарные произведения x₁x₂, x₁x₃ и так далее до x(d−1)xd. Заметим, что число признаков увеличится на порядок. Если у вас было не очень много объектов, то есть риск переобучения в таком большом признаковом пространстве. Нужно быть осторожным при использовании спрямляющих пространств. Если же у вас объектов много и вы не боитесь переобучения, но при этом знаете, что зависимости очень нелинейные, можно попробовать полиномиальные признаки более высоких порядков, например признаки третьего порядка. В этом случае помимо квадратичных признаков мы добавим еще кубы исходных признаков, то есть x₁³, x₂³, ..., а также произведение всех троек признаков x i-тое * x j-тое * x k-тое, где i, j и k — это какие-то индексы признаков. Также можно брать другие нелинейные функции. Например представьте, что мы используем признак «стоимость книги в интернет-магазине». Мы уже обсуждали этот пример ранее. Как мы говорили, большинство книг будут иметь стоимость в районе нескольких сотен рублей, но при этом есть очень дорогие книги. Распределение значений этого признака будет иметь тяжелый правый хвост. Это не очень хорошо для линейных моделей. Известно, что они работают гораздо лучше, если распределение признаков близко к нормальному. Чтобы сделать такое распределение тяжелых хвостов более близким к нормальному, нужно его прологарифмировать. Итак, если признак принимает только неотрицательные значения, то мы берем значение данного признака xᵢ, прибавляем к нему единицу, чтобы не взять логарифм от нуля, и берем логарифм от xᵢ + 1. После этого распределение станет более похожим на нормальное. Или же, если признак принимает как положительные, так и отрицательные значения, то можно сначала взять модуль от значения этого признака, а затем уже прибавить единицу и взять логарифм. Можно пробовать и другие нелинейные функции, но не будем об этом говорить сейчас. Итак, мы обсудили, что далеко не все задачи хорошо решаются линейными моделями. Но линейные модели можно применить к восстановлению нелинейных зависимостей, если перейти в спрямляющее пространство, то есть перейти к новым признакам, которые гораздо более сложные, чем исходные. Порождать эти признаки можно самыми разными способами, например достроить квадратичные, или кубические, или полиномиальные признаки более высоких размерностей. Или, скажем, брать логарифмы от исходных признаков. В следующем видео мы поговорим о том, как применять линейные модели к категориальным признакам.

[ЗАСТАВКА] В этом видео мы поговорим о том, как использовать категориальные признаки в линейных или других моделях. Мы уже приводили много примеров категориальных признаков. Это может быть город или цвет или, например, тарифный план у мобильного оператора или марка автомобиля. Особенность категориальных признаков в том, что это элементы некоторого неупорядоченного множества. Мы не можем говорить, что одно значение больше или меньше другого, можем только сравнивать их на равенство. А при этом в линейных моделях нам нужно брать значение признака, умножать его на вес и складывать с какими-то другими числами. Это нельзя делать со значениями категориальных признаков, их нужно как-то преобразовать, чтобы их можно было использовать в линейных моделях. Одним из наиболее популярных подходов к кодированию признаков, категориальных признаков, является бинарное кодирование. Давайте введем несколько обозначений, которые помогут нам понять, в чем оно заключается. Итак, представьте, что j-тый признак задачи категориальный. Значение j-того признака на объекте x будем обозначать, как fj (x). Допустим, он принимает n различных значений. Пронумеруем их. Обозначим эти значения, как c1, c2... cn. Чтобы закодировать данный признак, введем n новых бинарных признаков, которые обозначим, как b1 (x), b2 (x)... до bn (x). Значение i-того бинарного признака равно 1 только в том случае, если на данном объекте категориальный признак принимает значение ci. Если же он принимает какое-то другое значение, то i-тый признак будет равен 0. Таким образом, мы заменяем один категориальный признак на n бинарных, значения которых — это по сути числа, и из этих бинарных признаков единице равен только тот, который соответствует нашему значению категориального признака на этом объекте. Давайте разберем простой пример. Представьте, что j-тый признак — это цвет и он принимает три значения: синий, зеленый и красный. И у нас есть три объекта (x1, x2 и x3), на которых значение категориального признака равно «синий», «красный» и «синий», соответственно. Итак, категориальный признак принимает три значения. Нам понадобится три бинарных признака, чтобы его закодировать. Мы получим вот такую матрицу: первый столбец в ней, первый признак, соответствует значению «синий», второй — значению «зеленый», третий — значению «красный». И у нас есть три объекта, каждый из которых соответствует одной из строк. На первом и третьем объекте категориальный признак принимает значение «синий», значит, единица у них будет стоять в первом столбце. На втором объекте категориальный признак принимает значение «красный». Красный — это третий столбец, значит, единица стоит в третьем столбце. Эта матрица кодирует наш категориальный признак тремя бинарными. При этом вы можете столкнуться с такой проблемой: когда вы будете пытаться построить такое же кодирование для тестовой выборки, там может оказаться объект, на котором категориальный признак принимает новое, (n + 1)-е значение, которое вы не видели раньше на обучающей выборке. В этом случае логичным подходом будет не добавлять новый признак, это очень сложно, просто приравнять 0 все существующие признаки. Поскольку смысл наших бинарных признаков — это принимает ли категориальный признак то или иное значение от c1 до cn, то мы просто выставляем их равными 0, поскольку ни одно из них не получается на данном объекте. Итак, мы обсудили, что категориальные признаки нельзя непосредственно использовать в линейных моделях, и поговорили о том, как использовать бинарное кодирование, то есть кодирование одного категориального признака с помощью n бинарных, чтобы внедрять каким-то образом категориальные признаки в линейные модели. В следующем видео мы поговорим о том, как работать с задачами несбалансированной классификации.

[БЕЗ_ЗВУКА] В этом видео мы поговорим о том, что такое несбалансированные выборки, к каким проблемам они могут привести и как бороться с такими проблемами. Итак, представьте, что мы решаем задачу классификации с некоторой выборкой. Эта задача называется несбалансированной, если объектов одного или нескольких классов в этой выборке существенно меньше, чем объектов всех остальных классов. Например, если мы решаем задачу бинарной классификации, то есть класса всего два, то есть такое правило: выборка считается несбалансированной, если объектов одного класса 10 % или меньше от общего числа объектов выборки. Примеров задач с несбалансированными выборками довольно много. Например, представьте, что мы хотим предсказывать, случится ли на следующий день резкий скачок курса доллара. Если определение резкого скачка будет такое, что мы хотим ловить только очень сильные изменения, то примеров таких изменений за всю историю – единицы, но при этом практически каждый день – это отрицательный пример, то есть пример, когда такого скачка не было. Выборка в этом случае будет очень несбалансированной. Примеров может быть очень много: это медицинская диагностика, где больных, как правило, сильно меньше, чем здоровых, это обнаружение мошеннических транзакций по картам в банке, где примеров таких плохих транзакций существенно меньше, чем обычных транзакций, или это может быть классификация текстов, где мы пытаемся находить какие-то очень редкие классы. Основная проблема, связанная с несбалансированными выборками, в том, что практически все классификаторы пытаются минимизировать число ошибок на обучающей выборке. Они никак не учитывают цены ошибок, и может оказаться выгоднее отнести все объекты к наибольшему классу, не пытаясь как-то выделить объекты маленького класса. То есть при работе с несбалансированными выборками классификаторы могут получаться очень плохие с точки зрения точности или полноты. Мы разберем два подхода к работе с несбалансированными выборками, и первый называется undersampling. Его основная идея состоит в том, что нам не нужно много примеров объектов из больших классов, можно выкинуть часть из них. Например, представьте, что у нас есть три класса: первый — очень большой; второй — совсем маленький; и третий имеет средний размер. В этом случае мы выкинем большую часть объектов первого класса и половину объектов третьего класса. В этом случае размеры классов примерно сравняются. При этом то, сколько именно объектов каждого класса мы выбрасываем, это гиперпараметр, который имеет смысл настраивать по отложенной выборке или на кросс-валидации. Второй подход – это oversampling. Он противоположен предыдущему. Мы будем дублировать объекты маленьких классов так, чтобы выравнять соотношение классов. В нашем примере мы пять раз повторим объекты второго класса, а для третьего класса мы возьмем случайную половину объектов и продублируем их. Таким образом третий класс мы увеличим в полтора раза. В этом случае размеры выборок, размеры классов тоже выравняются. То, насколько мы будем увеличивать каждый класс, – это тоже гиперпараметр. Обратим внимание на одну особенность. Если мы решаем задачу на исходной выборке, то, например, среднеквадратичная ошибка будет выглядеть вот так. Это среднее значение квадратичной ошибки по всем объектам. Если же мы делаем oversampling, то есть дублируем какие-то объекты, то это будет означать, что какое-то слагаемое войдет в эту сумму несколько раз. Таким образом, вместо реального дублирования объектов, мы можем просто выставить соответствующие веса при каждом слагаемом. Например, если первый объект мы продублируем три раза, то мы просто выставим вес при нем равным трем, v1 будет равно 3. Обратим внимание на еще одну проблему, с которой можно столкнуться при работе с несбалансированными выборками. Напомню, что когда мы проводим кросс-валидацию, мы разбиваем исходную выборку на k блоков примерно одинаковой длины. При этом если выборка несбалансированная и, например, первого класса очень мало, то при таком разбиении может оказаться, что в некоторые блоки объекты первого класса не попадут вообще. Это будет очень плохо. Например, при обучении на этом блоке мы получим классификатор, который никогда не видел один из классов. Чтобы бороться с этим, нужно делать стратификацию. При стратификации мы строим разбиение на блоки так, чтобы распределение классов в каждом блоке примерно совпадало с распределением классов в исходной выборке. В этом случае будет гарантироваться, что объекты каждого класса будут представлены в каждом из блоков разбиения. Итак, мы обсудили, что несбалансированные выборки – это проблема, с которой можно столкнуться при решении задач классификации. В этом случае константный классификатор может оказаться лучше с точки зрения алгоритма обучения, чем какой-то разумный классификатор, выделяющий объекты маленького класса. Чтобы бороться с такой проблемой, есть несколько подходов, например oversampling и undersampling, в которых мы либо уменьшаем большие классы, либо дублируем объекты маленьких классов, чтобы как-то выравнять пропорции этих классов. Также мы поговорили, что в случае с несбалансированными выборками могут возникнуть проблемы при разбиении данных на кросс-валидацию или на обучающую и отложенную выборку. В этом случае нужно делать стратификацию, то есть стараться сохранить соотношение классов в каждой подвыборке при разбиении. В следующем видео мы поговорим о том, как решать задачи многоклассовой классификации с помощью линейных моделей.

[заставка без звука] В этом видео мы поговорим о том, как решать задачи многоклассовой классификации с помощью линейных моделей. Итак, как следует из названия, в задачах многоклассовой классификации — K возможных классов. Например, на этой картинке изображена выборка, у которой три класса: синий, красный и зелёный. И нужно как-то научиться отличать каждый класс от всех остальных. В случае с бинарной классификацией наш подход был довольно простой. Мы находили такой вектор весов w, что знак скалярного произведения этого вектора весов на вектор признаков говорил, к какому классу относится тот или иной объект. На самом деле, этот подход можно расширить и применить его же к задаче многоклассовой классификации. Это называется — один против всех. Мы будем строить свой бинарный классификатор для каждого класса. И задачей этого классификатора будет отделение данного класса от всех остальных. Например, на этой картинке мы можем отделить зелёные точки от всех остальных с помощью такого линейного классификатора. А красные точки от всех остальных — с помощью вот такого. Давайте поговорим об этом подходе чуть более формально. Итак, Мы будем решать K задач бинарной классификации. Рассмотрим одну из них. Допустим, мы хотим отделить класс k от всех остальных классов. В этом случае у нас будет несколько специфичная выборка. Объекты x i-тое останутся такими же, а вот ответы будут бинарными. Ответ на i-том объекте будет = 1, если этот объект относится к классу k и — 0, если он относится к какому-то другому классу. Объектов в выборке будет столько же, сколько и в условной задаче — l штук. Мы построим некоторый линейный классификатор, который отделяет k-тый класс от всех остальных. Он будет иметь вид знака скалярного произведения электровесов в w k-тое на вектор признаков x. Как мы говорили раньше, если скалярное произведение больше 0, то классификатор считает, что объект относится к классу 1. В нашем случае это будет класс k. И чем больше значение этого скалярного произведения, тем больше классификатор уверен в этом решении. Таким образом, будет логично отнести объект к тому классу, уверенность в принадлежности к которому больше всего, то есть для которого скалярное произведение w k-тое на x больше всего. Именно так и будет выглядеть итоговый многоклассовый классификатор a(x). Он будет возвращать тот класс k, для которого скалярное произведение w k-того на x больше всего. Удобно смотреть на матрицу ошибок, когда мы пытаемся проанализировать, насколько хорошо работает наш многоклассовый классификатор. Она может выглядеть вот так. Каждая строка соответствует тем объектам, который классификатор отнёс к тому или иному классу, а каждый столбец соответствует объектам, который на самом деле относится к тому или иному классу. Например, на пересечении первой строки второго столбца будет стоять число q12, которое показывает, сколько объектов второго класса наш классификатор отнёс к первому классу. Эта матрица, например, может позволить понять, какие классы мы путаем между собой чаще всего. Можно измерять и знакомые нам метрики качества. Например, долю правильных ответов или accuracy. Формула её вычисления никак не поменяется в зависимости от числа классов — два их, три или сто. Также можно измерять точность и полноту для задачи отделения того или иного класса от всех остальных классов. Если мы вычислим такие точность и полноту для каждого из классов, после этого их можно усреднить, получив такие агрегированные оценки. Или, например, можно вычислить F-меру для сдачи отделения одного класса от всех остальных и потом усреднить этот показатель по всем классам. Итак, мы обсудили, что многоклассовые задачи можно решать путём нахождения нескольких бинарных классификаторов. Этих классификаторов будет столько, сколько у нас классов в исходной задаче. При этом, например, удобно смотреть на матрицу ошибок, которая позволяет понять, какие классы мы путаем между собой чаще всего. Или можно вычислять знакомые нам метрики качества: долю правильных ответов, точность, полноту или F-меру.


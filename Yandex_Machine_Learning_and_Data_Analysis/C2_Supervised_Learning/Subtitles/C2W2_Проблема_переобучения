[БЕЗ_ЗВУКА] Мы начинаем урок, посвящённый проблеме переобучения и вопросу оценивания качества алгоритмов. По итогам этого урока вы будете понимать, как оценить качество алгоритма на новых неизвестных данных, а также как сравнить много алгоритмов и выбрать из них лучший. А начнём урок мы с того, что разберёмся с тем, что такое переобучение, и почему это очень плохо. Давайте рассмотрим простой пример. Допустим, мы решаем задачу классификации и построили некоторый алгоритм, например, линейный классификатор, и измеряем долю ошибок на обучающей выборке. Допустим, она получилась 0.2, то есть мы допускаем ошибку на двадцати процентах объектов обучающей выборки. Предположим, что нас это устроило, и мы используем этот алгоритм дальше. Но как понять из того, что у него небольшая доля ошибок на обучении, извлёк ли он закономерности, может ли он хорошо работать на новых данных? На самом деле, никаких гарантий нет. Легко может оказаться, что мы возьмём новую выборку, применим к ней наш уже обученный алгоритм и получим, что доля ошибок на новой выборке равна 0.9, то есть алгоритм ошибается на 90 % объектов. Это никуда не годится. Значит, что алгоритм не смог обобщить обучающую выборку, не смог извлечь из него закономерности и применить эти знания для классификации новых объектов. Но при этом, заметьте, что мы получили хорошее качество на обучении. То есть алгоритм как-то смог подогнаться под обучение, не извлекая из него закономерностей. Эта проблема и называется переобучение. Чтобы чуть лучше понять, в чём заключается переобучение, давайте рассмотрим классический пример про линейную регрессию. Итак, рассмотрим некоторую выборку. Объекты выборки обозначены синими точками, это одномерная выборка и сдача регрессии. По оси x отложено значение признака, по оси y — значение ответа. Истинная зависимость между ответом и признаком выглядит как зелёная кривая. Видно, что это такая нелинейная зависимость с двумя экстремумами. И давайте будем пробовать разные модели, с помощью которых будем пытаться предсказывать ответы. И начнём мы с константной регрессии, то есть алгоритм a(x) будет иметь вид w0, где w0 — некоторая константа. Настроив эту модель под данные, мы получим некоторую красную горизонтальную прямую, которая видно, что никуда не годится: она довольно плохо обобщает информацию. Эта проблема называется недообучением. Мы не смогли построить хороший алгоритм из-за того, что семейство алгоритмов слишком простое, оно не может уловить закономерности. Понятно, что решением является усложнение семейства алгоритмов. Хорошо, давайте рассмотрим линейную регрессию, то есть алгоритмы вида w0 + w1 * x. Настроив такой алгоритм под нашу выборку, мы всё ещё недообучимся. Видно, что получилось чуть лучше, но красная прямая всё ещё довольно плохо описывает наши данные, потому что она является линейной, а закономерность является нелинейной. Хорошо, давайте возьмём многочлен третьей степени. То есть алгоритм вида w0 + w1 * x + w2 * x² + w3 * x³, — многочлен третьей степени. Настроив его на нашу выборку, мы увидим, что полученный алгоритм, то есть красная кривая, очень хорошо приближает истинную зависимость. Скорее всего, нас устраивает такая модель. Мы её и оставим, будем ей пользоваться. Но при этом, смотрите, совпадение между красными и зелёными кривыми неидеальное. Что если ещё чуть-чуть усложнить алгоритм? Может, мы получим ещё более качественную модель. Хорошо, давайте возьмём многочлен девятой степени. И в этом случае мы получим вот такую закономерность. Видно, что восстановленная зависимость, красная кривая, — очень плохая. Да, она даёт идеальные ответы на всех объектах обучающей выборки, она проходит через все синие точки. Но при этом в любой другой точке ответ никуда не годится. Эти ответы никак не соответствуют истинной зелёной зависимости. Это является переобучением. Алгоритм слишком сильно подогнался под обучающую выборку ценой того, что он будет давать плохие ответы на новых точках. Итак, мы выяснили, что недообучение — это проблема, в которой алгоритм имеет плохое качество и на обучающей выборке, и на новых данных. А переобучение — это проблема, при которой алгоритм имеет хорошее качественной обучение, но плохое качество о новых данных. При этом с недообучением понятно как бороться: нужно усложнять семейство алгоритмов, брать более сложные алгоритмы, например, многочлены высокой степени вместо линейных. А вот с переобучением всё сложнее. Дело в том, что хороший алгоритм, который хорошо обобщает информацию, будет иметь хорошее качественное обучение. Переобученный алгоритм тоже будет иметь хорошее качество на обучающей выборке. Отличаются они только по качеству на новых данных. Хороший алгоритм будет хорошо работать в новых данных, а переобученный — плохо. Получается, что, имея лишь обучающую выборку, а мы имеем лишь её в момент настройки алгоритма, мы не можем понять, переобучился он или нет. Нам нужна какая-то дополнительная информация или дополнительные данные, чтобы выявить переобучение. Мы приходим к нескольким подходам к выявлению переобучения. Например, можно откладывать часть выборки, не использовать её при обучении, и дальше уже обученный алгоритм проверять на этой отложенной выборке. Или, например, есть кросс-валидация — это усложнённая версия отложенной выборки, о которой мы будем говорить в этом уроке. Также есть некоторые меры сложности модели, которые позволяют без дополнительной выборки понять, получилась ли модель слишком сложной или нет. Об этом мы и поговорим в следующем видео. И в качестве небольшой затравки давайте посмотрим, что получилось, когда мы настраивали многочлен девятой степени. Заметьте, что, по сути, обучение такого многочлена — это обучение линейной регрессии над признаками x, x в квадрате, и так далее, до x в девятой степени, то есть над девятью признаками. И если посмотреть на веса модели, которая получилась, окажется, что порядок весов очень большой — это миллионы и десятки миллионов. Если же посмотреть на порядок весов в модели третьей степени (в многочлене третьей степени), которая хорошо подходила под данные, можно увидеть, что там порядок гораздо ниже. Таким образом, наверное, абсолютные значения весов как-то говорят о том, насколько сложная модель у нас получилась. Итак, мы с вами выяснили, что переобучение — это проблема, которая состоит в излишней подгонке алгоритма под обучающую выборку, из-за чего страдает его качество на новых данных. Также мы выяснили, что одним из симптомов переобучения линейных моделей являются большие веса в этих моделях, что мы будем использовать в следующем уроке, когда будем говорить про регуляризацию — способ борьбы с переобучением в линейных методах.

[ЗАСТАВКА] В этом видео мы поговорим про регуляризацию — способ борьбы с переобучением в линейных моделях. В прошлый раз мы с вами убедились, что мерой сложности или симптомом переобученности линейной модели являются большие веса при признаках. Например, когда мы пытались обучить полином 9-й степени под вот такую выборку, мы получали переобученную модель, коэффициенты которой были огромными — миллионы и десятки миллионов. Еще одна ситуация, в которой можно столкнуться с переобучением — это мультиколлинеарность. Так называется проблема, при которой признаки выборки являются линейно зависимыми, то есть есть некоторый вектор значений признака на всех объектах, который выражается через векторы других признаков. Или, иными словами, это означает, что существуют такие веса α1, ..., αd, что какой бы объект обучающей выборки xi мы не взяли, оказывается, что если мы просуммируем с этими коэффициентами все значения признаков на этом объекте xi, получим 0. Это, по сути, есть определение линейной зависимости. Более компактно это можно записать как равенство нулю скалярного произведения вектора коэффициентов α на вектор признаков xi. Итак, в чем проблема мультиколлинеарности? Давайте представим, что мы решаем некоторую оптимизационную задачу, например минимизируем среднеквадратичную ошибку, то есть средний квадрат отклонения прогноза от истинного ответа yt. И нашли оптимальную точку w* — точку, на которой достигается минимум этого функционала. Хорошо, а теперь давайте возьмем этот оптимальный вектор весов w* и прибавим к нему тот вектор коэффициентов α из определения линейной зависимости с некоторым множителем t, скалярным множителем. И давайте посмотрим, как будет выглядеть прогноз алгоритма с этим новым модифицированным вектором весов на некотором объекте x. Для этого нужно посчитать скалярное произведение вектора w* + tα на вектор x. По правилам скалярного произведения это выражение распадается на сумму двух скалярных произведений. Первое — это w* умножить на x, второе — это α умножить на x с некоторым скалярным множителем t. Но при этом давайте вспомним, что α умножить на x скалярное — это 0, просто по определению линейной зависимости. Получаем, что прогноз нашего модифицированного алгоритма равен w* умножить на x, то есть прогнозу исходного оптимального алгоритма. Значит, мы получили новый алгоритм с новым векторов весов, который во всем совпадает с исходным алгоритмом. Получается, что и значение функционала качества, функционала ошибки на этом алгоритме будет такое же — он тоже будет оптимальным. Итак, в случае с мультиколлинеарностью у нас бесконечно много оптимальных алгоритмов, при этом многие из них будут иметь очень большие значения весов, но далеко не все из них хорошо обобщают информацию, обладают хорошей обобщающей способностью. Поэтому здесь тоже легко столкнуться с переобучением. Итак, мы выяснили, что симптомом переобучения являются большие веса в линейной модели — давайте будем штрафовать за это модель, чтобы бороться с переобучением. Делать это будем с помощью регуляризатора. Итак, допустим, есть некоторый функционал ошибки Q, которому на вход подаются, напомню, векторы весов w и выборка x. Будем прибавлять к нему квадратичный регуляризатор, то есть L2 — норму вектора весов, или просто сумму квадратов весов. И теперь заменим функционал ошибки на следующий: он будет представлять собой сумму исходного функционала Q и регуляризатора с некоторым коэффициентом λ. И будем минимизировать эту сумму. Ее минимизация приведет к тому, что мы хотим одновременно сделать ошибку на обучающей выборке как можно меньше, то есть минимизировать Q, но и при этом не слишком сильно увеличить веса при признаках, то есть не слишком сильно увеличить норму весов w. При этом у нас появляется новый параметр в модели — коэффициент регуляризации λ, который стоит перед своим регуляризатором. Чем больше мы делаем λ, тем менее сложные модели будут получаться. Если мы будем увеличивать λ все сильнее и сильнее, то в какой-то момент окажется, что оптимально просто занулить все веса, сделать их нулевыми. То есть слишком большая λ приведет к слишком простой константной модели. В то же время если λ делать маленькой, то есть риск переобучения, риск, что модель окажется слишком сложной. Таким образом, нужно искать некоторый баланс — выбирать λ такой, что, с одной стороны, она не допускает переобучения, с другой — позволяет делать модель достаточно сложной, чтобы уловить все закономерности в данных. Обычно λ подбирается по кросс-валидации, о которой будем говорить в следующем видео. А пока давайте выясним, какой смысл имеет добавление регуляризатора. Оказывается, что наша новая задача — Q + λ умножить на регуляризатор, и это мы минимизируем — эквивалентна условной задаче оптимизации, которая выглядит следующим образом. Мы минимизируем исходный функционал ошибки Q при ограничении. А ограничение состоит в том, что норма вектора весов не должна превосходить некоторую константу C. Получается, что мы решаем исходную задачу, но при этом ограничиваем по норме векторы весов, ровно то, что мы и хотели делать — штрафовать за слишком большую норму весов. Геометрически это означает, что если у нас есть некоторый функционал ошибки, который выпуклый и его линии уровня выглядят как-то вот так, то без регуляризатора мы бы просто искали минимум этого функционала — находили минимальную точку. После же добавления регуляризатора мы требуем, чтобы и решение находилось внутри некоторой круглой области с центром в 0. И теперь мы находим такое решение, которое находится внутри этой области и при этом как можно ближе к оптимальному решению без регуляризатора. Пока что мы говорили только про L2-регуляризатор — сумму квадратов весов. Он штрафует за сложность модели, и позволяет бороться с переобучение, и при этом является гладким и выпуклым, то есть его добавление к функционалу не будет усложнять процесс оптимизации, например, градиентный спуск. Но также есть L1-регуляризатор, который представляет собой L1-норму вектора весов, или просто сумму модулей весов. Он не является гладким — модуль не имеет производной в 0, то есть оптимизация функционала с таким регуляризатором будет затруднительна, но при этом такой регуляризатор обладает очень интересным свойством. Если использовать его, то часть весов в итоговом векторе весов будут нулевыми, то есть он производит отбор признаков — использует в модели не все признаки, а только самые важные из них. Это очень интересное свойство, которое часто пригождается на практике. Итак, мы обсудили, что большие веса в линейных моделях — это симптом переобучения. И для борьбы с этим переобучением можно пытаться «задавить» симптом, то есть штрафовать за слишком большие значения весов. Это можно делать с помощью L2-регуляризации, которая является самым частым выбором и штрафует за сложность модели. Или с помощью L1-регуляризации, которая чуть сложнее при оптимизации, но при этом позволяет отбирать признаки. В следующем видео мы поговорим про то, что такое кросс-валидация, и как оценивать качество алгоритма на новых данных.

В этом видео мы поговорим о том, как оценивать качество алгоритмов, как понимать, насколько хорошо алгоритм будет работать на новых данных. Как мы уже выясняли, например, переобучение сложно поймать только по обучающей выборке, и хороший алгоритм, который хорошо обобщает, и переобученный, будут показывать хорошее качество на обучении. И нужны какие-то дополнительные данные, дополнительная информация, чтобы понять, переобучился алгоритм или нет. Да, для этого еще можно использовать меры переобученности, например, регуляризатор — норму весов, но при этом все равно они не говорят о том, насколько хорошо алгоритм будет работать на новых данных. В этом видео мы попробуем понять, как предсказать, как понять, насколько хорошо он будет работать. То есть, например, какая у новых данных у алгоритма будет доля ошибок, если это классификация, или среднеквадратичная ошибка, если это задача регрессии. Понятно, что по обучающей выборке их оценивать нельзя, алгоритм подгонялся под обучающую выборку и, скорее всего, на ней значение качества будет неплохое. Самая простая идея того, как оценивать качество алгоритма, это построение отложенной выборки. Мы берем все данные, которые у нас есть, и разбиваем на две части. При этом первая выступает в качестве обучающей выборки, на нее мы настраиваем алгоритм, вторая выступает в качестве тестовой выборки, то есть на ней мы измеряем качество алгоритма, обученного на первой части. При этом мы измеряем качество как угодно, либо это среднеквадратичная ошибка, либо доля ошибок, либо что-то еще, в зависимости от специфики задачи. При этом сразу встает вопрос о том, в каких пропорциях разбивать данные на обучение и на тест. Если взять тестовую выборку слишком маленькой, отложенную выборку слишком маленькой, то, с одной стороны, обучающая выборка будет репрезентативной, и ее размер будет почти совпадать с размером настоящей обучающей выборки. Но, с другой, контрольная выборка, тестовая выборка, окажется слишком маленькой, в ней будет слишком мало объектов, чтобы надежно оценить качество, скорее всего, оценка качества будет зашумленной. Если же взять отложенную выборку слишком большой, то оценка по ней будет надежной, но, с другой стороны, обучение будет слишком маленьким, сильно меньше, чем настоящее обучение, и, например, мы можем увидеть качество очень небольшим, но из-за того, что обучения мало, что данных было слишком мало для обучения. Поэтому можно искать опять же какой-то баланс. Здесь нет конкретных советов, обычно берут разбиение в соотношении 70 к 30 или 80 к 20, где 70 и 80, соответственно, это размер обучения. Так же, например, есть подход, в котором размер обучающей выборки составляет 0,632 от общего размера данных. Преимуществом отложенной выборки является то, что обучать алгоритм нужно всего лишь один раз, на обучающей выборке. Но при этом результат очень сильно зависит от разбиения. Рассмотрим простой пример. Допустим, мы предсказываем стоимость жилья по некоторым характеристикам. И есть особая категория жилья, двухэтажные квартиры. Если вдруг окажется, что все двухэтажные квартиры, а их очень немного, попали в отложенную выборку, то мы увидим на них очень плохое качество, поскольку алгоритм не видел их на обучении, он ничего не знает о таких ситуациях и будет плохо предсказывать для них. При этом мы никогда не узнаем, что если бы хотя бы один такой объект оказался в обучении, то качество было бы гораздо лучше. Таким образом, результат измерения качества по отложенной выборке сильно зависит от того, как мы выбираем отложенную выборку, это не очень хорошо. Чтобы решить проблему, сразу приходит в голову следующий подход. Давайте много раз, n раз, разобьем все наши данные на обучение и тест, то есть много раз сгенерируем отложенную выборку. При этом каждый раз будем обучаться по обучающей выборке, измерять качество на отложенной выборке. Поскольку процедура повторяется n раз, мы получим n показателей качества, усредним их и получим итоговую оценку. Да, возможно, это уже решает проблему, но при этом, поскольку разбиения случайные, все еще нет гарантий, что каждый объект хотя бы раз побывает в обучении. Нужен более системный подход. Таким подходом является кросс-валидация. В ней предлагается следующее. Возьмем всю выборку и разобьем на k блоков примерно одинакового размера. И дальше каждый блок по очереди будет выступать в качестве тестового. Итак, сначала возьмем первый блок в качестве тестового, а все остальные в качестве обучения. Обучим алгоритм на обучающей выборке, измерим качество на тестовом блоке, запомним его. Далее возьмем второй блок в качестве тестового, все остальные сольем в обучающую выборку, обучимся и измерим качество, и так далее. Каждый блок побывает один раз тестовым, получим k показателей качества. Усредним их и получим оценку качества по кросс-валидации. При этом в кросс-валидации снова есть параметр, который нужно как-то выбирать, это число блоков k. Здесь ситуация примерно та же, что и с отложенной выборкой, если блоков мало, например, 3, то, с одной стороны, тестовая выборка при каждом разбиении на обучение и контроль, будет большой, то есть оценка по ней будет надежной, устойчивой, но при этом обучение окажется меньше, чем на самом деле, и есть риск, что оценка будет смещенной. Если же блоков мы берем много, то, с одной стороны, оценки ненадежные, тестовая выборка всегда маленькая, С другой стороны, оценки несмещенные, поскольку обучающая выборка всегда большая. Снова нет конкретных рекомендаций, каким выбирать k, обычно его берут равным трем, пяти или десяти, при этом, чем больше у вас данных, тем, как правило, меньше нужно больше блоков, потому что много блоков нужно, чтобы обучение было побольше, если у вас данных и так много, то даже удаление одной трети от всей выборки не приведет к тому, что у вас данных станет мало для обучения. При этом заметьте, что в кросс-валидации вам нужно обучать алгоритм k раз, поэтому опять же, если обучение алгоритма очень трудоемкое, очень много требует времени, то нужно брать k поменьше. Еще один совет, который относится ко всем этим способам. Всегда перемешивайте выборку перед тем, как делать отложенную выборку или кросс-валидацию. Дело в том, что в файле с данными выборка может быть отсортирована по какому-то неслучайному признаку. Например, сначала могут идти все мальчики, а потом все девочки. И если вы не перемешаете выборку и просто разобьете в соотношении 50 к 50, то получится, что в обучении у вас есть только мальчики, в контроле — только девочки, и, скорее всего, алгоритм будет показывать очень плохое качество, и вы долго будете пытаться понять, почему. Но при этом есть ситуации, в которых выборку нельзя перемешивать и нужно вполне понятным способом разбивать ее на обучение и контроль. Например, если вы строите алгоритм, который будет предсказывать погоду на следующие дни, понятно, что в момент, когда вы будете применять модель, у вас будет информация только о прошлом, и на основе нее нужно будет предсказывать будущее. Поэтому и когда вы будете разбивать выборку на обучение и тест, вам нужно следить, чтобы в обучении были дни, которые идут перед днями в тесте, иначе обучение будет заглядывать в будущее, и качество будет получаться завышенным. Итак, мы обсудили, что для грамотного оценивания качества алгоритма, нужно использовать данные не из обучающей выборки, для этого можно, например, делать отложенную выборку, или же оценивать качество по кросс-валидации. В следующем видео мы поговорим о том, как использовать эти подходы, чтобы сравнивать модели или выбирать гиперпараметры в них.

[ЗАСТАВКА] В этом видео мы поговорим о том, как выбирать гиперпараметры и сравнивать разные алгоритмы с помощью уже изученных нами схем — отложенной выборки или кросс-валидации. Давайте начнем с того, что разберемся, что такое гиперпараметры. Так называются те параметры алгоритмов, которые нельзя настраивать по обучающей выборке. Простым примером гиперпараметра является параметр регуляризации, поскольку регуляризатор штрафует модель и не дает ей слишком сильно подогнаться под обучающую выборку, понятно, что с точки зрения ошибки на обучение оптимально выставить параметр регуляризации в 0, то есть выключить регуляризатор. Другой пример гиперпараметра — это, например, степень полинома, с помощью которого мы описываем данные. В нашем примере про переобучение с точки зрения обучающей выборки оптимально было брать полином в степени 9, поскольку он проходил через через все точки обучения, давал нулевую ошибку на обучение. Но при этом понятно, что обобщающая способность у него была никакая. Более общая задача — это сравнение разных алгоритмов, например, сравнение качества алгоритмов, настроенных с разными значениями гиперпараметров. Или, предположим, вы можете настраивать алгоритмы на среднеквадратичную ошибку и на среднеабсолютную ошибку и пытаться понять, что из этого лучше. Или выбирать типы регуляризации: L2 или L1 — и тоже как-то сравнивать алгоритмы, обученные с разными видами регуляризации. Или сравнивать разные классы моделей, например, линейные модели и решающие деревья, которые будем изучать в следующем модуле. Всё это называется сравнением алгоритмов. Понятно, что для этого нужно использовать либо обучающую... либо отложенную выборку, либо кросс-валидацию, но при этом нужно соблюдать осторожность. Вот почему: давайте рассмотрим пример, в котором мы сравниваем тысячу разных типов алгоритмов с помощью отложенной выборки. Каждый их них мы обучаем на обучающей выборке, измеряем качество на отложенной выборке и дальше выбираем из них лучшие по качеству на отложенной выборке. При этом заметьте, что отложенная выборка, по сути, превратилась в обучающую. У нас было большое семейство алгоритмов, и мы из них выбрали лучшие отложенные выборки. По сути, мы подогнались под нее, и у нас снова появился риск переобучения под отложенную выборку. Чтобы бороться с этим, нужно немножко усовершенствовать нашу схему оценивания качества. Разобьем все данные на три части: на обучение, валидацию и контроль. Каждый из нашей тысячи алгоритмов будем обучать на обучающей выборке и измерять качество на валидационной выборке. Получим тысячу показателей качества и по ним выберем лучший из этой тысячи алгоритмов — тот, который допускает наименьшую ошибку. После того, как лучший алгоритм выбран, мы измерим его качество на контрольной выборке и проверим его на адекватность, то есть что оно устраивает нас. По сути, именно контрольная выборка будет играть роль новых данных. Например, можно проверять, что доля ошибки не слишком большая и отличается от одной второй, то есть от случайного угадывания, от подбрасывания монетки. Или что среднеквадратичная ошибка лучше, чем у константного алгоритма. Если же в вашей схеме предпочтительней использовать кросс-валидацию, нужно разбить выборку на две части. Одна — это контрольная, на которой будет измеряться качество итогового алгоритма, а другая — та, на которой будет делаться кросс-валидация. То есть по стандартной схеме разбивается на K блоков, каждый блок по очереди выступает в качестве контрольного, на нём измеряется качество, а алгоритмы обучены по всем остальным блокам. После того как по кросс-валидации выбран лучший из множества алгоритм, его адекватность измеряется на контрольной выборке. Итак, мы выяснили, что для выбора гиперпараметров или сравнения алгоритмов нужно использовать стандартные схемы: отложенную выборку или кросс-валидацию. Но при этом, если вы сравниваете очень много разных моделей, есть риск переобучения, и чтобы его избежать, нужно выделять контрольную выборку, на которой вы проверяете итоговый алгоритм на адекватность. На этом урок про сравнение моделей заканчивается, и вы узнали много нового. Например, как использовать регуляризацию, чтобы бороться с переобучением линейных моделей, или как строить схему проверки качества, которая позволит понять, насколько хорошо алгоритм будет работать на новых данных.


[БЕЗ_ЗВУКА] В этом уроке мы поговорим с вами про матричные разложения. Мы уже затрагивали эту тему в самом первом курсе и сейчас выясним, как именно матричные разложения можно будет применять в каких-то конкретных задачах. Итак, сначала мы вспомним, что же такое матричные разложения, после этого мы освежим в памяти, что такое сингулярное разложение матриц и выясним, что это значит в машинном обучении. После этого мы поговорим про использование разложения матриц в задачах рекомендаций, затем в задачах анализа текстов и немножко обсудим особенности обозначения. Итак, в задачах про матричные разложения мы пытаемся приблизить исходную матрицу какого-то размера произведением двух других матриц. При этом мы хотим, чтобы если исходная матрица была, например, размера l на d, то матрица U была размера l на k, матрица V транспонированное была размера k на d, причем k было чем-то небольшим. То есть мы пытаемся получить вместо исходной матрицы X две матрицы U и V, которые будут, по сути, представлять собой какое-то новое признаковое описание объектов и изначальных признаков. Как это можно записать? Можно записать, что мы пытаемся приблизить X произведением U и V транспонированное, то есть добиться того, чтобы норма разности была минимальна. Но что за норма? Какую норму можно ввести на матрице? Например, можно ввести норму Фробениуса. Корень из суммы квадратов элементов матрицы. Если воспользоваться нормой Фробениуса, то мы увидим, что вся эта задача выписывается в виде суммы по i и j, квадрат отклонения xij от скалярного произведения ui на vj, где ui — это новое описание i-го объекта, а vj — это новое описание j-го признака. Давайте чуть подробнее разберемся с обозначениями. Изначально мы имеем матрицу l на d, ее мы приближаем произведением матрицы l на k — это матрица U, и матрицы размером k на d — это матрица V транспонированное. Если мы посмотрим на элемент xij, то так как матрицы умножаются — строка на столбец, понятно, что это будет произведение i-ой строки матрицы U и j-го столбца матрицы V транспонированное. Теперь вспомним про сингулярное разложение матриц. Сингулярное разложение — это способ представить некоторую исходную матрицу в виде произведения трех других матриц. Ортогональной матрицы U, диагональной матрицы Σ и ортогональной матрицы V транспонированное. Геометрически это можно проиллюстрировать следующим образом. Мы, конечно, об этом задумываемся не очень часто, но любая матрица задает некоторое отображение, потому что мы можем умножить некоторый вектор на эту матрицу и получить какой-то другой вектор. И если мы рассмотрим матрицу X, как матрицу задающую некоторое отображение, то можно это отображение разложить на составляющие, то есть представить, что сначала мы как-то повернули пространство, потом мы его растянули вдоль осей координат, а потом снова повернули. На самом деле, говоря более точно, здесь могут быть не только повороты, но и вращения некоторых осей, но так или иначе в каком-то простом виде это все выглядит так. Оказывается, что сингулярное разложение матриц может быть полезно для нашей задачи приближения произведением двух матриц. Действительно, давайте представим, что мы ее решаем, решаем по норме Фробениуса, то есть по сумме квадратов отклонений. И вот давайте рассмотрим сингулярное разложение матрицы X на матрицу U «с волной», Σ и V «с волной» транспонированное. Здесь мне пришлось прибегнуть к обозначениям U «с волной» и V «с волной» чтобы не было пересечения с нашими обозначениями для разложения на две матрицы. Можно было бы выбрать какие-то другие обозначения, но так получилось, что и обозначение для разложения на две матрицы, и обозначение для сингулярного разложения достаточно хорошо прижилось. Итак, мы можем понять, что мы получаем в этом сингулярном разложении. Мы получаем представление произведением трех матриц. Теперь давайте у каждой матрицы возьмем какую-то часть — от матрицы U «с волной» возьмем первые k столбцов, от матрицы Σ возьмем квадрат размера k на k, от матрицы V «с волной» транспонированное возьмем первые k строк. И таким образом определим усеченные матрицы из SVD — U «с волной» k-тое, Σ k-тое и V «с волной» k-тое. Оказывается, если мы возьмем в качестве матрицы U U «с волной» k-тое на Σ k-тое, а в качестве матрицы V — V «с волной» k-тое — это будет решением нашей оптимизационной задачи. Это действительно даст наилучшее приближение по норме Фробениуса, это удивительное свойство SVD разложения. При этом обратите внимание, мы могли бы отнести матрицу Σ и к матрице V, а могли бы расписать — корень из Σ для одной матрицы и корень из Σ для другой матрицы. Ну под корнем подразумевается такая же диагональная матрица, только теперь взяты на диагонали не те же элементы, а корни из этих элементов. Ну вот, это в целом указывает на неоднозначность решения задачи матричного разложения, с которой мы еще будем иметь в дальнейшем дело и которую еще вспомним не раз. Так или иначе, часто оказывается, что брать и выполнять SVD разложение — не очень быстрая операция, и в принципе можно мыслить об этой задаче получения матриц U и V просто как самой по себе задаче и оптимизации, и подбирать ui и vj, то есть получаются некоторые профили объектов и профили исходных признаков прямо из этой оптимизационной задачи каким-нибудь оптимизационным методом. Поэтому SVD здесь с какой-то стороны уже ни при чем, мы просто «в лоб» решаем эту задачу. С другой стороны, мы помним, что здесь есть некоторая связь с SVD, и если мы придумываем какое-то решением для этой задачи, примерно такое же решение можно придумать для вычисления усеченных матриц из SVD. Таким образом, в машинном обучении прижилось SVD как матричное разложение по норме Фробениуса, но на самом деле нужно понимать, что здесь речь идет не о сингулярном разложении в обычном смысле, а именно о решении вот этой оптимизационной задачи. Теперь перейдем к применению SVD в рекомендациях. В рекомендациях мы обычно имеем матрицу пользователи-объекты, и пользователи ставят какие-то оценки. Ну вот пример такой матрицы сейчас вы видите на слайде. Матрица заполнена не полностью, и в целом довольно серьезный вопрос: а как же заполнить пропущенные места? Можно вставить нули, можно оставить эти значения неизвестными и адаптировать алгоритмы к этому, но так или иначе, если мы будем использовать матричные разложения здесь, то i-тый j-тый элемент мы будем просто приближать произведением профиля пользователя и профиля объекта. В случае на слайде — профиля фильма. Можно интерпретировать это как интересы пользователя и какие-то параметры фильма. Хотя, конечно, интерпретировать полученные алгоритмические числа на практике, то есть понять, что какое-то число соответствует количеству «экшена» фильма, какое число соответствует длительности фильма, мелодраматичности его, получается очень редко, даже, скорее, не получается. Другой пример — это матрица частот слов. Она часто встречается при анализе текстов, например, если нам нужно классифицировать тексты, кластеризовать тексты, мы непременно построим такую матрицу. И здесь мы снова имеем ситуацию, когда на пересечении i-го и j-го столбца у нас есть некоторые значения, которые можно приближать как скалярное произведение профиля документа и профиля термина. В данном случае профиль можно интерпретировать как какие-то темы, которым соответствует документ и которым соответствует термин. Давайте еще немного поговорим про обозначения. Дело в том, что здесь мы встречаем не просто представление матрицы X в виде произведения U на V, а в виде произведения U на V транспонированное. Возникает вопрос: а зачем понадобилось транспонировать? Ну это просто некоторые эстетические соображения, которые возникли из желания сделать так, чтобы и матрица U, и матрица V представляла собой матрицу количества каких-то сущностей, либо объектов, либо исходных признаков, на количество новых признаков k. Тогда, если мы запишем, что xij у нас приближается скалярным произведением ui на vj, и вспомним, что обычно, когда мы говорим о скалярном произведении, мы имеем в виду скалярное произведение векторов, а векторы мы обычно представляем столбцами, становится понятно, почему можно встретить запись «xij приближенно равно ui транспонированное на vj». То есть это просто расписанное скалярное произведение, сумма покоординатных произведений векторов. Но эта же запись может вызвать вопросы. Действительно, мы записываем таким образом, для того чтобы передать мысль, что строка должна умножаться на столбец. Следовательно, если нам нужно взять скалярное произведение двух вектор-столбцов, нам нужно один из них транспонировать. В то же время изначально ui — это строка в матрице U, а не столбец, и vj — это строка в матрице V. Конечно, не стоит путаться из-за этого и нужно понимать, что имеется в виду именно покоординатное произведение ui и vj, которые были строчками в матрицах U и V. На самом деле мы встречали аналогичную ситуацию, когда говорили о линейных моделях. Действительно, у нас была матрица признаков X, и i-тый объект соответствовал i-той строке в матрице. В то же время когда мы писали скалярное произведение вектора весов w на вектор xi, иногда можно было расписывать — w транспонированное на xi. Хотя xi действительно изначально было строчкой, но в этой записи уже подразумевается столбец. Кроме того, в матричных разложениях встречается много различных обозначений в зависимости от того, для чего они применяются. Часто в рекомендациях используются обозначения U и V для матриц, на которые мы разлагаем исходную матрицу, а также встречаются обозначения P и Q (тоже в рекомендациях), обозначения W и H часто используются в неотрицательных матричных разложениях и в анализе текстов, и даже обозначения Φ и Θ, которые мы будем использовать, когда будем говорить о вероятностных тематических моделях. Мы могли бы выработать какое-то более-менее принятое в рамках нашего курса обозначение, но тогда бы это могло вызвать какие-то сложности при изучении соответствующих статей по той области, которая вас интересует. Поэтому мы решили просто рассказать о том, что обозначения бывают разные, и предупредить, что использовать мы тоже будем разные обозначения. Итак, подведем итог. Мы вспомнили, что такое матричные разложения, вспомнили, что такое SVD в линейной алгебре, узнали, что такое SVD в машинном обучении и что правильно будет говорить не SVD, а матричное разложение по норме Фробениуса. Узнали, как можно применять SVD в рекомендациях, как применяется SVD для анализа текстов, и немножко поговорили про особенности обозначений. В следующем видео мы узнаем, а как же вычислить профили объектов и профили признаков.

Итак, сейчас мы понимаем, что матричные разложения — очень полезная вещь, мы можем их использовать, использовать их уж как минимум в рекомендациях в анализе текстов. И пора бы уже понять, а как мы можем их делать, как нам вычислять профили объектов uᵢ и профили старых признаков vⱼ. В этом видео мы рассмотрим два метода, которые позволяют это делать. Сначала мы вспомним постановку задачи. Затем мы поговорим про градиентный спуск и поймем, что здесь неизбежно придется перейти к стохастическому градиентному спуску, ну и выпишем формулы обновления значений uᵢ и vⱼ. А затем рассмотрим метод, который позволяет решать задачу несколько быстрее, — ALS. После этого мы поговорим о регуляризации, которая в этой задаче очень важна. И все это вместе даст нам возможность обучать профили uᵢ и vⱼ. Итак, постановка задачи у нас достаточно простая. Нам нужно минимизировать функционал (давайте будем пока что рассматривать случай нормы Фробениуса), и в этом функционале у нас рассматривается отклонение xᵢⱼ от скалярного произведения uᵢ и vⱼ. Функционал достаточно прост, поэтому для него мы можем выписать градиент, ну например, по uᵢ. В силу линейности градиента градиент от суммы будет равен сумме градиентов. Здесь у нас возникнет двойка, которую мы можем опустить в дальнейшем (все равно у нас будет некоторый шаг градиента, который возникнет как константа перед антиградиентом). Ну и в конечном счете мы получаем достаточно простую формулу для обновления uᵢ на каждой итерации градиентного спуска. Аналогичную формулу мы получаем для vⱼ. Обратите внимание: в этой формуле есть достаточно большая сумма, то есть сумма большого количества слагаемых. Матрицы, на которых мы используем этот метод, могут быть очень велики. И конечно, считать такую сумму на каждой итерации — не очень интересная затея. Именно поэтому нам неизбежно потребуется метод стохастического градиентного спуска, то есть мы будем брать некоторые случайные слагаемые на каждом шаге и использовать только их. С одной стороны, такой алгоритм очень просто реализовать, и он довольно прост для понимания. И понятно, что, скорее всего, он будет сходиться даже без каких-то дополнительных выкладок. Это почти ясно, почти очевидно. Но в то же время понятно, что сходиться он будет очень медленно. И совершенно неясно, как нам выбирать шаг в градиентном спуске. Если мы возьмем константный шаг, так вообще получится очень медленная сходимость. В этом месте нам может помочь другой метод — ALS. ALS — это сокращение от alternating least squares, и идея этого метода заключается в следующем: в точке оптимума, то есть там, где функционал будет принимать минимальное значение, производные функционала по uᵢ и по vⱼ должны быть равны нулю. Тогда давайте действовать следующим образом: на одной итерации мы вычисляем производную по uᵢ, приравниваем ее к нулю и находим новое значение uᵢ. На другой итерации мы вычисляем производную по vⱼ, приравниваем к нулю ее и находим новое значение vⱼ. И продолжаем делать так до тех пор, пока значения uᵢ и vⱼ не будут стабилизироваться. Можно выписать явно шаги в ALS, увидеть, что у нас получаются достаточно простые выражения и, сделав несложные преобразования, получить задачу в виде задачи решения системы линейных уравнений. Понятно, как такие задачи решать, и понятно, что отсюда мы уже можем выражать uᵢ и vⱼ на каждой итерации. В итоге мы получаем алгоритм, который вы видите на слайде. При этом в этой задаче очень важно, что задача имеет много разных решений. То есть в принципе задача поставлена не совсем корректно. В то же время мы хотим получать некоторые адекватные решения. И в таких случаях, как обычно, мы будем делать регуляризацию, то есть мы добавим некоторые штрафы за большие значения параметров, которые здесь возникают, то есть uᵢ и vⱼ, ну, например, с помощью L2-регуляризаторов. Удивительно, но добавление регуляризаторов очень сильно сказывается на качестве в этой задаче. Казалось бы, совсем маленькая добавка в функционале, но такое значение. Подведем итог. Мы с вами еще раз вспомнили постановку задачи в матричных разложениях по норме Фробениуса. Далее мы обсудили метод градиентного спуска применительно к этой задаче и перешли к методу стохастического градиентного спуска. Затем обсудили ALS и важность регуляризации в этой задаче.

[БЕЗ_ЗВУКА] Сейчас мы понимаем, что из себя представляют матричные разложения и как можно их вычислять. Даже знаем уже целых два метода для этого, стохастический градиентный спуск и IRLS. Теперь стоит поговорить о том, как можно смотреть на эти задачи. Существуют уж как минимум два разных взгляда на задачи матричных разложений. Один взгляд — это получение некоторых новых признаков для объектов и для исходных признаков, а другой взгляд — это прогнозирование неизвестных значений матрицы. Итак, сначала мы поговорим про постановку задачи в рекомендациях, потому что именно к рекомендациям ближе всего такой взгляд на матричное разложение. Затем мы поговорим о том, как именно прогнозируются неизвестные значения в матрице, из каких соображений. Затем — об оптимизируемом функционале, затем — о таких вещах, как сдвиг и базовые предикторы, которые очень часто используются в рекомендациях и представляют собой некоторую специфику матричных разложений в случае задачи рекомендации. А также поговорим о регуляризации по базовым предикторам: поскольку мы введем какие-то новые параметры, регуляризацию нужно будет делать и по ним. Итак, в рекомендациях мы, как уже знаем, имеем матрицу пользователи / оценки. И в этой матрице стоят оценки, которые пользователи поставили тем объектам, которые видели. Ну, например, тем фильмам, которые они смотрели. В то же время какие-то значения неизвестны. Мы можем посмотреть на нашу задачу следующим образом: давайте будем считать, что в известных значениях матрицы мы пытаемся приблизить эти значения как скалярное произведение некоторого профиля пользователя на профиль объекта, ну, например к фильмам. И оптимизировать будем функционал, в котором суммы берем только по известным значениям матрицы, для того чтобы, взяв скалярное произведение профиля пользователя и профиля фильма, получить прогноз оценки, которую пользователь поставил бы фильму, если бы видел его, для тех элементов матрицы, которые нам неизвестны. В этой задаче мы можем добавить учет некоторых дополнительных факторов. Ну, например, если наша шкала оценки подразумевает, что есть некоторая средняя оценка (обозначим ее μ), от которой отталкиваются пользователи при оценивании фильмов, тогда правильнее будет приближать оценки xi-тое j-тое как μ плюс скалярное произведение u-того на v-тое, а μ тоже настраивать, исходя из оптимизационной задачи. Другое соображение: пользователи бывают разными не только в силу своих интересов, но и в силу строгости оценок, которые они ставят фильмам. И какие-то пользователи могут быть предрасположены ставить оценки повыше, какие-то пользователи предрасположены ставить оценки пониже. Поэтому мы можем добавить еще одно слагаемое, b u-тое i-тое. Это базовый предиктор i-того пользователя, который будет отражать предпочтения пользователя в среднем по оценкам, то есть какие оценки в среднем примерно он склонен ставить. Но при этом не стоит считать, что это честное среднее оценок, которые он поставит фильму, потому что не надо забывать, что у нас есть слагаемое μ и еще одно слагаемое, которое мы сейчас добавим, b v-тое j-тое, базовый предиктор по j-тому фильму. Это слагаемое выражает мысль, что каждый фильм тоже может быть в какой-то степени хорош или плох. То есть, если хотите, это слагаемое будет в каком-то смысле приближать рейтинг фильма самого по себе. И теперь слагаемое ui-тое умножить на vj-тое выражает именно взаимодействие интересов пользователя и особенности фильма, без влияния хорошести или плохости фильма, без влияния строгости пользователя и без учета средней оценки, которую пользователь ставит фильмам. Так как мы добавили какие-то новые параметры, уместно обсудить вопрос регуляризации. Добавлять регуляризаторы по новым параметрам тоже нужно. Ну, при этом новых параметров у нас значительно меньше, чем старых, потому что b u-тое i-тое — это просто число, то есть таких чисел у нас по количеству пользователей, и b v-тое j-тое — это тоже число, и таких чисел у нас по количеству фильмов. Ну и для них мы тоже можем добавить оптимизированный функционал l2 регуляризаторы, ну и лучше это все же сделать. Итак, подведем итог. Мы вспомнили постановку задачи в рекомендациях и, исходя из этой постановки, посмотрели на матричное разложение немного иначе. А именно, как на задачу прогнозирования значений в матрице, которых мы пока что не знаем, на основе тех значений, которые нам известны. При этом мы предполагаем, что есть какая-то простая модель, которая описывает оценки, которые ставят пользователи. В самом простом виде это было просто скалярное произведение профиля пользователя ui-того на профиль объекта vj-тое. В более сложной ситуации мы можем добавлять сдвиг и базовые предикторы по пользователям и по фильмам. Кроме того, если мы добавляем какие-то новые параметры, нужно не забыть добавить регуляризаторы, учитывающие эти новые параметры в оптимизационную задачу.

[БЕЗ_ЗВУКА] В этом видео мы поговорим об одной особенной задаче, в которой могут применяться матричные разложения и в которой возникают некоторые сложности с тем, чтобы применить все то, что мы только что уже обсудили. Итак, сначала мы поговорим про задачу рекомендации товаров. Эта задача будет отличаться от рекомендации фильмов или каких-то других объектов, про которые у нас есть рейтинги от пользователей. Затем мы поговорим, почему нельзя делать все так же, как и раньше; выясним, что feedback от пользователей бывает implicit и explicit; сформулируем идею implicit матричных разложений и познакомимся с часто используемым методом implicit ALS. Итак, в случае рекомендации товаров мы уже имеем не матрицу с оценками пользователей для объектов, а имеем матрицу с какими-то событиями, например матрицу покупок. То есть в каких-то ячейках матрицы будут нули, в каких-то — единички, реже — какие-то числа побольше. Но так или иначе у нас будут присутствовать только положительные примеры, то есть случаи, когда человек что-то купил. То есть ему что-то понравилось, и он был готов потратить на это деньги, и он потратил деньги. В то же время у нас не будет примеров товаров, про которые мы точно знаем, что человек никогда это не купит. Мы никогда не можем понять: человек просто не видел этот товар и поэтому не купил, или он его не купил, потому что он ему не нравится. Таким образом, получается, что все известные значения в матрице будут у нас единичками, ну или каким-то числом больше, но давайте для простоты рассматривать случай, когда все значения — единички. Так в принципе может получится, если никакой товар не покупали больше чем один раз. Казалось бы, мы можем применить здесь все те же методы. Но если мы рассматриваем сейчас задачу матричного разложения как прогнозирование неизвестных значений матрицы, то легко сообразить, что на такую матрицу, в которой все известные значения — это единички, легко настроятся константные профили для пользователей и для объектов, которые, конечно, не будут нести никакой содержательной информации. Это наводит на мысль, что что-то не так в нашей постановке задачи. И действительно, у нас есть только примеры, когда что-то человеку понравилось. Примеров, когда не понравилось — нет. И поэтому мы в принципе не можем научить нашу модель понимать, что что-то кому-то нравится не будет. Конечно, такая модель не применима на практике. Таким образом, мы понимаем, что feedback от пользователя может быть implicit (то есть только какой-то один feedback: только позитивный или только негативный) либо explicit, когда есть и низкие оценки, и высокие, как это было в случае задачи рекомендации фильмов. Это наводит на мысль, что нужно адаптировать методы матричных разложений для случая implicit feedback'а. Идея очень простая: давайте заполним неизвестные значения матрицы каким-то числом, например нулем, и давайте настраивать матричное разложение на всей матрице. Если мы будем делать таким образом, мы будем страдать от того, что нули мы тоже пытаемся приблизить и пытаемся приблизить их так же старательно, как пытаемся приблизить ненулевые значения. А это не очень хорошо, ведь в нулях-то мы как раз не уверены, а в значениях, отличных от нуля, уверены достаточно сильно. Поэтому можно схитрить. Можно решать оптимизационную задачу, но каждому слагаемому в этой задаче присвоить некоторый вес, который зависит от того, знаем мы значение матрицы для этого i и этого j или нет. В итоге мы получаем задачу минимизации некоторого взвешенного расстояния между настоящими ответами и нашими прогнозами. При этом в случаях, где стоят нули, мы можем брать веса поменьше, для того чтобы не слишком настраиваться на нули, в которых мы не очень уверены. Таким образом, мы позволяем нашему алгоритму ошибаться в тех ячейках матрицы, где стоят нули в большей степени, нежели в тех ячейках матрицы, где стоят ненулевые элементы. И это достаточно логично с учетом того, что в нулях мы уверены меньше. И достаточно логично, что если нашему алгоритму нужно будет ошибиться в каком-то нуле, для того чтобы лучше прогнозировать известные значения, можно интерпретировать это как то, что этот ноль, скорее всего, результат того, что человек не наблюдал этот объект, а не результат того, что этот объект ему бы не понравился. В частности, для выбора весов часто используют следующую простую формулу: 1 плюс α умножить на модуль значения в этой ячейке матрицы. Обратите внимание: α — это некоторый параметр, который нам нужно подбирать. Ну обычно подбирают порядок значения, то есть перебирают между значениями: 10, 100, 1000. Кроме того, обратите внимание, мы можем использовать этот метод не только для случая implicit feedback'а, потому что у нас стоит модуль, и в принципе мы можем считать, что значения, близкие к нулю, — это значения, в которых мы не очень уверены, а чем больше значение по модулю, тем больше мы в нем уверены. Если ко всем этому добавить оптимизацию с помощью метода ALS, то получится часто используемый на практике алгоритм implicit ALS. Итак, мы поговорили с вами о задаче рекомендации товаров; выяснили, чем она отличается от задачи рекомендации фильмов; выяснили, почему нельзя применить в точности те же методы, которые мы обсуждали до этого; и обсудили проблему implicit feedback'а и построения матричных разложений для этого случая.

В этом видео мы выясним, какие вероятностные соображения стоят за задачей матричных разложений. Сначала мы поговорим о матричных разложениях по норме Фробениуса и их связи с нормальным распределением. После этого мы зададимся вопросом: а какие распределения больше подходят для различных задач? И рассмотрим распределение Пуассона и получающееся из него неотрицательное матричное разложение. В конце мы обсудим другие способы получить неотрицательное матричное разложение, а в следующих видео разовьём эту тему еще более подробно. Итак. В случае построения матричного разложения по норме Фробениуса оптимизационная задача выглядит очень просто. Она в целом напоминает обобщение метода наименьших квадратов просто на случай матриц. В то же время мы помним, как выглядит нормальное распределение и знаем, что нормальное распределение очень часто используется для того, чтобы моделировать какие-нибудь погрешности, шумы и тому подобные отклонения. Поэтому кажется достаточно логичным представить, что значения в нашей исходной матрице — это некоторые истинные значения плюс некоторый нормальный шум. И в такой постановке можно сказать, что просто значения в исходной матрице распределены нормально, где в качестве матожидания выступают истинные значения, и есть некоторая дисперсия. В такой постановке можно записать принцип максимума правдоподобия. И из него постепенно получить всё тот же функционал, который так нам напоминает метод наименьших квадратов, который тоже понятным образом связан с нормальным распределением. С другой стороны, понятно, что нормальное распределение кажется не очень удачным, если значения матрицы — это просто какие-то целые числа. Или если значения в матрицах очень часто оказываются нулями. Возможно, больше бы подошло какое-то другое распределение, особенно в случае целочисленных признаков. Ну, например, в задачах анализа текстов, когда в качестве признаков часто выступают частоты слов. Ну, если мы говорим о признаках счетчиков, то понятно, что здесь лучше всего подходит распределение Пуассона, как мы уже обсуждали в первом курсе. Распределение Пуассона — это дискретное распределение, значения, которые может принимать случайная величина, целочисленные, поэтому, действительно, всё очень хорошо подходит для счетчиков. Давайте в этом случае тоже запишем принцип максимизации правдоподобия, и тогда постепенно, делая преобразования, мы получим некоторое выражение, которое нужно оптимизировать, для того чтобы подобрать профили ui-тое и vj-тое, исходя из предположения, что значения в матрице исходной были распределены по Пуассону с средним некоторым идеальным значением, которое и будут воспроизводить произведения ui-тое * vj-тое. Оказывается, что в этом случае мы получим разложение исходной матрицы на некоторые матрицы с неотрицательными элементами. Такие разложения называются неотрицательными матричными разложениями и особенно хороши, потому что их гораздо легче интерпретировать, чем разложения с отрицательными элементами. В самом деле, если мы пытаемся понять каждую новую компоненту, как какую-нибудь тему, которая представлена в документах, то как нам интерпретировать отрицательные числа, как нам интерпретировать ноль и как интерпретировать положительные? Положительные, понятное дело, должны означать, что тема как-то ярко выражена. Ноль, по идее, может означать, что тема не выражена в этом документе. Но что значат отрицательные числа? Такой проблемы не возникает в случае неотрицательных матричных разложений, а самое главное, некоторыми нормировками все эти числа можно привести к каким-то вероятностям. В случае неотрицательного матричного разложения, использующего распределение Пуассона, мы точно так же можем выписать метод стохастического градиентного спуска и получить простые правила обновления профилей ui-тое и vj-тое. Но в то же время использовать распределение Пуассона — это не единственный способ получить неотрицательные матрицы. Можно, например, по-прежнему использовать норму Фробениуса, но при этом добавлять дополнительные ограничения на значения элементов матрицы. Но об этом ещё будет сказано подробнее в следующих видео. Подведём итог. Мы с вами выяснили, как связана постановка задачи матричных разложений по норме Фробениуса с нормальным распределением, обсудили вопрос выбора распределений и рассмотрели случай распределения Пуассона. Кроме того, мы начали обсуждать с вами неотрицательные матричные разложения.

[ЗАСТАВКА] Привет! С вами Евгений. Из этого видео вы узнаете про неотрицательные матричные разложения — еще один способ факторизации матрицы. Факторизация матриц или представление матрицы в виде произведения двух матриц меньшего ранга — это задача, которую вы в разных постановках уже несколько раз рассматривали. Давайте рассмотрим еще одну постановку. Чтобы вы не расслаблялись, давайте снова сменим все обозначения. Пусть матрица X размера n х m — это то, что нам дано. Мы хотим ее представить в виде произведения матриц W, размера n х r, и H, размера r х m. r, естественно, меньше чем минимум между n и m. Задача поиска таких матриц может быть представлена, как оптимизационная, то есть задача минимизации некоторого функционала D (X, W * H). Этот функционал будет измерять насколько точно наше произведение приближает исходную матрицу X. Особенность задачи неотрицательных матричных разложений, или NMF, заключается в том, что решение W и H мы будем искать в множестве матриц с неотрицательными элементами. Такая постановка часто имеет смысл, если матрицы W и H вы хотите по итогам разложения как-то интерпретировать. Например, эти матрицы могут представлять собой вероятности появления слов в каких-то текстах, документах, или концентрации веществ в растворах и так далее. То есть, если вам важно, чтобы они были неотрицательными, используйте этот метод. Давайте обозначим за X с крышкой произведение W * H. Нас будут интересовать функции потерь D, которые распадаются на суммы функции потерь между ij компонентой исходной матрицы X и ij компонентой матрицы X с крышкой. Такие функции потерь называются сепарабельными. Чаще всего в задаче неотрицательного матричного разложения в качестве функции потерь используют норму Фробениуса, то есть, просто сумму квадратов отклонений X (X с крышкой). В задаче получения неотрицательных матричных разложений есть несколько проблем. Во-первых, она некорректно поставлена. Если мы имеем какое-то решение этой задачи W0, H0, то существует большое количество матриц Y, таких, что W0 * Y и Y в минус первой * H0 также будут решением нашей задачи. Если только у Y существует обратная матрица и преобразование с помощью Y сохраняет неотрицательность элементов матриц W0, H0. То есть, решение никогда не определяется однозначно. Кроме того, функция потерь D и норма Фробениуса, которая берется чаще всего, и многие другие не выпукла по совокупности аргументов W и H, поэтому мы не можем использовать методы, которые находят глобальный минимум нашей функции потерь и вынуждены использовать какие-то методы для бедных. Чаще всего используется блочно-покоординатная минимизация, то есть, мы фиксируем одну из матриц, например, W и обновляем матрицу H, используя какую-то функцию f от исходной матрицы X, матрицы W и матрицы H с предыдущего шага. Затем обновляем матрицу W, используя вот это новое значение матрицы H. И вот так делаем в цикле до тех пор, пока не сойдемся. Поскольку эта задача симметричная, кстати говоря, функция f должна быть очень похожа на функцию g, то есть, в частности она должна быть равна g транспонированное от всех транспонированных элементов. Давайте вернемся к задаче с нормой Фробениуса. Если бы у нас не было ограничения неотрицательности, мы легко получили бы решение с помощью сингулярного разложения. Ну поскольку его нет, будем пользоваться какими-то градиентными методами. Базовым методом для нас будет служить поочередный градиентный спуск, то есть мы будем фиксировать одну матрицу по всем элементам второй матрицы пробегать и делать какой-то шажок в направлении антиградиента. Затем повторять то же самое со второй матрицей. Проблема в том, что градиентный спуск не учитывает ограничение неотрицательности. Это можно как-то исправить. Способ номер №1: мы можем выбрать шаг градиентного спуска так, что обновления наших матриц станут мультипликативными, и тогда знак будет автоматически сохраняться. Посмотрите, как это можно сделать. Частная производная нашей функции потерь по элементу матрицы h с индексами k и j равна разности двух положительных компонент. Возьмем в качестве шага градиентного спуска отношение h kj-го к вот этой первой положительной компоненте из разностей. Если мы теперь это подставим в выражение для градиентного спуска и упростим, мы получим, что наши обновления имеют мультипликативный вид, то есть, старый элемент матрицы просто умножается на какое-то число и это число неотрицательное, вообще говоря, даже 0 не может быть равно. Таким образом, если мы инициализировали нашу матрицу H как-то удачно, и там нет отрицательных компонент, то в ходе итерационного процесса они не могут и появиться. Это то, что нам нужно. В матричном виде такие мультипликативные обновления можно записать следующим образом. Здесь крестик в кружочке обозначает поэлементное умножение матриц, а черточка в кружочке — поэлементное деление. Можно показать, что в алгоритме с мультипликативными обновлениями функция потерь D на каждом шаге монотонно не возрастает, то есть, мы постепенно уменьшаем нашу функцию потерь, ну или, по крайней мере, не увеличиваем, то есть, задача как-то решается. Такие методы очень популярны. Потому что, во-первых, они просты в реализации. Во-вторых, они хорошо масштабируются и легко приспосабливаются к работе с разреженными матрицами. И, кроме того, исторически эти методы были предложены в самой первой статье по неотрицательным матричным разложениям. Однако скорость сходимости таких методов не очень большая. Впрочем, ее можно увеличить, если обновлять матрицы W и H не по одному разу в цикле, а по несколько раз подряд. Задача неотрицательного матричного разложения с нормой Фробениуса может решаться еще несколькими очень эффективными интересными способами. Давайте их тоже рассмотрим. Поскольку, если мы фиксируем одну из двух матриц внутри нашей нормы Фробениуса, мы получим задачу минимизации наименьших квадратов, которую мы можем решать аналитически, кажется, что вот это знание как-то можно использовать для ускорения поиска глобального минимума нашей задачи. Это делает метод попеременных наименьших квадратов. На каждом шаге мы находим точное решение задачи наименьших квадратов по одной из компонент, но, к сожалению, это решение может давать и неотрицательные значения в матрицах. Просто будем все их заменять нулями, то есть будем проецировать нашу матрицу на неотрицательную область. Этот метод быстрый и грубый. Итерационный процесс может не сходиться при таких обновлениях. Функция потерь не монотонна, то есть она может увеличиваться, и это все происходит из-за проецирования. Этот метод можно использовать для инициализации каких-то других более сложных методов. На другом полюсе методов неотрицательного матричного разложения с нормой Фробениуса находится метод попеременных неотрицательных наименьших квадратов. Он действует сначала точно так же, как метод попеременных наименьших квадратов. Мы фиксируем одну из матриц, ищем минимум нашей функции потерь по второй. Но в этом методе мы будем его искать только в области неотрицательности, то есть мы не будем вообще рассматривать в качестве решения матрицы H с отрицательными элементами. Решение такой задачи найти сложнее. Аналитически его записать нельзя. Поэтому этот метод медленнее, но он точнее. Каждая итерация этого метода требует существенных вычислительных затрат, поэтому им можно пользоваться для уточнения решения, которое найдено более простыми методами. Наконец, один из самых эффективных и популярных методов неотрицательного матричного разложения с нормой Фробениуса является метод иерархических попеременных наименьших квадратов. Идея заключается в том, чтобы обновлять матрицы W и H не целиком, а небольшими кусками. Оказывается, что мы можем найти аналитически минимум нормы Фробениуса не только по матрице W, но и по отдельному ее столбцу, или то же самое по строке матрицы H, а затем мы вот этот аналитический минимум будем проецировать на неотрицательную область. Проекция здесь оказывает менее разрушительное действие, чем в методе попеременных наименьших квадратов, поскольку одновременно обновляются только небольшие куски матриц. Такой метод достаточно вычислительно эффективен и сходится он быстрее, чем метод мультипликативных обновлений. Однако он более чувствителен к начальному приближению, то есть матрицы W и H, которые вы подаете на вход, должны быть лучше. Итак, в этом видео мы узнали, что такое неотрицательные матричные разложения. Поставили задачу и узнали, какие у этой задачи есть проблемы, а затем мы зафиксировали функционал потерь нормы Фробениуса и для этого Функционала рассмотрели несколько классических методов получения неотрицательного матричного разложения. В следующем видео мы поговорим о том, какие еще можно брать функционалы потерь и зачем это делать, а также откуда можно брать начальное приближение.

В этом видео мы продолжим разбираться с задачей неотрицательного матричного разложения и посмотрим, какие ещё функционалы потерь можно использовать в этой задаче, кроме нормы Фробениуса, и зачем это делать. А также разберёмся с тем, откуда можно взять начальное приближение для наших оптимизационных методов. Функций потерь можно придумать огромное количество. Единственное, чем мы ограничиваем свою свободу здесь — это сепарабельностью. То есть мы хотим, чтоб наша функция потерь распадалась на сумму поэлементных расстояний между матрицами x и x с крышкой. Кроме того, мы хотим, чтобы это расстояние было всегда неотрицательным, и было равно нулю только, когда x и x с крышкой в точности совпадают. В качестве такой функции потерь можно использовать норму l1, норму Фробениуса, то есть сумму квадратов расстояний между матрицами, обобщённую дивергенцию Кульбака‐Лейблера, дивергенцию Итакура‐Саито, расстояние Хеллингера и так далее, это далеко не полный список. В разных прикладных областях используются разные функции потерь. Во многих биологических приложениях, например, используется норма Фробениуса. В анализе аудиозаписи — дивергенция Итакура‐Саито. В задачах моделирования текстов чаще всего используется обобщённая дивергенция Кульбака‐Лейблера. Почему? Почему какие‐то из функций оптимальные для своих классов задач? Часто функции потерь представляют собой замаскированные правдоподобия. То есть существуют такие плотности p(X), что минимизация функций потерь соответствует максимизации логарифма правдоподобия нашей модели. Норма Фробениуса соответствует аддитивной гауссовской модели. Дивергенция Кульбака‐Лейблера соответствует пуассоновской модели данных, то есть случаю, когда наша матрица x заполнена счётчиками. Дивергенция Итакура‐Саито соответствует мультипликативному гамма‐распределённому шуму, и поэтому хорошо подходит для задач анализа аудиозаписи. Дивергенция Кульбака‐Лейблера, пожалуй, на втором месте по популярности среди всех функционалов потерь и задач неотрицательного матричного разложения. Для неё можно точно так же, как мы сделали для нормы Фробениуса, записать блочно‐покоординатный спуск с мультипликативными обновлениями. И точно так же можно показать, что функция потерь будет монотонно не возрастать при таких обновлениях. Ещё один алгоритм, который решает эту же самую задачу минимизации дивергенции Кульбака‐Лейблера, но немного по‐другому, — это метод PLSA, вы о нём услышите очень скоро. Давайте теперь поговорим об инициализации. Инициализация в задачах неотрицательного матричного разложения играет очень большую роль, поскольку у функционала, который мы минимизируем, очень много локальных минимумов, и сходимость нашего метода именно локальная. В зависимости от того, насколько точно наше начальное приближение, мы получим решение разной степени удачности. Откуда же можно брать начальные приближения? Ну, во‐первых, их можно брать случайными. То есть, мы возьмём наши матрицы w и h и заполним их случайными неотрицательными числами. Можно сделать предварительную кластеризацию столбцов матрицы x каким‐нибудь грубым методом, типа K средних, на r кластеров, а затем инициализировать столбцы нашей матрицы w центроидами этих кластеров, а строки матрицы h инициализировать в соответствии с матрицей смежности. Можно здесь использовать какой‐то грубый и быстрый метод кластеризации. Кроме того, начальные приближения можно получать на основе сингулярного разложения. Вы делаете сингулярное разложение, затем выбираете r собственных троек, относящихся к наибольшим собственным числам, и затем из собственных векторов соответствующих конструируете ваши неотрицательные матрицы w и h. Это и есть начальное приближение. Очень эффективно на любом из полученных одним из этих способов в начальном приближении прогнать несколько итераций итеративных наименьших квадратов. Это улучшает качество приближения. Наконец, один из самых эффективных методов получения качественных начальных приближений — это мультистарт. Он сочетает в себе достоинства нескольких приведённых ранее методов. Вы генерируете 10–20 случайных пар матриц w и h. На каждой паре прогоняете по несколько итераций метода попеременных наименьших квадратов. Затем на каждой из полученных пар делаете 10–20 итераций вашего целевого метода, например метода с мультипликативными обновлениями или метода хаос — какой вам хочется дальше использовать. А затем среди полученных 10–20 пар отбрасываете все, кроме той, на которой значение функционала качества минимальное. Вот эта пара и будет вашим начальным приближением, которое вы дальше подадите на вход интересующему вас методу. В этом видео мы поговорили о том, как выбирать функции потерь в задачах неотрицательного матричного разложения, из чего их можно выбирать, и почему выбираются разные. А также обсудили способы инициализации матриц w и h при построении итерационного процесса.

В этом видео мы поговорим про работу с пропусками. Эта задача решается в большинстве своем методами обучения без учителя. Однако она актуальна и во многих задачах обучения с учителем. Представьте, что у вас есть матрица X и какие-то значения этой матрицы пропущены. Например, можно представить, что строки этой матрицы — это пользователи «КиноПоиска», а столбцы — это разные фильмы. Соответственно элементы матрицы — это оценки, которые пользователи выставляют фильмам. Большая часть людей не посмотрела всех фильмов. Более того, скорей всего, большая часть людей посмотрела какую-то маленькую долю фильмов из всех, что есть в базе «КиноПоиска». Поэтому в нашей матрице X такой, будет огромное количество неизвестных значений. Можно ли пропуски в такой матрице как-то заполнить? Еще одна задача. Если матрица X — это матрица объекты-признаки, на которые мы дальше хотим как-то делать классификацию или регрессию, и в этой матрице есть пропуски. Как это правильно делать? Ключевое предположение всех методов работы с пропусками — это что пропуски матрицы расположены случайно. Это предположение очень сильное и в каждой задаче нужно проверять, действительно ли оно выполняется. Примеры задач, в которых оно заведомо не выполняется, можно привести такие. Представьте, что вы делаете какой-то опрос и среди списка вопросов, которые вы задаете вашим респондентам, есть вопрос про годовой доход. Не все респонденты могут захотеть на этот вопрос отвечать. Более того, может оказаться так, что респонденты с большим годовым доходом чаще будут отказываться отвечать на этот вопрос и тогда в вашей итоговой матрице, которая по итогам опроса у вас составится, будут неслучайные пропуски. Еще один классический пример, взятый из практики венгерского статистика Абрахама Вальда, который работал в США во время второй мировой войны и анализировал повреждения самолетов, которые возвращались с бомбардировок. На основании этого анализа принималось решение о том, какие части самолетов нужно укрепить. Нельзя укрепить весь самолет целиком, потому что от этого он будет плохо летать, поэтому нужно как-то выбрать, какие части самолетов важнее всего. Для того чтобы это понять, собиралась статистика о количестве пулевых отверстий в разных частях самолетов. Это задача, в которой пропуски не просто не случайны, а несут в себе самую важную информацию о нашем признаке, потому что самолеты, которые не возвращаются с боевых действий, получили как раз наиболее критические повреждения. Поэтому Вальд принял решение о том, что укреплять нужно те части самолетов, в которых... на самолетах, которые вернулись, повреждений меньше всего. Эти примеры показывают, что всегда нужно следить за выполнением предположения о случайности пропусков. А теперь давайте разберем, что можно сделать с матрицей X в условиях, когда это предположение выполняется. Ну, во-первых, самый простой способ — можно выбрасывать те объекты, на которых значение хотя бы одного из признаков пропущено. Перед этим, пожалуй, стоит избавиться от признаков, у которых очень много пропусков. Потому что иначе вы оставите себя совсем без выборки. Этот способ очень прост, но, кажется, что он не очень хорош, потому что вы выбрасываете информацию. Поскольку вы исключаете объекты на которых какие-то признаки все-таки померяны. Другая крайность работы с пропусками — это методы, которые эти пропуски пытаются заполнить. Это можно делать большим количеством разных способов. Например, для каждого объекта, для каждой строки xi1, в которой есть хотя бы один пропуск, вы находите самую похожую на нее строку xi2, в смысле какой-то функции потери, и заменяете пропущенное значение в xi1 на соответствующее значение из xi2. Другая крайность — это заполнение пропусков средними или медианами по столбцу. Таким образом, вы не используете никакой информации об объекте, а используете только среднее значение признака во всей вашей выборке. Эти две крайности сочетает друг с другом EM-алгоритм. EM-алгоритм предполагает, что полные данные каким-то образом распределены. Например, имеют совместное многомерное нормальное распределение. И по имеющимся данным оценивает среднее и ковариационную матрицу признаков у этого распределения. Затем пропуски заполняются наиболее вероятными значениями в соответствии с полученной оценкой распределения. Этот процесс повторяется несколько раз, то есть после заполнения пропусков, вы переоцениваете параметры распределения. После получения новых параметров распределения вы заново заполняете пропуски. И так, пока процесс не сойдется. Еще один способ заполнения пропусков — это матричное разложение. Вы можете представить вашу большую разреженную матрицу в виде произведения двух плотных матриц меньшего ранга, а затем пропуски в исходной матрице представить, как значение матрицы X с крышкой равное произведению ваших маленьких матриц. Все эти методы немного подозрительны, поскольку информация в них берется как будто бы ниоткуда. Действительно, у вас были объекты, на которых значения признака было неизвестно, а затем после каких-то магических манипуляций, оно вдруг стало известным. Как это произошло? И правильно ли это? В некоторых задачах, вроде линейной регрессии или метода главных компонент, можно обойтись вовсе без заполнения пропусков. В таких задачах часто матрица объекты-признаки X используется только для подсчета величин вида 1 / l (X транспонированное X), или 1 / l (X транспонированное Y). Значение вот таких матриц можно вычислять только по полным парам, то есть для каждого jk-го элемента матрицы X транспонированное X мы будем считать вот эту сумму только по тем парам X ij-ое, X jk-ое, которые обе не равны NA, то есть они обе не пропущены. И делить будем соответственно не на l, а на число полных пар. При использовании таких методов у вас информация никуда не исчезает, и не появляется ниоткуда. Кажется, что когда этот метод применим, он оптимален. Давайте обсудим еще несколько деталей в задаче заполнения пропусков. Если у вас есть категориальные переменные, некоторые здесь значения которые пропущены, вот эти пропуски удобно закодировать просто отдельной категорией. Этот метод работает, в том числе и для ситуации, когда пропуски у вас неслучайны. Если вы работаете с деревьями или лесами и у вас пропущены значения в каких-то непрерывных признаках, то заполнить их можно каким-то значением, которое сильно отличается от всех типичных значений, значений признака. Например, какими-то очень большими отрицательными признаками. Если вы так поступите, то эти значения будут попадать на ваших деревьях в отдельный лист, и будут обрабатываться отдельно. Заполнение пропусков — это задача творческая. Поэтому к ней нужно подходить вдумчиво в каждой конкретной задаче анализа данных. Если вы используете какой-то метод обучения с учителем и в вашей матрице объекты-признаки есть пропуски, всегда следите за тем, какой метод обработки пропусков зашит по умолчанию в метод, который вы хотите применить. Например, в большей части методов, которые реализуют линейную регрессию, по умолчанию зашито отбрасывание объектов, на которых есть пропуски — не очень хороший метод. Например, в методе xgboost по умолчанию используется какой-то свой собственный, достаточно сложный метод обработки пропусков и, таким образом, метод xgboost можно использовать с пропусками менее вдумчиво. В этом видео мы поговорили про пропуски в матрице X и о том, как в разных ситуациях эти пропуски либо нельзя игнорировать, либо можно заполнять, либо можно выбрасывать, либо можно обрабатывать как-то еще по-другому. Если вы анализируете данные, в которых есть пропуски, имеет смысл посвятить какое-то время обдумыванию того, как их правильно обработать. За счет этого часто можно получить существенный выигрыш, что видно, например, на многих конкурсах, на сайте кэгл.
[БЕЗ_ЗВУКА] Привет! С вами Евгений. В этом уроке мы поговорим о том, как в теории вероятностей и математической статистике изучаются случайные события, и какие основные математические инструменты для этого используются. Большинство явлений окружающего мира слишком сложны для того, чтобы их можно было описать простыми детерминированными законами. Например, мы не можем абсолютно точно предсказывать атмосферные явления, несмотря на то, что мы очень хорошо понимаем, по каким законам живут отдельные молекулы атмосферы. Их просто слишком много, и в их взаимодействии участвуют слишком много факторов, для того чтобы мы могли построить исчерпывающую прогнозирующую модель. Намного более простой процесс — это подбрасывание кубика, но даже его результат мы никогда не можем предсказать, если, конечно, не жульничаем. Вместо того чтобы пытаться построить какую-то исчерпывающую, заведомо слишком сложную физическую модель подбрасывания, мы можем сделать шаг назад и представить, что мы имеем дело с неким черным ящиком, внутреннее устройство которого мы даже не будем пытаться определить. Этот черный ящик по каким-то своим неизвестным нам законам генерирует случайные события, соответствующие числам, выпадающим на кубике. Такие черные ящики в математике называются случайными величинами, а события, которые они генерируют, — реализациями этих случайных величин. Набор реализаций случайной величины называется выборкой из нее. Мы никогда не сможем сказать, какое событие произойдет в следующий момент наблюдения черного ящика, но если мы будем вести эти наблюдения достаточно долго, мы сможем начать замечать некоторые закономерности. Например, если мы честно подбрасываем кубик, то каждое число на нем будет выпадать примерно одинаковое количество раз. Именно такие закономерности и изучают теория вероятностей и математическая статистика. Если мы будем проводить эксперимент со случайной величиной бесконечно, то в этом бесконечном эксперименте каждому событию мы сможем поставить в соответствие его вероятность — эту долю испытаний, в которых событие произошло. Эта вероятность никогда не может быть измерена на практике, потому что в ее определении зашито, что последовательность испытаний бесконечна. Теория вероятностей изучает модели случайных величин, свойства этих моделей и то, какие выводы можно сделать о том, какие события будут нас ожидать при проведении испытаний со случайными величинами в будущем. Статистика и анализ данных действуют в обратном направлении. Мы имеем дело с конечными выборками, и по этим конечным выборкам мы пытаемся определить свойства нашего черного ящика случайной величины и понять, как эта случайная величина будет себя вести в будущих испытаниях. Совершить такой переход позволяет закон больших чисел. Крайне нестрогая его формулировка звучит следующим образом: вероятность любого события может быть приближена частотой этого события, если выборка достаточно большая. Итак, в этом видео мы поговорили о том, чем отличаются теория вероятностей и математическая статистика, как они изучают одну и ту же обобщенную модель случайности с разных сторон. Мы дали определение вероятности как частоты события на бесконечной выборке и договорились, что закон больших чисел позволяет нам оценивать эту вероятность с помощью частоты события на конечной выборке. В следующих видео мы обсудим свойства вероятностей, часто используемые распределения и процессы, которые они могут описывать, мы познакомимся с основными средствами работы со случайными величинами. И все это мы будем делать на уровне, достаточном для интуитивного понимания последующего материала. Теория вероятностей — достаточно сложная наука, но мы абсолютно не будем затрагивать ее фундаментальный контекст. К счастью, для того чтобы делать анализ данных, совершенно необязательно знать, что такое сигма-алгебра или уметь брать интеграл по мере Лебега.

[БЕЗ_ЗВУКА] В предыдущем видео мы разобрались, что такое вероятность. Давайте теперь посмотрим, какими свойствами она обладает. Вероятность любого события A всегда лежит на отрезке от 0 до 1. Невозможное событие (событие, которое никогда не может произойти) мы будем обозначать значком пустого множества. Вероятность такого события, естественно, равна нулю. Как ни странно, существуют события, вероятность которых равна нулю, но при этом невозможными они не являются. Примеры таких событий мы увидим дальше, когда будем изучать непрерывные случайные величины. Для любого события A можно определить событие не A, которое означает: A не произошло. Вероятности таких событий A и не A в сумме дают единицу. Если мы имеем дело с парой событий A и B, они могут вступать друг с другом в разные отношения. Давайте рассмотрим некоторые из них. Первое отношение — это отношение вложенности. Чтобы лучше его понять, представьте, что вы стреляете из арбалета по мишени. И пусть событие A — это попадание в десятку, а событие B — это набор 5-ти или больше очков. Ясно, что событие A вложено в B, область, которая соответствует A, в буквальном смысле на мишени лежит внутри области, которая соответствует B. Для таких вложенных событий выполняется следующее неравенство. Вероятность A меньше либо равна вероятности B. Давайте теперь определим произведение и объединение событий. Пусть A — это попадание в синюю область на мишени, а B — это попадание в зеленую. Событием произведением AB мы будем называть такое событие, при котором и A, и B одновременно выполняются. А событием суммой A + B — событие, при котором выполняется хотя бы одно из двух событий A и B. Вероятности таких событий — суммы и произведения — связаны друг с другом следующим тождеством: вероятность события суммы равна сумме вероятностей событий компонент за вычетом вероятности события произведения. Теперь, когда у нас есть сумма и произведение, мы можем еще ввести разности. Рассмотрим отношение дополнения между событиями. Событием B без A мы будем называть событие произведение B и не A. Событием A без B, соответственно, произведение A и не B. Вероятность события B без A равна разности вероятностей события B и произведения AB. Если A целиком лежит внутри B, если A вложено в B, то эта формула упрощается. Допустим, снова A — это попадание в десятку, а B — это набор 5-ти или больше очков. Событием B без A будет набор от 5 до 9 очков. Вероятность такого события равна разности вероятностей событий B и A. Введем теперь понятие независимости событий. Пусть событие A — это попадание в нижнюю половину мишени, а событие B — это попадание в ее правую половину. Согласно только что введенному определению, событием AB будет попадание в нижнюю правую четверть мишени. Событие A и B называются независимыми, если вероятность события AB равна произведению вероятностей событий компонент A и B. Если не дует ветер и вы попадаете в мишень каждый раз, то вероятность события A = 1 / 2, вероятность события B также равна 1 / 2. Вероятность события AB (попадания в правую нижнюю четверть) равна 1 / 4. Для этих событий выполняется определение независимости, они независимы. Итак, в этом видео мы ввели простейшие свойства вероятности. Мы поняли, как определяются вероятности сумм, произведений и дополнений событий, а также определили понятие независимости событий. В следующем видео мы поговорим про условную вероятность.

[БЕЗ_ЗВУКА] В этом видео мы с вами разберемся с условными вероятностями. В предыдущем видео, когда мы приводили пример независимых событий, мы неявно ввели некоторое свойство, рассматривая вероятность какого-то события при выполнении некоторых условий. Давайте теперь это свойство введем более формально. Пусть событие A — это попадание в десятку на мишени, а событие B — это попадание хотя бы куда-нибудь в мишень. Если вы точно знаете, что B произошло, вероятность события A для вас повышается. Именно для того, чтобы это квантифицировать, используется аппарат условной вероятности. Условной вероятностью события A при условии B называется отношение вероятностей события произведения AB к вероятности B. Это соотношение, естественно, определено только при условии, что вероятность события B не нулевая. Пусть вероятность попадания куда-нибудь в мишень равна 0,8, вероятность попадания в десятку — 0,05. Вероятность события произведения AB равна также 0,05, поскольку A целиком лежит внутри B. Тогда по определению условной вероятности вероятность A при условии B равна отношению 0,05 к 0,8, то есть примерно 6 %. Эта вероятность выше, чем если мы не уверены, что попали в мишень. Вероятность события A можно расписать в виде суммы произведений вероятностей событий A при условии B и B, и событий A при условии не B и не B. Такая формула называется формулой полной вероятности. Еще одна важная формула связывает условные вероятности A при условии B и B при условии А. Это формула называется формулой Байеса, и она широко используется в байесовской статистике. Вы еще не раз встретите эту формулу на протяжении нашей специализации. Итак, в этом видео мы поговорили про условную вероятность. Мы дали ее определение и рассмотрели две важные формулы. Это формула полной вероятности и формула Байеса. В следующем видео мы поговорим про дискретные случайные величины и узнаем, что это такое и как их можно использовать.

Это видео про дискретные случайные величины. Мы разберемся, что это такое и рассмотрим 3 самых популярных дискретных распределения. Чтобы лучше понимать дискретную случайную величину, давайте вернемся к примеру с подбрасыванием кубика. Это испытание, у которого может быть только 6 исходов. Перенумеруем эти исходы согласно тому, что выпадает на кубике, и поставим этому множеству исходов в соответствие вектор вероятностей длины 6. Все эти вероятности неотрицательны, и в сумме они дают единицу. Именно так устроена дискретная случайная величина. Она принимает значение из счетного множества A (множество называется счетным, если его элементы можно перенумеровать), и вероятность того, что X будет равно aᵢ равна pᵢ. Все pᵢ неотрицательны и в сумме дают единицу. Прекрасно. Одна из наиболее популярных дискретных случайных величин — это дискретная случайная величина с двумя исходами. Представьте, что вы подбрасываете монетку. Будем называть выпадение решки успехом и обозначать за единицу, выпадение орла, соответственно, неуспехом и обозначать за 0. Пусть вероятность успеха равна p. Поскольку исходов всего два, то вероятность неудачи равна 1 − p. Именно так устроена бернуллиевская случайная величина. Она имеет единственный параметр p, который принимает значение от 0 до 1. Следующий пример — это случайная величина, являющаяся суммой независимых бинарных случайных величин. Представьте, что вы бросаете мяч в баскетбольное кольцо. И пусть вероятность попадания равна p. Если вы это делаете так же плохо, как я, то возможно p = 0,2. Пусть у вас есть n попыток, и X — это число попаданий. Поскольку все попытки независимы, вероятность, например, того, что вы попадете в кольцо ровно n раз, равна p в степени n. Вероятность того, что за n попыток вы ровно k раз попадете в кольцо, равна произведению Cnpk (1 − p) в степени n − k. Cnpk, напомню, это биномиальный коэффициент, равный отношению факториалов n, k и n − k. Такая случайная величина x называется биномиальной. Биномиальное распределение имеет два параметра: n целочисленный и p от 0 до 1. Наконец, следующий класс дискретных случайных величин — это счетчики. Возьмем произвольный текст на русском языке. Например, текст романа Набокова «Приглашение на казнь». Составим словарь из всех произведений Набокова и пройдемся с этим словарем по тексту романа, посчитаем, сколько раз каждое слово из словаря встречается в романе. Некоторые слова не встречаются ни разу, например, «шахматист» или «родина». Есть слова, которые встречаются редко. Например, слово «аляповатость» встречается в романе 1 раз. Есть слова, которые встречаются очень часто. Например, слово «год» и все его словоформы встречается 21 раз. Неудивительно, «год» — это самое популярное существительное в русском языке. Пусть X — это число использований слова в тексте. Каким распределением можно описать эту случайную величину? Чему равна вероятность того, что X равно k? Оказывается, что эту вероятность можно неплохо описывать распределением Пуассона. Это распределение с единственным параметром лямбда, это параметр неотрицательный. И меняя значение параметра, можно описывать огромный класс событий, связанных с подсчетом чего-либо. Например, распределением Пуассона очень хорошо описывается число автобусов, которые проходят за час мимо автобусной остановки. Или число изюма в булочках с изюмом. Или число радиоактивных распадов, которые улавливает счетчик Гейгера. Итак, в этом видео мы поговорили про дискретные случайные величины, дали определение дискретной случайной величины и рассмотрели 3 наиболее часто встречающихся распределения — это бернуллиевское, Пуассона и биномиальное. В следующем видео мы поговорим про непрерывные случайные величины.

В прошлом видео мы научились работать с дискретными случайными величинами. В этом давайте разберемся с тем, как работают непрерывные. Перед вами определение дискретной случайной величины, она принимает значение из счетного множества A с вероятностями, которые задаются с помощью функции вероятности, то есть для каждого ai из A, мы знаем, с какой вероятностью наша случайная величина принимает это значение. Если мы пытаемся обобщить это определение на случай непрерывных множеств, у нас возникает проблема со словом счетный. Дело в том, что по таким множествам, как множества всех действительных чисел или интервалы на действительной оси, счетными не являются. Поэтому вероятность любого события из такого множества будет в точности равна 0. Поэтому непрерывные случайные величины нельзя задавать с помощью функции вероятности. Их нужно определять как-то по-другому. Давайте посмотрим на два способа. Способ первый: функция распределения. Функцией распределения называется такая функция F (x), что она равна вероятности того, что случайная величина не превышает этого значения x. Что нужно знать о функциях распределения? Они всего выглядят примерно вот так. Поскольку это вероятность, они принимают значение от 0 до 1. Причем единице они равны где-то справа на числовой оси, а нулю где-то слева. Кроме того функции распределения всегда не бывают по аргументу x. Второй способ — это плотность распределения. Плотностью называется такая функция f (x), что ее интеграл по любому отрезку ab равен вероятности того, что наша случайная величина x попадает в этот отрезок. Плотности связаны с функциями распределения следующим образом: интеграл от плотности, от минус бесконечности до x равен функции распределения. Кроме того, интеграл от плотности по всей числовой оси всегда равен 1, потому что это вероятность того, что случайная величина принимает значение между минус бесконечностью и плюс бесконечностью. Естественно, наша случайная величина делает так всегда. Плотности, в отличие от функции распределения, могут выглядеть очень по-разному. Например, вот так… или вот так, или так, или даже так… Их существует огромное количество, они очень разнообразны. В разных семействах распределения плотности выглядят по-разному. Это их достоинство, потому что плотности визуально легче отличить друг от друга, чем функции распределения, функции распределения всегда примерно одинаковые. Давайте теперь рассмотрим несколько примеров непрерывных случайных величин. Пример 1: случайные величины, имеющие равномерное распределение на отрезке. Представьте, что вы подходите к перекрестку, на светофоре горит красный свет, пусть x — это время ожидания на светофоре до того, как вы сможете перейти дорогу. Если на светофоре нет счетчика, вы не можете угадать, сколько именно времени вам придется прождать. Это может быть любое число от 0 до 30 секунд, допустим, если это максимальное время ожидания на светофоре. Именно так устроено равномерное распределение. Случайная величина имеет равномерное распределение на отрезке ab, если она принимает любое значение на этом отрезке с одинаковой вероятностью. Вот так выглядит функция плотности вероятности для равномерной случайной величины. Она равна 1 / (b − a) везде на отрезке от a до b, и 0 везде вне этого отрезка. График этой функции представляет собой вот такой прямоугольник, длина которого равна b − a, а высота — 1 / (b − a). Если мы найдем площадь этого прямоугольника, перемножив длины сторон, мы получим 1. Прекрасно, поскольку интеграл от плотности распределение и должен быть всегда равен 1. Следующий пример — нормальное распределение. Представьте, что вы любите приходить на работу к 11 или может быть даже лучше к 12, но вряд ли вам удается каждый день входить в ваш рабочий кабинет с последним ударом часов. Скорее всего, точное время вашего прихода на работу немного варьируется. Иногда рано утром вас может разбудить ваш кот, и вы не сможете отказать себе в удовольствии прийти на работу пораньше, а иногда вы слишком долго стоите на светофоре и немного опаздываете. Таким образом, точное время вашего прихода на работу представляет собой результат взаимодействия большого количества слабо связанных друг с другом случайных факторов. Именно такие величины хорошо моделируются нормальным распределением или еще его называют Гауссовским. Нормальное распределение имеет два параметра: параметр μ отвечает за среднее (в нашем примере это среднее время прихода на работу), а параметр σ определяет разброс вокруг этого среднего. Вот так выглядит функция плотности вероятности нормального распределения. График этой функции немного напоминает эту шляпу. Варьируя значения параметров μ и σ можно влиять на форму графика функции плотности вероятности нормального распределения. μ отвечает за положение «шляпы» на числовой оси, а σ за ее форму. Если σ велико, то «шляпа» получается широкая и плоская, а если мало, то наоборот, узкая и высокая. А еще нормальное распределение может быть многомерным, то есть задавать не скалярную, а векторную случайную величину. В таком случае параметры нормального распределения тоже будут многомерными. Так, если случайная величина имеет размерность k, то μ также будет вектором размера k, а σ — матрицей размера k х k, которая должна быть еще к тому же положительна определена. Перед вами функция плотности вероятности нормального распределения и вот ее график для двумерного случая. Очень похож на эту «шляпу». Итак, в этом видео мы узнали, что такое функция распределения и функция плотности вероятности, а также рассмотрели два самых популярных непрерывных распределения — нормальное и равномерное на отрезке. Далее вам будет предложен IPython Notebook с примерами генерации случайных величин и построение разных красивых картинок о распределениях. Я советую вам его внимательнее изучить, это понадобится вам для домашней работы. Это последнее видео в этом уроке, поэтому давайте подведем небольшие итоги. В течение этого урока мы познакомились с механизмом, с помощью которого в математике изучаются случайные явления и рассмотрели подробно первую компоненту этого механизма — теорию вероятностей. Мы узнали, что такое случайные величины, и какие у них бывают распределения, а также познакомились с этой «шляпой». В следующем уроке мы продолжим говорить о случайности и займемся второй компонентой механизма — статистикой.
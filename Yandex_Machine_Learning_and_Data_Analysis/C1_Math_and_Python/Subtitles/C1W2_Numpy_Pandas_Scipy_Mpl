[БЕЗ_ЗВУКА] В этом видео мы начнем знакомство с библиотекой Pandas. Pandas — очень мощный инструмент для анализа данных Python. Pandas позволяет нам работать с данными в виде таблиц. Это очень естественное представление данных в задачах анализа. Например, если мы решаем задачу классификации данных, то часто мы работаем с матрицей «объект-признак». В этом случае по строчкам у нас идут объекты, а по столбцам — их признаки. Опять же, если мы решаем задачу построения рекомендательных систем, снова мы работаем с таблицами. Мы работаем с таблицей User right, ну или с матрицей предпочтения. Итак, переходим к нашей библиотеке. Сначала нам нужно ее импортировать. Делаем это с помощью команды import. [ПЕЧАТАЕТ] Я использую стандартное сокращение pd, вы будете часто это встречать в коде. Итак, основное в структуре данных, которое позволяет нам работать с таблицами, является Data Frame. Data Frame можно представлять себе как такую двумерную матрицу или как dict-like container для работы c Series. Series — это обычный одномерный drr массив, он отличается от простого массива только тем, что в простом массиве у нас все элементы проиндексированы от 0 до размера массива −1, а тут у нас элементы могут иметь лейблы, то есть это могут быть, в принципе, произвольные имена. Итак, создадим нашу первую таблицу, или наш первый DataFrame. Сделаем это с помощью словаря. Пусть наш DataFrame состоит всего лишь из двух столбцов. Первый столбец будет числами, второй столбец будет каким-нибудь повторяющимся символом. Ну так, теперь создаем наш словарь. [ПЕЧАТАЕТ] [ПЕЧАТАЕТ] Итак, мы сделали табличку, теперь давайте выведем ее на экран и посмотрим, как она выглядит. Итак, мы видим, что названия столбцов соответствуют нашим ключам в словаре, и значения соответствуют тому, чем мы их заполнили. Довольно удобно. Но на самом деле такой способ создания DataFrame будет использоваться не так часто, потому что обычно мы хотим анализировать какие-то внешние данные, а эти данные часто хранятся в виде файлов или в виде набора файлов. Поэтому нам удобнее будет считывать эти данные в DataFrame и дальше работать с ними, как с таблицами. Вот давайте попробуем такое сделать. Для этого есть функция read_csv. Она позволяет нам считывать данные с каким-то стандартным разделителем и далее работать с ними, как с таблицей. Создадим новый объект и считаем на него специально заготовленный файл. [ПЕЧАТАЕТ] В качестве первого аргумента передаем имя этого файла. [ПЕЧАТАЕТ] Дальше нам нужно указать, есть ли в нашем файле заголовки. В нашем файле они есть, они находятся в первой строчке. И дальше нужно написать, какой разделитель у нас используется. В данном случае мы используем табуляцию. Итак, мы считали наш файл в таблицу, давайте на него посмотрим. [ПЕЧАТАЕТ] Видим, что получилась небольшая табличка. Она состоит из шести строк и четырех столбцов. Наши столбцы имеют имена (они перед вами в верхней строчке), и строки опять проиндексированы. Кстати, чтобы обратиться к именам столбцов или чтобы их поменять, есть специальный атрибут, называется columns. Таким образом, можно к нему обратиться через точку. И вот мы видим все наши имена столбцов. Также довольно полезный атрибут – shape. С помощью него можно посмотреть на размер нашей таблицы. Ну сейчас табличка маленькая, мы и так представляем себе ее размеры, а когда таблица довольно большая, то это полезно. [ПЕЧАТАЕТ] Итак, мы научились создавать DataFrame, а теперь давайте потренируемся их модифицировать. Мы можем удалять и добавлять строчки, удалять и добавлять столбцы. Давайте начнем с простого и добавим в конец нашего DataFrame новую строчку. Строчку будем добавлять в виде словаря. Это далеко не единственный способ добавления строки, но он довольно простой. Для начала давайте создадим такой словарь. Назовем его new_line, потому что он будет являться впоследствии новой линией в нашем DataFrame, в нашей таблице. Ну и давайте заполним какие-нибудь значения. Допустим, заполним имя. Ну давайте еще заполним дату рождения. Ну вот можно еще заполнить город. [ПЕЧАТАЕТ] Итак, наш словарь готов. Теперь с помощью команды append нужно его добавить к нашему DataFrame. Вызываем во frame метод append. В качестве первого аргумента передаем наш словарь. И еще указываем аргумент ignore_index = True, потому что нам не так важно, под каким индексом добавится наша новая строчка. Так, сделали команду, видим что в конце DataFrame добавилась новая 6-я строка с тем, что мы заполнили. Давайте еще раз выведем на печать наш DataFrame. Так. Видим, что здесь этих изменений нет. Почему это произошло? Ну потому что команда append, на самом деле, работает не inplace, то есть она никак не изменяет наш исходный DataFrame. Она вносит нужные изменения и возвращает нам его копию. Если же мы хотим, чтобы наш DataFrame изменился, то нужно немножечко модифицировать нашу команду. Ну опять же, как вариант можно сделать вот так. Тогда, если мы снова выведем на печать наш DataFrame, то увидим, что он изменился. Действительно добавилась новая строчка. Теперь давайте добавим новые столбцы. Это делается довольно просто, потому что наш DataFrame можно представлять себе как такой словарь Series. Если мы добавляем новый объект к словарю, то как мы делаем? Мы просто указываем значение нового ключа и добавляем объект. Вот давайте здесь поступим по аналогии. Итак, пишем его название. И дальше более-менее случайно давайте его заполним. [ПЕЧАТАЕТ] Итак, готово. Выводим наш DatаFrame на экран и видим, что добавился новый столбец. Так, с добавлением более-менее разобрались. Теперь давайте что-нибудь удалим. Ну сначала можно удалить некоторые строчки. Вот давайте последние две строки удалим. Для этого существует команда drop. Сначала указываем, какие именно объекты мы удаляем. Если мы удаляем строчки, то нам нужно указывать название индекса. Ну то есть названия этой оси. Так, ну вот смотрим: давайте удалим две последних строки, у них номера 5 и 6. Указываем, что эти номера мы указываем по оси 0, и запускаем. Видим, что наш DataFrame стал на 2 строки короче. Но в drop есть такая же особенность, как и у функции append. Она тоже работает не inplace. Поэтому если мы еще раз выведем на экран наш DataFrame, то мы обнаружим, что все строчки на месте. Чтобы это поправить, нужно в предыдущей команде добавить аргумент inplace = True. Но если мы действительно хотим удалить эти строчки из исходного DataFrame. Итак, запускаем и проверяем: действительно строчки удалились. Аналогично можно удалить столбцы. Здесь нам снова понадобится функция drop. Только в данном случае нам нужно будет обращаться уже не к индексам, а к именам наших столбцов. Вот давайте удалим тот столбец, который мы с вами недавно создали. Мы обращаемся к нему по имени. Так, только обратиться нужно правильно, иначе ничего не получится. Так, дальше указываем, что мы работаем с осью 1. Ну и давайте тоже сделаем это сразу inplace. [ПЕЧАТАЕТ] Так, готово. Выводим наш DataFrame на экран и видим, что все получилось. Наш столбец пропал. Часто, после того, как мы проделываем какие-то манипуляции с DataFrame, например чистим данные, добавляем новые столбцы, вычисляем какие-то новые значения, нам хочется сохранить результат в виде файла, чтобы в дальнейшем с ним работать. Pandas позволяет нам сделать это с помощью простого метода. Он называется to_csv. Давайте запишем наш новый получившийся DataFrame в файл. Для этого вызываем эту функцию — to_csv. И давайте теперь аккуратненько запишем, заполним ее аргументы. Для начала нужно написать название файла, в который мы хотим сохранить наш DataFrame. [ПЕЧАТАЕТ] Ну давайте придумаем какое-нибудь простое название — updated_dataset. Дальше у нас есть очень много свободы в том, как именно мы будем сохранять наш файл. Например, мы можем выбрать другой сепаратор, не тот, который был изначально. Вот давайте для разнообразия теперь укажем запятую. Дальше мы можем решать, хотим ли мы оставить header в нашем файле. Ну давайте оставим. Напишем header = True. И то же самое можно сделать с индексами. В данном случае индекс нам не очень полезен, поэтому давайте записывать его не будем. Напишем, что индекс нам не нужен. Так, запускаем команду. И теперь давайте убедимся, что наш файл выглядит именно так, как мы ожидаем, — наш DataFrame через запятую, с заголовком и без индекса. Сделаем это с помощью команды cat. Так, теперь нужно написать название нашего файла: updated_ dataset.csv. Так, значит, где-то мы опечатались. Так. Ну вот так получше. Видим, что действительно в первой строчке идут header, дальше идет наша таблица, все данные через запятую. Ровно то, что мы хотели. На этом мы заканчиваем наше первое знакомство с Pandas. А на следующем видео мы продолжим говорить о DataFrame. Мы изучим еще несколько полезных функций и научимся работать с индексами. Также мы будем делать выборки из таблиц.

[БЕЗ_ЗВУКА] В этом видео мы продолжаем работать с библиотекой Pandas. Мы узнаем еще несколько полезных функций для работы с Data Frame, а также поговорим об индексации и селекции. Для начала импортируем нашу библиотеку. Далее снова создаем Data Frame. Делаем это с помощью уже знакомой нам функции read.csv [БЕЗ_ЗВУКА] [БЕЗ_ЗВУКА] Итак, наш Data Frame перед вами. Первое, что хочется сделать, это посмотреть, какого типа наши столбцы. Это делается с помощью dtypes. [БЕЗ_ЗВУКА] Мы видим, что все столбцы имеют тип object. Если присмотреться повнимательнее к нашему Data Frame, то можно заметить, что столбец Birth соответствует дата рождения. А в Python есть специальный тип datetime для работы с датами. Если мы сделаем наш столбец типа datetime, то нам будет удобнее с ним работать, потому что мы сможем вызывать специфичные для datetime функции. Это можно сделать с помощью метода Apply. Давайте посмотрим, как он работает. Сразу скажу, что метод Apply тоже работает не inplace, поэтому воспользуемся уже привычным синтаксисом с присваиванием. Вызываем метод Apply. Итак, что мы хотим? Мы хотим применить к нашему столбцу функцию, которая поменяет его тип. Вот давайте вызовем функцию to.datetime. Это также функция модуля Pandas. Так, вызываем нашу функцию. И теперь смотрим, как изменился наш Data Frame. [БЕЗ_ЗВУКА] Сначала можем просто вывести его на печать. Видим, что немножечко изменился формат записи наших дат. А теперь убедимся, что тип также изменился. Снова высылаем dtypes. И видим, что, действительно, колонка Birth изменила свой тип. Теперь это datetime, теперь мы сможем с ней работать, как с датой. А следующая полезная функция, которую мы изучим, это функция info. Она позволяет нам получить мини сводку по нашему Data Frame. Мы видим список всех колонок, которые у нас есть, видим, сколько там ненулевых объектов. Вот мы видим, что в колонке Position есть два нулевых значения. Также мы видим, какие типы данных у нас используются, и сколько места тратится на хранения нашего Data Frame. Мы видим, что наш Data Frame содержит пропущенные значения. Это пропуски – столбцы Position. Не все должности заполнены. Нам не всегда удобно работать с пропущенными значениями в том виде, в котором они есть, и часто мы хотим их на что-то заменить и чем-то их заполнить. Давайте это сделаем и в нашем случае. Например, предположим, что откуда-то из наших опорных данных мы знаем, что везде, где позиция пропущена, она соответствует должности «разнорабочий». Давайте так и заполним. Для этого можем воспользоваться методом Fillna. [БЕЗ_ЗВУКА] В качестве аргумента передаем то значение, которое мы хотим заполнить наши пропуски. Мы с вами просто пишем строчку «разнорабочий». И сразу говорим, что мы хотим это делать inplace. Итак, запускаем. Убираем лишнюю букву «a». И еще раз запускаем. Теперь давайте посмотрим, как выглядит наш Data Frame после изменений. На экране появился Data Frame без пропусков. Теперь все наши пропуски заполнены значением «разнорабочий». Но на самом деле в данном случае мы видим, что наши изменения коснулись только одного столбца. Часто нам удобней вывести его отдельно. Это можно сделать, обратившись к нему по имени через точку. Например frame.Position. Видим, что нам вывелся только один столбец. Причем он вывелся, как serias, то есть как обычный массив. Если мы хотим вывести его в виде Data Frame, то есть чтобы было видно саму таблицу, то нужно обратиться к нему несколько иначе. Указываем значение нашего столбца, вернее его имя, Position. И видим, что теперь он вывелся в привычной для нас форме в виде таблицы. На самом деле аналогичным образом можно вывести любой набор столбцов. Давайте выведем имя и позицию, Name и Position. И аналогично можно поступать со строчками. Допустим, мы хотим вывести первые несколько строк. Если мы выводим первые строки, то можно воспользоваться командой head. Допустим первые 3 строки. Есть и альтернативный способ вывода первых трех строк нашего Data Frame. Мы можем работать с Frame в данном случае как с простым списком. Давайте просто обратимся по индексу. Сделаем вот так, и также получим наши первые 3 строки. Аналогично можно вывести, там, последние 3 строки. Все очень похоже на обычный список. Вот так. Все работает. Если же мы хотим сделать что-то более сложное, например выбрать какой-то список строк и какой-то список столбцов, мы можем воспользоваться командой loc. Она позволяет обращаться к нашему Data Frame с помощью обращения к названиям наших осей. Давайте продемонстрируем, как это работает. Вызываем loc. Дальше сначала передаем ему список тех строк, которые мы хотим. Название наших строк – это их индекс. Поэтому можем, ну просто, написать список цифр, ну допустим, 1-я, 3-я и 5-а строка. Дальше говорим, с какими столбцами мы хотим работать. Ну давайте выведем Name, например, и City. Теперь видим, что получилось ровно то, что мы хотели: 3 строчки и 2 столбца. Альтернативно можно обращаться к нашим осям не по имени, а по позиции, то есть по номеру нашего столбца и по номеру нашей строки. Это делается с помощью команды iloc. [БЕЗ_ЗВУКА] В данном случае первый аргумент не изменится, потому что название оси совпадает с ее позициями, поэтому просто пишем 1, 3, 5. А вот для обращения к колонкам, нам придется просто заменить Name и City на их номера. Соответственно, это получается, что у нас, у нас получается 0-й и 2-й номер. Индексация с 0. Да, получили тот же самый срез нашего массива. Есть еще один способ обратиться к нашему массиву и сделать выборку. Это метод ix. Он умеет работать одновременно и с именами, и с позициями. Вот давайте проверим. Сначала давайте проверим, как он работает с именами. Повторим те же аргументы, которые мы передавали методу «loc. Соответственно результат должен быть таким же. Так, передаем Name и City. И запускаем. Видим, что выброска не изменилась. А теперь давайте попробуем передать туда номера. [БЕЗ_ЗВУКА] Да, все точно так же. Поэтому чаще всего разработчики предпочитают использовать сразу ix, потому что он поддерживает и ту, и другую аннотацию. Так, на самом деле мы можем делать не только такие простые выгрузки из нашей таблицы. Мы можем делать более сложные срезы, удовлетворяющие некоторым логическим операциям. Ну, например, мы можем как-нибудь отфильтровать наш Data Set. Давайте возьмем Data Frame и отфильтруем его по дате рождения. Например, выберем только тех людей, кто старше 85-го года рождения. Как это можно сделать? Берем наш Data Frame. Берем что нас будет интересовать поле «дата рождения». Указываем его в квадратных скобках. Дальше записываем явно то логическое выражение, которое мы хотим проверить. В данном случае нас интересует «больше, либо равно» и давайте будем сравнивать с 85-м годом. Нам нужно создать сначала наш datetime объект. Помните мы заранее поменяли тип нашего столбца, чтобы мы могли работать с ним, как с датами. Поэтому теперь, если мы будем сравнивать этот столбец с датой, то мы получим корректный результат сравнения. Итак, 1 января 85-го года. Итак, мы видим, что результат соответствует нашему условию. В таблице остались только те сотрудники, дата рождения которых не раньше, чем 1 января 1985 года. Работает это с помощью логических индексов. Чуть подробнее, что это такое, вы узнаете несколько позже, когда будете изучать библиотеку NumPy. Там вы обязательно познакомитесь с этим понятием. Но а сейчас мы двигаемся дальше. И давайте мы несколько усложним наше условие. Сейчас мы проверяли условие только на один столбец, давайте проверим сразу несколько. Так как результат применения нашего условия к столбцу логический, то есть True или Falce для каждой строки, то на самом деле мы можем применить некоторую логическую функцию между различными условиями. Например, мы можем проверить условие на дату рождения, еще одно условие на дату рождения или на какой-то другой столбец, и посмотреть, скажем, на их пересечение или на их объединение. Любую логическую функцию. Вот давайте сначала возьмем некоторое условие на дату рождения. Даже давайте оставим то же самое и проверим условие на город. Например, выберем только сотрудников, которые не из Москвы. Вот синтаксически это будет выглядеть следующим образом: снова берем наш Frame, и в квадратных скобках записываем условия. Так как условия будет два, давайте сразу подготовим круглые скобки для каждого из условий. И так как мы уже договорились, что будем использовать их пересечение, давайте добавим знак логического «и» между ними. Теперь первое условие оставляем без изменений. Дата рождения. Дата рождения должна быть не раньше, чем 1-го января. [БЕЗ_ЗВУКА] [БЕЗ_ЗВУКА] И следующее условие давайте выберем таким: «город» ≠ «Москва». [БЕЗ_ЗВУКА] Судя по предыдущей таблице, мы ожидаем получить только одну строчку. Давайте посмотрим. Ровно так и получилось. Это было пересечение условий. А теперь давайте попробуем сделать объединение условий. То есть логическое «или». Синтаксис будет очень похож. Сначала записываем первое условие. Давайте снова его оставим. [БЕЗ_ЗВУКА] [БЕЗ_ЗВУКА] Дальше набираем знак логического «или». И запишем второе условие. Давайте выберем тех людей, которые из Волгограда. [БЕЗ_ЗВУКА] Запускаем нашу команду и видим, что у нас появилось два типа людей: первые те, у кого «город» = «Волгограду», это первый человек, и все остальные, у кого дата рождения позже 1 января 85-го года. На этом мы закончим работу с Data Frame. Вы уже научились создавать Data Frame, модифицировать их, применять к ним различную функцию, работать с индексами и делать выборки. На самом деле это только вершина айсберга, но нам пора двигаться дальше, и в следующей видеолекции вы будете изучать библиотеку NumPy.

[БЕЗ_ЗВУКА] Давайте познакомимся с библиотеками NumPy, SciPy и Matplotlib. Начнем с NumPy. Для начала импортируем NumPy, ну и посмотрим, как выглядят массивы в этой библиотеке. Для этого создадим обычный массив и создадим NumPy-ский массив. Ну и посмотрим, что у нас получилось. Как видите, типы данных действительно разные. Выводятся на печать они тоже немного по-разному, так что уже по выводу на печать можно понять, какой массив у вас используется в конкретном месте. Ну и давайте поищем какие-то более существенные различия. Попробуем применить привычную нам операцию среза, то есть получить элементы с индексами от 1 до 3 (не включая 3). Видим, действительно, всё отработало как нужно для обычного массива. Проверим для NumPy-ского. Для NumPy-ского тоже работает. Ну и в принципе все основные операции, которые можно делать с массивами, можно делать с массивами в NumPy. Но есть некоторые операции, которые добавились. Ну, например, если мы хотим взять элементы с индексами 0 и 2 и для этого хотим передать в качестве индекса нашему исходному массиву массив из 0 и 2, то это, конечно, не отработает. Но вот если мы сделаем то же самое для NumPy-ского массива, то все будет хорошо. Действительно, получились 2 и 4. Давайте посмотрим. Да, 2 и 4. Кроме того, есть логическая индексация, то есть можно написать y > 3, получится массив из true и false, где true будет на тех позициях, где значение действительно больше 3, а false будет на тех позициях, где это условие нарушено. Передать этот массив из true и false в качестве индекса и взять соответствующий элемент. Действительно, 4 и 6. Смотрим на исходный массив. Действительно, только 4 и 6 у нас больше 3 в этом массиве. Вообще, наверное, очень часто вам хотелось сделать какую-нибудь операцию с каждым элементом массива, ну, например, написав x * 5. Но если это сделать с обычным массивом, то значение не умножится на 5, а просто вы пять раз повторите один и тот же массив. В NumPy-ских массивах произойдет именно то, что хочется. Вот, как вы видите. у нас все значения умножились на 5. То же самое можно делать с некоторыми другими операциями, например, возведение в степень. Как мы видим, для обычных массивов возведение в степень вообще не отработало, а для NumPy-ских все будет хорошо. Ну и в случае многомерных массивов, ну, например, двумерных, индексация в NumPy может немножко отличаться. Для этого давайте создадим двумерный массив в обычном виде и NumPy-ский. И захотим получить элемент с индексами [1, 2]. Вот выведем его. Действительно, это нолик. То есть во внешнем массиве мы выбираем элемент с индексом 1. Это вот этот массив. В нем мы выбираем элемент с индексом 2. Это нолик. Точно так же можно сделать и для NumPy-ского двумерного массива, но можно сделать это и немного иначе. Например, просто написав [1, 2]. Результат будет тот же самый. Поэтому если вы увидите где-то такую индексацию, не надо удивляться — что же сломалось, в чем же дело, разве можно так оперировать с массивами — а нужно просто сделать вывод, что, видимо, это был NumPy-ский массив. Конечно, в NumPy есть не только массивы, есть еще много других полезных вещей, и вообще в целом библиотека ориентирована на то, чтобы как-то упростить вам вычисления. Ну, например, там есть случайные числа. Вот сейчас мы сгенерировали некоторое дробное случайное число из равномерного распределения. О распределениях будет подробнее в части про теорию вероятности. Ну а вот это случайное число из нормального распределения. Давайте перегенерируем их, чтобы убедиться, что это действительно какие-то случайные числа. Вот, как вы видите, число меняется. Нормальное, вот даже отрицательным может быть. Но это, разумеется, нормальное распределение с некоторыми фиксированными параметрами. Но это будет более ясно уже после части про вероятность. Ну и мы можем сгенерировать не одно число, а несколько. Просто передадим параметр сколько чисел нам нужно, и вот мы получили четыре числа. Можно сгенерировать даже матрицу или еще более сложный, многомерный массив. Давайте попробуем это сделать. Есть и другие интересные вспомогательные функции в NumPy. Ну, например, аналог функции range, которому мы можем задавать размер шага. Ну и вот что получается. Давайте попробуем тоже самое сделать с помощью range. Мы увидим сообщение об ошибке. И действительно, range нужно передавать целочисленный размер шага. Ну, давайте на всякий случай сравним еще их по производительности. Может быть и здесь есть некоторое превосходство. Magic timeit просто несколько раз выполняет код и замеряет, сколько занимает выполнение один раз. Ну и как мы видим, вариант из NumPy отработал намного быстрее. [БЕЗ_ЗВУКА] Таким образом, NumPy — это библиотека, позволяющая выполнять некоторые вычисления и делать это более хорошо, более оптимизированно, соответственно, тратить на это меньше времени. И поэтому она пользуется такой популярностью. Теперь перейдем к библиотеке SkiPy. SkiPy реализует некоторые более высокоуровневые вещи. То есть если в NumPy речь идет о том, что у нас есть какие-то матрицы, с ними нужно делать какие-то операции, то в SkiPy речь идет о том, что у нас бывают задачи оптимизации, бывают задачи из линейной алгебры, бывают какие-то более сложные вещи из теории вероятности. И некоторые простые операции из этих разделов нужно тоже уметь делать. Ну давайте сначала посмотрим на оптимизацию. Импортируем модуль optimize, сделаем какую-нибудь свою простую функцию, про которую нам понятно, где у нее минимум. Ну вот здесь рассмотрена очень простая функция, которая представляет собой сумму двух квадратов и некоторого числа. Ну и понятно, что вот этот вот квадрат мы можем приравнять к 0, этот квадрат тоже, а с этим числом мы ничего не сделаем. То есть минимальное значение этой функции будет 3. Ну и смотрите, как мы реализовали функцию от нескольких переменных. Мы просто передаем на вход некоторый массив, ну и считаем, что одна переменная — это нулевая координата, а другая переменная — это то, что лежит по индексу 1. Ну и давайте убедимся, что минимум действительно там, где мы его ожидаем. Действительно, все хорошо. Вот, оказывается, в модуле optimize есть метод minimize, которому достаточно передать функцию, передать начальное приближение, ну, то есть вектор, с которого начнется некоторый оптимизационный процесс. Ну и можно запустить и посмотреть, какой результат получится. Вот мы видим, что значение функции равно 3 в точке с вот такими вот координатами, которые с достаточно высокой степенью точности совпадают с правильными. Если нам нужно вывести именно координаты точки минимума, то можно обратиться к полю x у полученного объекта. Конечно, в модуле SciPy есть много разных хороших инструментов, в частности есть инструменты для работы с линейной алгеброй, ну, давайте, например, решим простенькую систему уравнений. Импортируем linalg, задаем систему, первая строчка задает матрицу системы, вторая строчка задает значения, которые должны получиться. Нам нужно найти такой x, что, если матрицу умножить на x, получится вот этот ответ. Подробнее про матрицы и операции с ними вы узнаете в разделе про линейную алгебру. Ну давайте попробуем воспользоваться модулем linalg и посмотреть на результат. Вот мы получили какой-то результат, но, наверное, заведомо не ясно, правильный он или нет. Давайте просто проверим. Давайте умножим матрицу a на полученный x и увидим, что получившийся вектор ровно тот, который мы требовали. Ну, кроме того, в в модуле lynalg есть разные операции для матричных разложений, ну, например, есть сингулярные разложения матрицы, или SVD разложения, о нем мы тоже еще будем говорить подробнее. Оно очень часто используется в анализе данных. Оказывается, все это можно делать буквально в одну строчку. Вот здесь мы сгенерировали матрицу из случайных чисел размером 4 х 3, сделали разложение на 3 матрицы, и вот эти матрицы имеют размеры 4 х 4, диагональная матрица размера 3 и матрица 3 х 3, все, как и должно быть в сингулярном разложении, о чем мы еще поговорим. Модуль MatPlotLib позволяет очень просто строить графики. Ну, для начала выполним magic MatPloLib inline, для того, чтобы все графики отражались сразу в ноутбуке, ну и буквально в пару строчек построим какой-то первый график. Ну вот здесь вот первый аргумент у функции plot, это значение x, второй аргумент это значение y, когда мы выполняем show, мы получаем, собственно, график, ну и, наверное, обычно мы будем хотеть строить не какие-то произвольные зависимости, заданные вот прямо двумя массивами прямо в аргументах, а уже что-то осмысленное. Ну, например, давайте построим график функции y = x в кубе. Здесь нам уже немножко понадобится NumPy. Мы просто задаем массив значений x от −10 до 10 с шагом 0,1. Получаем значение y, просто возводя в степень, ведь у нас есть операции с массивами в NumPy, и строим график, действительно, это похоже на кубическую параболу. Ну и давайте в качестве небольшого итога попробуем разобрать пример, где используется все вместе. Сначала проимпортируем необходимые модули. Смотрите, нам потребуется NumPy, нам потребуется MatPlotLib, и в Scripy мы воспользуемся модулем interpolate для того, чтобы по известным значениям функции приблизить значение в промежуточных точках. Ну, то есть, выполнить задачу интерполяции. Ну и давайте для примера рассмотрим такую вот простую функцию. Это будет просто экспонента, то есть e в степени −x / 3, ну и посмотрим, какие значения x и y у нас получатся. Я вывел только первые пять, чтобы не смотреть на все точки, ну, вроде, что-то получилось. Давайте это построим, но сначала выполним интерполяцию, а теперь построим все вместе. Смотрите, синие точки это известные значения функции. Зеленые точки – это наше приближение. По умолчанию параметр kind равен linear. Ну, то есть, если мы его не будем указывать, результат будет тот же, но его можно задавать. Например, можно сделать так. И вот уже функция получилась более гладкой. Кстати, обратите внимание, если мы сделаем здесь не делить на 3,0, а, например, на 3, то график уже будет выглядеть немного странновато. Это не очень похоже на экспоненту. В чем же дело? Ну, на самом деле нужно быть очень внимательным, так как в Python деление целочисленное, x у нас получились целыми, потому что мы шли от 0 до 10 с шагом 2, и при делении на 3 у нас получилось деление нацело, поэтому в итоге все немного поменялось. Ну, и конечно, в машинном обучении мы будем иметь дело не просто с такой ситуацией, что некоторые значения функции нам известны точно, а некоторые значения будут известны нам с некоторым шумом. Давайте просто возьмем и добавим шум, мы же это умеем, у нас есть библиотека NumPy. Возьмем и добавим шумы, для этого нам потребуется сгенерировать какие-то случайные числа, их нам нужно сгенерировать по длине массива x, ну и давайте, чтобы шум был не слишком большой, домножим этот шум на 0,1. И посмотрим, что получится. Ну, даже, наверное, можно еще меньше: на 0,5. Так, вот здесь уже как раз видно, что у нас получается не совсем экспонента, а у нас получается небольшой изгиб здесь, чего на самом деле быть не должно. Ну, и как вы видите, просто интерполировать, чтобы восстановить зашумленную зависимость, уже недостаточно. А вот что же делать, когда в зависимости действительно есть какой-то шум, вы узнаете в нашей специализации. Итак, подведем итог. Мы с вами познакомились с библиотеками NumPy, Scripy, MatPlotLib. NumPy нам предоставляет средства для высокопроизводительных вычислений, Scripy предоставляет некоторые более высокоуровневые вещи из математики, а MatPlotLib позволяет все очень легко визуализировать.

[БЕЗ_ЗВУКА] Познакомимся чуть подробнее с решением оптимизационных задач в библиотеке SkiPy. Ну, для начала импортируем уже известный нам модуль optimize. И определим некоторую функцию, на которой будем всё тестировать. Ну мы воспользуемся функцией Розенброка, которая часто используется для тестирования оптимизационных алгоритмов. У нее минимум в точке (1, 1). Этот минимум находится в продолговатом желобе, поэтому его не так просто найти. Ну и для начала применим какой-нибудь очень примитивный метод, например, перебор. И вот как вы видите, уже находится достаточно хорошо минимум, но иногда бывает важно, сколько раз мы вычисляем функцию. Потому что не все функции можно вычислить быстро. И здесь появляется интерес использовать разные другие методы. Если ваша функция достаточно плохая, ну то есть в ней есть разрывы, ну, может быть она не гладкая, то подойдет дифференциальная эволюция. Это генетический алгоритм, о генетических алгоритмах мы еще поговорим подробнее в дальнейшем. Ну и давайте посмотрим, что получится. Действительно, мы нашли точку минимума, нам потребовалось некоторое приличное количество итераций. Если же у вашей функции есть градиент... Если вы вдруг забыли, что такое градиент, то об этом мы тоже поговорим позднее, когда будем вспоминать ключевые понятия из математического анализа. Так вот, если у функции есть градиент, то можно воспользоваться градиентными методами. Для этого сначала мы определим градиент функции Розенброка, дальше резонно задаться вопросом — а верно ли мы его выписали? Может быть он на самом деле другой? На этот случай есть функция check grad. Она позволяет проверить. Вот мы сравнили наш градиент с численной оценкой для градиента, увидели, что расхождение небольшое. Ну и теперь можем спокойно его использовать. Один из популярных градиентных методов — bfgs. Он достаточно хорошо решает задачу оптимизации. Его мы и применим. Ну вот, как вы видите, здесь нам уже хватило всего 16 итераций, поэтому в случае, если функция достаточно хорошая и можно воспользоваться градиентными методами, не стоит пытаться использовать методы для негладких функций. Ну и вообще есть модуль optimize с функцией minimize, который не обязательно писать, какой метод использовать или передавать градиент. Если градиент нужен, она его оценит, какой метод использовать — тоже ей более-менее понятно. Ну, по умолчанию для достаточно хороших функций будут использоваться как раз bfgs. Ну вот, мы видим, что всё тоже получилось. Ну, на самом деле можно явно специфицировать, какой метод применять. Даже передать градиент, если нужно. Обратите внимание — здесь уже параметр, в который нужно передавать градиент, называется немного по-другому. Раньше для функции fmin bfgs он назывался fprime, ну а здесь он называется jac. Ну, вот запустим, посмотрим. Ну и видим, что всё получилось. На самом деле можно не передавать градиент bfgs, давайте сделаем так. Вот получился немного другой результат. И можно заметить, что он совпадает с результатом функции minimize. Без параметра method. Ну есть, конечно, много других разных методов, подробнее об этом можно посмотреть в документации функции minimize. Но мы, например, в этом курсе еще рассмотрим метод Нелдера — Мида. Он тоже часто используется для решения задач оптимизации.

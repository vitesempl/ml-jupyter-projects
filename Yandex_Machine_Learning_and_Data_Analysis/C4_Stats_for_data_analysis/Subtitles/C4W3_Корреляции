[БЕЗ ЗВУКА] В этом видео мы начнем разбираться со способами формализации понятия корреляции. И начнем с самого распространенного — с коэффициента корреляции Пирсона. Корреляция Пирсона — это мера силы линейной взаимосвязи между двумя случайными величинами X1 и X2. Определяется она следующим образом. Это математическое ожидание произведения отклонений случайных величин от своих математических ожиданий, деленное на корни из дисперсии этих случайных величин. Коэффициент корреляции Пирсона принимает значения от −1 до 1, где 1 соответствует идеальной линейной взаимосвязи между случайными величинами, в которой при росте X1 растет и X2. −1 — это идеальная линейная связь с отрицательным знаком. То есть когда X1 растет, X2 падает. 0 — это случай отсутствия корреляции. когда корреляция равна 0, это значит, что две случайные величины меняются независимо друг от друга. Если у вас есть выборка пар X1X2 объема n, по ней очень легко посчитать выборочный коэффициент корреляции Пирсона. Вот формула. Давайте теперь посмотрим на несколько примеров, которые помогут нам разобраться, как работает коэффициент корреляции. Рассмотрим облако точек на диаграмме рассеивания, то есть на графике, где по одной оси отложена X1, по другой – X2. Возьмем облако точек с идеальной положительной корреляцией, равной 1, и начнем это облако постепенно размывать. Вы видите, как с размытием облака коэффициент корреляции Пирсона начинает постепенно уменьшаться до 0, а потом, когда облако снова начинает сжиматься в обратном направлении, он растет по модулю и становится постепенно равным −1. Следующий эксперимент. Возьмем облако с высокой положительной корреляцией между случайными величинами, и начнем его постепенно загибать. Чем сильнее мы его искривляем, тем меньше становится коэффициент корреляции Пирсона. Когда мы превращаем наше облако в параболу, значение выборочного коэффициента корреляции получается близким к 0. Это неудивительно, поскольку корреляция Пирсона — это мера силы линейной взаимосвязи между случайными величинами. То есть все нелинейные функциональные зависимости, даже если они очень хорошо выражены, коэффициент корреляции Пирсона не обнаруживают. Это можно увидеть и на следующих примерах. Если между X1 и X2 какие-то сложные зависимости, далекие от линейных, коэффициент корреляции Пирсона будет всё равно равным 0. Следующий важный пример. Возьмем облако из тысячи точек с сильной отрицательной корреляцией. И из этого облака 5 точек начнем постепенно отодвигать в верхний правый угол диаграммы рассеивания. Мы видим, что чем дальше мы отодвигаем эти 5 точек, тем меньше по модулю становится значение выборочного коэффициента корреляции. С какого-то момента оно переходит через 0 и начинает расти. Достаточно сильно отодвинув эти всего 5 точек из тысячи, мы можем получить большой положительный коэффициент корреляции. Это говорит нам о том, что коэффициент корреляции Пирсона неустойчив к выбросам. Небольшое количество точек могут оказывать на него существенное влияние, если они находятся достаточно далеко от основного облака. Это существенная особенность корреляции Пирсона, которую нужно иметь ввиду. В следующем видео мы поговорим о корреляции Спирмена, которая к выбросам существенно более устойчива.

[БЕЗ ЗВУКА] В этом видео мы разберемся еще с одним способом формализации понятия корреляции — корреляцией Спирмена. Коэффициент корреляции Спирмена — это мера силы монотонной взаимосвязи между двумя случайными величинами. Для того чтобы ее посчитать, вам нужно взять вашу выборку пар (X1, X2), превратить наблюдение в каждой из подвыборок в ранги и уже на этих рангах посчитать значение коэффициента корреляции Пирсона. Именно за счет вот этого рангового преобразования мы получаем, что корреляция Спирмена устойчива к любой монотонной взаимосвязи между X1 и X2, поскольку ранговое преобразование превращает любую монотонную взаимосвязь в линейную. Корреляция Спирмена наследует часть свойств корреляции Пирсона. Так, она точно так же меняется от −1 до 1, где крайние значения отрезка соответствуют идеальной, в данной случае монотонной, взаимосвязи между нашими случайными величинами, а 0 — полному отсутствию монотонной взаимосвязи между ними. Если у вас есть выборка пар (X1, X2) — вот так считается выборочный коэффициент корреляции Спирмена. В данном случае формулу выборочной корреляции Пирсона можно немного упростить, поскольку мы заранее знаем, чему равны средние ранги в наших выборках и чему равны их дисперсии. Давайте воспроизведем эксперименты с облаками точек, которые мы делали для корреляции Пирсона и посмотрим, какие из свойств корреляции Спирмена отличны от того, что мы видели раньше. Корреляция Спирмена примерно так же реагирует на сжатие и размывание облака точек на диаграмме рассеяния, как корреляция Пирсона. Мы видим, что крайние случаи идеальной линейной взаимосвязи соответствуют −1 и 1, а в середине мы получаем значения коэффициента корреляции, близкие к 0. Что-то более интересное мы получаем в эксперименте, когда мы наше облако точек загибаем. Мы видим, что пока зависимость между X1 и X2 остается монотонной, значение коэффициента корреляции Спирмена не убывает. Однако потом, когда мы начинаем постепенно превращать наше облако точек в параболу, значение выборочного коэффициента корреляции Спирмена постепенно превращается в 0. Корреляция Спирмена не обнаруживает взаимосвязи между X1 и X2, отличные от монотонных. Это можно заметить и на следующих примерах. Когда у нас между X1 и X2 есть какие-то сложные функциональные взаимосвязи, корреляция Спирмена все равно остается равной 0, поскольку они далеки от монотонных. Гораздо более интересные результаты мы получаем в эксперименте с выбросами. Когда мы из нашего облака точек с сильной отрицательной корреляцией начинаем пять точек выдвигать в правый верхний угол диаграммы рассеяния, значение коэффициента корреляции Спирмена сначала немного уменьшается, однако как только эти пять точек оказываются за пределами диапазона изменений случайных величин в нашем основном облаке, значение коэффициента корреляции Спирмена меняться перестает. Как бы далеко мы их не отодвигали, мы не сможем получить большую положительную корреляцию, как в случае с корреляцией Пирсона. Это говорит о том, что коэффициент корреляции Спирмена гораздо более к выбросам устойчив, то есть небольшое количество точек с огромными значениями признаков очень слабо влияют на выборочное значение нашего коэффициента корреляции. В следующем видео мы разберемся с тем, как оценивать корреляцию между бинарными случайными величинами.

Корреляции Пирсона и Спирмена, которые мы теперь умеем считать, позволяют нам квантифицировать силу взаимосвязи между двумя непрерывными переменными. В этом видео мы разберемся с тем, как это делать для категориальных, и начнем с бинарных. Для двух бинарных переменных мерой силы взаимосвязи между ними является коэффициент корреляции Мэтьюса. На вход он принимает таблицу сопряженности. По строкам там стоят значения одного признака, по столбцам — второго, в каждой ячейке — количество объектов, на которых реализовалась эта пара. Равен коэффициент корреляции Мэтьюса отношению ad − bc к корню из произведения всех сумм по строкам и столбцам. Точно так же, как и коэффициенты Пирсона и Спирмена, корреляция Мэтьюса лежит в диапазоне от −1 до 1, и 0 точно так же соответствует случаю полного отсутствия взаимосвязи между переменными. 1 соответствует ситуации, когда у вас X1 и X2 полностью совпадают, то есть у вас b и c равны 0, у вас отсутствуют в выборке объекты, на которых значение X1 и X2 отличаются. −1 — это ситуация противоположная: в вашей выборке нет ни одного объекта, на которых значения двух бинарных признаков совпадают. Давайте обобщим этот подход на случай категориальных признаков. Пусть у нас X1 принимает K1 разных значений, а X2 — K2 разных значений. Составим большую таблицу сопряженности, у которой в i-й строке и j-м столбце будет стоять nij — это количество объектов выборки, на которых значение признака X1 = i, а значение признака X2 = j. Вот на основании этой таблицы сопряженности мы будем считать нашу меру взаимосвязи между X1 и X2, и мера эта называется коэффициент V Крамера. Как ни странно, обозначается она не V, а φ с нижним индексом c (по первой букве фамилии Крамер). И равен этот коэффициент корню из специальным образом нормированного значения статистики хи-квадрат. Как хи-квадрат считается для таблицы сопряженности, мы узнаем очень скоро. А пока давайте обратим внимание на то, что значение коэффициент Крамера принимает исключительно в интервале от 0 до 1, то есть он не может быть отрицательным. 0 точно так же соответствует полному отсутствию взаимосвязи, а 1 — полному совпадению переменных X1 и X2 с точностью до переименования уровней. Отрицательная корреляция между двумя категориальными переменными быть не может, поскольку уровни категориальных переменных не связаны друг с другом отношениями порядков. Итак, мы разобрались, как считать корреляцию между парами бинарных переменных, парами категориальных, а до этого — как считать корреляцию между парами непрерывных переменных. Что делать, если признаки в вашей паре разных видов? Например, пусть X1 — непрерывный, а X2 — бинарный. Чисто теоретически на этих данных вы можете посчитать корреляцию Пирсона или Спирмена. Никакая из них не сломается из-за того, что одна из выборок будет не непрерывной, а бинарной. Но делать так не стоит. Это очень плохо. Корреляции Пирсона и Спирмена не рассчитаны на применение к бинарным или категориальным признакам. Величина, которую вы получите, будет иметь мало смысла. На самом деле для пар признаков, один из которых непрерывный, а другой — категориальный, вообще не нужно считать никакой коэффициент корреляции. X1 и X2 в нашем примере, где X1 непрерывный, а X2 — бинарный, будут положительно коррелированы, если матожидание X1 на объектах, где X2 = 1 больше, чем матожидание X1 на объектах, где X2 = 0. Таким образом, мерой силы взаимосвязи между X1 и X2 может служить просто разность вот этих двух математических ожиданий. Эта величина не нормированная, она может меняться в любом диапазоне, от −∞ до +∞, но интерпретировать ее намного легче, чем вот странный коэффициент корреляции, который вы можете посчитать на такой паре выборок. Итак, в этом видео мы разобрались, как считать корреляцию между бинарными переменными с помощью коэффициента Мэтьюса, между категориальными переменными с помощью коэффициента Крамера, и между парами переменных, одна из которых категориальная, а другая — непрерывная: никак. В следующем видео мы поговорим об интерпретации значений корреляции.

В этом видео мы поговорим про поиск зависимости данных и потренируемся считать корреляцию Пирсона. Анализировать мы будем довольно интересный набор данных Foodmart product sales. В этом наборе данных для каждого продукта известно количество покупок этого продукта в некоторую дату, в определенном магазине. Мы с вами будем искать связи вида: правда ли, что покупки этого товара влияют на покупку второго товара? Правда ли, что покупки товара a приводят к увеличению или уменьшению покупок товара b? Давайте для начала загрузим данные. Наши данные состоят из двух файлов. Первый файл, Foodmart sales, говорит о том, сколько раз каждый продукт был продан в каждом магазине за некоторую дату. Давайте посмотрим, как это выглядит. Видим, что у нас всего 4 столбца. Первый столбец соответствует id продукта, второй — id магазинов, в которых произошли покупки, третий столбец — это дата в которую это произошло, ну и, соответственно, количество покупок. Второй файл, foodmart products, содержит огромное количество полей. На самом деле, нам далеко не все отсюда интересно. Нам просто не очень удобно работать с id продуктов, потому что они не несут смысловой нагрузки, нам хочется получить их имена. Соответственно, этот файл содержит столбец с id и столбец с именами, поэтому с помощью него мы сможем связать информацию о id продукта с его именем. Это довольно просто делается, для этого мы будем пользоваться функцией merge. Вызываем функцию merge у первого dataframe sales. Дальше в качестве первого аргумента передаем второй dataframe. Давайте сразу отрежем только те столбцы, которые нам интересны, а так же указываем по какому столбцу можно производить соединение, в данном случае это столбец product id. И говорим, что мы хотим делать inner join, то есть мы хотим оставить только свое совпадающее значение. Ну в данном случае у нас с вами все значения совпадают, поэтому размер исходной таблицы будет совпадать с размером получившейся таблицы. Давайте посмотрим, как это выглядит. Видим, что наша таблица sales теперь содержит дополнительное поле product name. Давайте проанализируем взаимное влияние продуктов друг на друга. Для этого давайте рассчитаем корреляцию Пирсона между каждой парой продуктов. Будем это делать по рассчитанной на предыдущем шаге таблице sales. Однако в таком виде, в каком она сейчас существует, это делать не очень удобно. Дело в том, что в этой таблице у нас есть информация только о покупках товара, и нет информации об отсутствии покупок некоторого товара. Ну то есть в некоторую дату в некотором магазине продукт a, скажем, не покупали, то у нас нет соответствующей строчки со значением sales = 0. Вот давайте эти строчки получим и вообще в целом немножечко изменим внешний вид таблицы. Давайте будем работать с таблицей, у которой индексом является дата и магазин, а в столбцах расположена информация о покупках продуктов. То есть каждый столбец соответствует своему продукту. Тогда в каждой строчке мы получим значение покупок этого продукта за соответствующую дату в соответствующем магазине. Таким образом, мы сможем добавить туда эти самые нулевые значения, которых нам не хватало, и сможем рассчитать корреляцию между всеми парами столбцов. Давайте сначала получим правильную таблицу, это делается с помощью метода pivot table. Передаем туда исходную таблицу. Указываем, что нас интересует значение столбца sales, в качестве значений, которые мы будем заполнять. Дальше индексами будут являться дата и id магазина, как мы уже говорили, и в качестве столбцов будут выбраны продукты. Ну в данном случае мы могли бы взять, как product id, так и product name. Но с именами работать немножко удобней, поэтому давайте остановимся на них. Итак, давайте соответствующую таблицу получим и посмотрим, как она выглядит. Понятно, что она будет очень большая. Ну давайте выведем только начало. Видим, что, действительно, индексами у нас являются дата и id магазина, и, соответственно, каждый столбец соответствует своему продукту. Вот мы видим, что их очень-очень-очень много. Добавилось огромное количество нулей. Ну и вот мы видим, что в тех местах, где у нас были покупки, вот эти значения остались, их можно найти. Что ж, теперь давайте рассчитывать корреляции. Так как мы с вами работаем с pandas dataframe, это делает очень просто — для этого достаточно просто вызвать метод corr. Запишем результат в новый dataframe, в новую таблицу. И так же давайте выведем только ее начало. Мы видим, что корреляция выглядит приблизительно так, как бы нам хотелось. По диагонали мы видим значения, соответствующие 1, ну по понятным причинам это корреляции между одним и тем же продуктом. И в остальных ячейках мы видим корреляции между парами продуктов. Такую таблицу очень удобно анализировать. По этой таблице для каждого продукта мы можем посмотреть, как его покупки коррелируют с покупками других продуктов и найти наиболее сильные корреляции. Причем, как в положительную, так и в отрицательную сторону. Вот давайте попробуем что-то такое сделать. Зафиксируем некоторый продукт, например, american chicken hot dogs и посмотрим, какие продукты, покупки каких продуктов, коррелируют с ним сильней всего. Для этого сначала просто выберем столбец, соответствующий этому продукту. На самом деле, можно было бы и строчку выбрать, данные будут те же самые. И просто отсортируем этот столбец по корреляциям. Сортировать будем по убыванию: ascending = false. Давайте выведем тоже самое начало. Ну понятно, что со значением 1 в топ попадает этот же самый продукт, это нам не так интересно. Давайте смотреть следующее. Вот следующий продукт, это какой-то журнал. Мы вот видим, что его покупки коррелируют с покупками хот-догов на 0,24. Ну вот следующий, это frozen chicken wings (замороженные крылышки). Потом идет сметана, маффины. Мы видим, что довольно такой понятный топ продуктов. В принципе, мы можем посмотреть продукты, которые коррелируют меньше всего. Для этого давайте отсортируем просто в обратном порядке. Вернее, неверно сказать, что они меньше всего коррелируют, они коррелируют просто с отрицательным знаком. По сути, если корреляция по модулю большая, но перед ней стоит знак минус, значит, что покупки этих продуктов отрицательно влияют на покупки этого продукта. Ну давайте посмотрим. Меняем порядок, которым мы хотим сортировать и выводим топ. Ну вот видим, что есть некоторые продукты, которые коррелируют с одним отрицательным знаком, нельзя сказать, что очень сильно, потому что все эти значения очень близки к нулю. Поэтому тут сложно сделать выводы. Давайте сделаем следующее. Давайте посмотрим, в принципе, максимальное по модулю отрицательное значение корреляции, чтобы понять, есть ли они в наших данных. Возможно, все отрицательные значения близки к 0 и мы просто ничего не сможем найти. Да, мы видим, что так и есть. У нас нет больших по модулю отрицательных значений. Так, давайте посмотрим тогда на положительные значения. Может быть, они есть. Ну вот видим, что с положительными значениями корреляции ситуация обстоит несколько лучше. Вот есть довольно большие значения по модулю. Вот давайте посмотрим на первый продукт и видим, что есть какие-то продукты, которые неплохо с ним коррелируют. Ну, вот, да, видим, что с кофе покупают внезапно молочный суп. Ну то есть по таким таблицам достаточно просто можно получить представление о том, как покупки одного товара коррелируют с покупками другого товара и попытаться сделать соответствующие выводы. Мы с вами на этом заканчиваем. В этом видео мы поговорили о том, как считать корреляцию Пирсона. В следующем видео мы продолжим говорить о поиске взаимосвязи в данных.

В этом видео мы начнем говорить о том, как правильно интерпретировать значения коэффициентов корреляции и, в частности, сосредоточимся на проблеме, можно ли по полученному выборочному значению коэффициента корреляции сказать, что он достаточно большой и отличается от 0? Давайте рассмотрим вот такую задачу. За 100 дней у нас есть значения средней дневной температуры и количество проданных рожков мороженого. Значение коэффициента корреляции Пирсона, посчитанное по этой выборке, равно 0,45, Спирмена – 0,44. Можно ли по этим полученным значениям утверждать, что объем продаж мороженого и среднедневная температура статистически взаимосвязаны? Ответить на этот вопрос позволяет статистический критерий Стьюдента. Он принимает на вход парные выборки признаков X1 и X2, и проверяет нулевую гипотезу о том, что значение коэффициента корреляции Пирсона между ними равно 0. Он может это делать против любой односторонней или двусторонней альтернативы. Статистика критерия выражается через значение выборочного коэффициента корреляции и объема выборки n. Если нулевая гипотеза справедлива, то есть, корреляции нет, эта статистика имеет распределение Стьюдента с числом степеней свободы n − 2. Для проверки такой же точно гипотезы, но про корреляцию Спирмена, а не Пирсона, можно использовать абсолютно тот же самый критерий Стьюдента. Давайте вернемся к примеру с мороженым. Нулевая гипотеза о том, что линейной связи нет или значение коэффициента корреляции Пирсона равно 0, против двусторонней альтернативы критерием Стьюдента уверенно отвергается. Достигаемый уровень значимости порядка 4 * 10 в −6 < 0,05. Признаки действительно, похоже, линейно статистически взаимосвязаны. Корреляция Пирсона между ними равна 0,45. 95 % доверительный интервал для нее от 0,28 до 0,59. Этот доверительный интервал, кстати, можно построить, как на основе статистики критерия Стьюдента, так и, например, с помощью бутстрепа. Используем корреляцию Спирмена, чтобы проверить гипотезу об отсутствии монотонной взаимосвязи между двумя признаками. Против двусторонней альтернативы критерием Стьюдента эта гипотеза также отвергается с очень похожим достигаемым уровнем значимости. Признаки действительно монотонно связаны. Это не удивительно, мы уже показали, что они связаны линейно, а линейная взаимосвязь – частный случай монотонной. Корреляция Спирмена составляет 0,44. 95 % доверительный интервал для нее от 0,26 до 0,60. Давайте теперь перейдем к признакам категориальным, и рассмотрим задачу оценки эффективности тромболитической терапии по данным эксперимента, который проводился в Московской городской клинической больнице №25. В эксперименте участвовало 206 пациентов. Мы хотим понять, влияет ли наличие сахарного диабета у этих пациентов на эффективность тромболитической терапии. Данные представляют такую таблицу 2 x 2. У 78 пациентов сахарный диабет был. Из них 48 выздоровели, 30 не выздоровели. Значение коэффициента корреляции Мэтьюса, подсчитанное по этой таблице, составляет −11. Кажется, что, возможно, наличие сахарного диабета понижает шансы на выздоровление у пациентов. Давайте эту гипотезу проверим формально. Это делается с помощью критерия хи-квадрат. Он принимает на вход две связанные выборки длины n, каждая из нулей и единиц, и проверяет нулевую гипотезу о том, что значение коэффициента корреляции Мэтьюса между нашими двумя признаками равно нулю против двусторонней альтернативы. Гипотеза проверяется с помощью статистики, равной произведению n на квадрат выборочного коэффициента корреляции Мэтьюса. Если нулевая гипотеза справедлива и значение коэффициента корреляции действительно равно 0, то статистика имеет распределение хи-квадрат с одной степенью свободы. В задаче проверки нормальности мы уже говорили о том, что критерий хи-квадрат достаточно капризный. Вот и в этом случае для него нужно, чтобы выборки были достаточно большими: нужно не менее 40 объектов для того, чтобы использовать этот критерий. Кроме того, необходимо, чтобы каждая из вот этих четырех величин была больше 5. Откуда эти четыре величины берутся, мы узнаем очень скоро. А пока давайте применим критерий хи-квадрат к данным эксперимента по оценке эффективности тромболитической терапии. Нулевая гипотеза о том, что эффективность лечения не зависит от наличия диабета против двусторонней альтернативы, критерием хи-квадрат не отвергается. Достигаемый уровень значимости примерно 0,17 – это больше чем уровень значимости 0,05. То есть нельзя утверждать, что между двумя этими признаками есть связь. Давайте обобщим критерий хи-квадрат на случай категориальных признаков. Рассмотрим вот такую таблицу сопряженности для X1 и X2. Пусть X1 принимает k1 разных уровней, X2 — k2 разных уровней, в ячейке, в строке и в столбце j стоит nij — количество объектов, на которых реализуется значение X1 номер i и значение X2 номер j. Введем еще дополнительное обозначение для сумм по строкам и столбцам. Сумма по j-тому столбцу будем обозначать за n + j, а сумму по i-той строке за ni+. Критерий хи-квадрат для категориальных признаков выглядит следующим образом. Он принимает на вход связанные выборки X1 и X2 длины n и проверяет гипотезу о том, что между X1 и X2 связи нет, то есть они независимы. Проверяет ее он против общей альтернативы, то есть H0 не верна, какая-то связь есть. Это делается с помощью статистики хи-квадрат, которая считается по таблице сопряженности, которую мы только что нарисовали. Смотрится отклонение между nij, количеством объектов в каждой ячейке, и ожидаемым количеством объектов в этой ячейке, при условии справедливости нулевой гипотезы. Если X1 и X2 независимы, то мы ожидаем, что в ячейке, в строке i и в столбце j реализуется количество элементов равное (ni+ * n +j) / n. При справедливости нулевой гипотезы, статистика критерия имеет распределение хи-квадрат с числом степеней свободы k1 − 1 * k2 − 2. Не сложно показать, что критерий для таблиц 2 x 2, которые мы до этого рассмотрели, является частным случаем этого критерия. А вот в каких условиях критерий хи- квадрат для таблиц сопряженности может применяться. Нужно, чтобы выборки были достаточно большими, нужно, чтобы у вас было не менее 40 объектов, и кроме того, нужно, чтобы ожидаемое количество элементов в каждой ячейке таблицы было меньше 5, не более чем в 20 % ячеек. Можно считать, что для категориальных признаков критерий хи-квадрат проверяет гипотезу о равенстве нулю коэффициента V Крамера против альтернативы, что он нулю не равен. Вообще говоря, коэффициент V Крамера определяется как раз через статистику вот этого критерия хи-квадрат. Именно вот этот хи-квадрат стоит здесь в числителе дроби под корнем. Итак, в этом видео мы начали говорить о том, как правильно интерпретировать полученные в эксперименте значения выборочных коэффициентов корреляции. Мы узнали, с помощью каких методов можно отвечать на вопрос: значимо ли коэффициент корреляции отличается от нуля? Для корреляции Пирсона и Спирмена это делается с помощью критерия Стьюдента. Для корреляции Мэтьюса и коэффициента V Крамера — с помощью критерия хи-квадрат. В следующем видео мы продолжим говорить о том, как значения коэффициентов корреляции правильно интерпретировать.

В этом видео мы начнем говорить о том, как правильно интерпретировать значения коэффициентов корреляции и, в частности, сосредоточимся на проблеме, можно ли по полученному выборочному значению коэффициента корреляции сказать, что он достаточно большой и отличается от 0? Давайте рассмотрим вот такую задачу. За 100 дней у нас есть значения средней дневной температуры и количество проданных рожков мороженого. Значение коэффициента корреляции Пирсона, посчитанное по этой выборке, равно 0,45, Спирмена – 0,44. Можно ли по этим полученным значениям утверждать, что объем продаж мороженого и среднедневная температура статистически взаимосвязаны? Ответить на этот вопрос позволяет статистический критерий Стьюдента. Он принимает на вход парные выборки признаков X1 и X2, и проверяет нулевую гипотезу о том, что значение коэффициента корреляции Пирсона между ними равно 0. Он может это делать против любой односторонней или двусторонней альтернативы. Статистика критерия выражается через значение выборочного коэффициента корреляции и объема выборки n. Если нулевая гипотеза справедлива, то есть, корреляции нет, эта статистика имеет распределение Стьюдента с числом степеней свободы n − 2. Для проверки такой же точно гипотезы, но про корреляцию Спирмена, а не Пирсона, можно использовать абсолютно тот же самый критерий Стьюдента. Давайте вернемся к примеру с мороженым. Нулевая гипотеза о том, что линейной связи нет или значение коэффициента корреляции Пирсона равно 0, против двусторонней альтернативы критерием Стьюдента уверенно отвергается. Достигаемый уровень значимости порядка 4 * 10 в −6 < 0,05. Признаки действительно, похоже, линейно статистически взаимосвязаны. Корреляция Пирсона между ними равна 0,45. 95 % доверительный интервал для нее от 0,28 до 0,59. Этот доверительный интервал, кстати, можно построить, как на основе статистики критерия Стьюдента, так и, например, с помощью бутстрепа. Используем корреляцию Спирмена, чтобы проверить гипотезу об отсутствии монотонной взаимосвязи между двумя признаками. Против двусторонней альтернативы критерием Стьюдента эта гипотеза также отвергается с очень похожим достигаемым уровнем значимости. Признаки действительно монотонно связаны. Это не удивительно, мы уже показали, что они связаны линейно, а линейная взаимосвязь – частный случай монотонной. Корреляция Спирмена составляет 0,44. 95 % доверительный интервал для нее от 0,26 до 0,60. Давайте теперь перейдем к признакам категориальным, и рассмотрим задачу оценки эффективности тромболитической терапии по данным эксперимента, который проводился в Московской городской клинической больнице №25. В эксперименте участвовало 206 пациентов. Мы хотим понять, влияет ли наличие сахарного диабета у этих пациентов на эффективность тромболитической терапии. Данные представляют такую таблицу 2 x 2. У 78 пациентов сахарный диабет был. Из них 48 выздоровели, 30 не выздоровели. Значение коэффициента корреляции Мэтьюса, подсчитанное по этой таблице, составляет −11. Кажется, что, возможно, наличие сахарного диабета понижает шансы на выздоровление у пациентов. Давайте эту гипотезу проверим формально. Это делается с помощью критерия хи-квадрат. Он принимает на вход две связанные выборки длины n, каждая из нулей и единиц, и проверяет нулевую гипотезу о том, что значение коэффициента корреляции Мэтьюса между нашими двумя признаками равно нулю против двусторонней альтернативы. Гипотеза проверяется с помощью статистики, равной произведению n на квадрат выборочного коэффициента корреляции Мэтьюса. Если нулевая гипотеза справедлива и значение коэффициента корреляции действительно равно 0, то статистика имеет распределение хи-квадрат с одной степенью свободы. В задаче проверки нормальности мы уже говорили о том, что критерий хи-квадрат достаточно капризный. Вот и в этом случае для него нужно, чтобы выборки были достаточно большими: нужно не менее 40 объектов для того, чтобы использовать этот критерий. Кроме того, необходимо, чтобы каждая из вот этих четырех величин была больше 5. Откуда эти четыре величины берутся, мы узнаем очень скоро. А пока давайте применим критерий хи-квадрат к данным эксперимента по оценке эффективности тромболитической терапии. Нулевая гипотеза о том, что эффективность лечения не зависит от наличия диабета против двусторонней альтернативы, критерием хи-квадрат не отвергается. Достигаемый уровень значимости примерно 0,17 – это больше чем уровень значимости 0,05. То есть нельзя утверждать, что между двумя этими признаками есть связь. Давайте обобщим критерий хи-квадрат на случай категориальных признаков. Рассмотрим вот такую таблицу сопряженности для X1 и X2. Пусть X1 принимает k1 разных уровней, X2 — k2 разных уровней, в ячейке, в строке и в столбце j стоит nij — количество объектов, на которых реализуется значение X1 номер i и значение X2 номер j. Введем еще дополнительное обозначение для сумм по строкам и столбцам. Сумма по j-тому столбцу будем обозначать за n + j, а сумму по i-той строке за ni+. Критерий хи-квадрат для категориальных признаков выглядит следующим образом. Он принимает на вход связанные выборки X1 и X2 длины n и проверяет гипотезу о том, что между X1 и X2 связи нет, то есть они независимы. Проверяет ее он против общей альтернативы, то есть H0 не верна, какая-то связь есть. Это делается с помощью статистики хи-квадрат, которая считается по таблице сопряженности, которую мы только что нарисовали. Смотрится отклонение между nij, количеством объектов в каждой ячейке, и ожидаемым количеством объектов в этой ячейке, при условии справедливости нулевой гипотезы. Если X1 и X2 независимы, то мы ожидаем, что в ячейке, в строке i и в столбце j реализуется количество элементов равное (ni+ * n +j) / n. При справедливости нулевой гипотезы, статистика критерия имеет распределение хи-квадрат с числом степеней свободы k1 − 1 * k2 − 2. Не сложно показать, что критерий для таблиц 2 x 2, которые мы до этого рассмотрели, является частным случаем этого критерия. А вот в каких условиях критерий хи- квадрат для таблиц сопряженности может применяться. Нужно, чтобы выборки были достаточно большими, нужно, чтобы у вас было не менее 40 объектов, и кроме того, нужно, чтобы ожидаемое количество элементов в каждой ячейке таблицы было меньше 5, не более чем в 20 % ячеек. Можно считать, что для категориальных признаков критерий хи-квадрат проверяет гипотезу о равенстве нулю коэффициента V Крамера против альтернативы, что он нулю не равен. Вообще говоря, коэффициент V Крамера определяется как раз через статистику вот этого критерия хи-квадрат. Именно вот этот хи-квадрат стоит здесь в числителе дроби под корнем. Итак, в этом видео мы начали говорить о том, как правильно интерпретировать полученные в эксперименте значения выборочных коэффициентов корреляции. Мы узнали, с помощью каких методов можно отвечать на вопрос: значимо ли коэффициент корреляции отличается от нуля? Для корреляции Пирсона и Спирмена это делается с помощью критерия Стьюдента. Для корреляции Мэтьюса и коэффициента V Крамера — с помощью критерия хи-квадрат. В следующем видео мы продолжим говорить о том, как значения коэффициентов корреляции правильно интерпретировать.

В этом видео мы поговорим про соответствие между корреляциями и причинно-следственными связями. Спойлер: оно не взаимно однозначное. Давайте проанализируем корреляцию между такими двумя признаками: один из них — это суммарные продажи мороженого за день, а второй — это количество людей, которое в этот день утонуло на всех пляжах города. Корреляция между этими двумя признаками положительная, она равна 0,30. Достигаемый уровень значимости критерия Стьюдента — 0,0009. 95 % доверительный интервал для корреляции Пирсона от 0,138 до 0,491. Значит ли это, что чем больше люди едят мороженого, тем чаще они тонут? Или может быть, это значит, что из-за того, что люди часто тонут, другие люди больше едят мороженого? На самом деле мы прекрасно понимаем, что это не так. Мы уже видели, что продажи мороженого очень неплохо коррелированы со среднедневной температурой. Если мы посмотрим на корреляцию между среднедневной температурой и вторым признаком (число утонувших людей), мы увидим, что она еще больше, это естестественно. Таким образом, в нашем примере значимость корреляции между продажами мороженого и числом утонувших людей объясняется воздействием третьего признака — это среднедневная температура. Мы совершенно уверены в том, что именно этот третий признак — это единственный из трех, который оказывает причинно-следственное влияние на оставшиеся два. Никаких других причинно-следственных связей между этими тремя признаками быть просто не может. В учебниках по статистике можно найти большое количество веселых примеров таких ложных корреляций, объясняющихся воздействием третьего скрытого признака. Например, количество самоубийств и радиоприемников на душу населения высоко положительно коррелировано, и объясняется это воздействием признака «размер города». Уровень углекислого газа в атмосфере планеты и распространенность ожирения также высоко положительно коррелированы, и объясняется это ростом со временем уровня жизни. Рыночная доля браузера Internet Explorer и количество убийств в США тоже положительно коррелированы, и объясняется это в первую очередь фактором времени: во времени снижается и тот, и другой показатель. Иногда корреляцию между парой признаков нельзя объяснить даже влиянием никакого третьего другого, а эта корреляция просто случайна. Если мы возьмем достаточное количество величин и будем искать среди них все возможные попарные корреляции, мы найдем очень много странного. Например, можно показать, что значима положительная корреляция между количеством людей, которые утонули при падении в бассейн, и количеством фильмов, в которых снялся за год Николас Кейдж. Корреляция Пирсона между этими двумя признаками равна 0,67. Достигаемый уровень значимости критерия Стьюдента — 0,02. 95 % доверительный интервал для корреляции Пирсона — от примерно 0,1 до примерно 0,9. Несмотря на то, что он довольно широкий, 0 он не содержит. Тем не менее, абсолютно очевидно, что связать эти два признака какой бы то ни было цепочкой причинно-следственных связей не представляется возможным. Этот эффект явно случайный, и то, что мы его нашли, — это следствие того, что мы очень хорошо искали. В следующем видео мы будем говорить о том, как с этим бороться. А главные выводы, которые вы должны вынести из этого видео, — это что из корреляции никогда не следует причинно-следственная связь, но из причинно-следственной связи часто следуют корреляции. Причинно-следственная связь оставляет в данных какие-то следы, которые можно обнаружить в том числе и корреляционными методами. Однако для этого есть другие специальные методы, связанные с построением графов причинности, и лучше использовать именно их.
Этот урок посвящен параметрическим критериям проверки гипотез. Параметрическими они называются потому, что они предполагают, что выборки, с которыми они имеют дело, взяты из каких-то конкретных распределений и проверяют гипотезы, связанные со значениями параметров этих распределений. Мы разберем несколько самых важных типов критериев и начнем с критериев, которые связаны с гипотезами о значениях параметров распределения нормального — главного распределения статистики. В ближайших нескольких видео мы разберемся с семейством критериев Стьюдента, которые позволяют проверять гипотезы о математических ожиданиях нормальных распределений. Это видео посвящено одновыборочным критериям Стьюдента. Давайте рассмотрим следующий пример. Средний вес детей при рождении составляет 3300 граммов, в то же время у женщин, живущих за чертой бедности, он равен 2800 граммам. Вес при рождении — это очень важный показатель здоровья ребенка. Так, только 7 % детей рождаются с весом меньше 2,5 килограммов, в то же время на них приходится 70 % детских смертей. Мы заинтересованы в том, чтобы у женщин, живущих за чертой бедности, дети рождались больше, поэтому мы разработали некоторую экспериментальную программу ведения беременности, и чтобы проверить ее эффективность, нам нужен эксперимент. В эксперименте участвует 25 женщин, живущих за чертой бедности. По итогам программы ведения беременности у всех у них рождаются дети, и средний вес ребенка в нашей выборке составляет 3075 граммов. Много это или мало? Эффективна ли программа, которую мы придумали? Вот для того чтобы ответить на это вопрос, и используется критерий Стьюдента. Давайте начнем вводить математический аппарат, который нужен для того чтобы эту задачу решить. Пусть у нас есть выборка из нормального распределения с какими-то параметрами μ и σ, и эта выборка объема n. Давайте для начала представим, что значение параметра σ, который определяет разброс, нам откуда-то известно. Мы хотим проверить гипотезу о том, что среднее значение нашего распределения μ равно какой-то константе μ0. Эту гипотезу мы можем проверять против разных альтернатив: μ меньше, чем μ0; μ больше, чем μ0; μ ≠ μ0. Первые два типа альтернативы называются односторонними, а последний — двухсторонний. Эту нулевую гипотезу мы будем проверять с помощью Z-статистики. Значение Z-статистики равно отношению разности выборочного среднего и μ к σ, деленному на корень из n. Если нулевая гипотеза справедлива, то наша статистика имеет стандартное нормальное распределение. Большая часть критериев, статистика которых имеет стандартное нормальное нулевое распределение, называются Z-критериями. Этот критерий не исключение. Как посчитать достигаемый уровень значимости такого критерия? Это уже зависит от того, какой именно тип альтернативы мы используем. Представьте, что альтернатива у нас односторонняя, вида μ меньше, чем μ0. Если такая альтернатива справедлива, то более вероятными являются маленькие значения нашей Z-статистики. Поэтому интересовать нас в нашем нулевом распределении будет левый хвост. Таким образом, чтобы посчитать достигаемый уровень значимости, нужно взять интеграл от плотности нулевого распределения стандартного нормального от −∞ до значения статистики Z, которая реализовалась в нашем эксперименте. Представьте, что вы получили значение Z, равное −2, в таком случае ваш достигаемый уровень значимости — это интеграл от плотности стандартного нормального распределения от −∞ до −2. На самом деле, само значение интеграла вычислять не нужно, потому что значение этого интеграла в точности равно значению функции стандартного нормального распределения в точке z. Если вы используете противоположную одностороннюю альтернативу вида μ больше, чем μ0, то при такой альтернативе более вероятными являются большие значения статистики. Поэтому для того чтобы посчитать достигаемый уровень значимости, нужно взять интеграл по правому хвосту плотности нашего нулевого распределения. Этот интеграл в свою очередь равен 1 минус значение функции распределения в точке z. Вот если у вас получилось значение статистики, равным −2, то ваш p-value — это интеграл от −2 до +∞, или 1 минус значение функции стандартного нормального распределения в точке −2. Если же вы используете двухстороннюю альтернативу, то при ее справедливости более вероятными будут большие по модулю значения статистики Z. Поэтому при подсчете достигаемого уровня значимости вас будут интересовать и левый, и правый хвосты вашего нулевого распределения. Если вы получили значения статистики Z, равное −2, то достигаемый уровень значимости равен сумме интегралов от −∞ до −2 и от 2 до ∞. Чтобы не считать эти два интеграла, можно просто удвоить и значение 1 минус значение функции стандартного нормального распределения, взятое в точке |z|. Давайте теперь разберем более общий случай, когда дисперсия распределения, из которого взята ваша выборка, вам ниоткуда неизвестна, то есть вы не знаете σ. В этом случае вместо Z-критерия Стьюдента нужно использовать t-критерий Стьюдента. Он использует следующую идею: поскольку σ мы не знаем, естественный шаг — это в формуле, где σ используется, то есть в формуле нашей статистики, заменить σ на S, то есть на выборочное стандартное отклонение. Вот статистика t-критерия Стьюдента ровно такая — это разность выборочного среднего и μ0, деленное на S, деленное на корень из n. Такая статистика имеет уже не стандартное нормальное нулевое распределение, а распределение Стьюдента с числом степеней свободы n − 1. Достигаемый уровень значимости для t-критерия Стьюдента считается абсолютно так же, как и для Z-критерия. В зависимости от типа альтернативы вы выбираете одно из этих трех выражений для достигаемого уровня значимости. Единственное отличие от Z-критерия заключается в том, что вместо функции стандартного нормального распределения вы берете функцию распределения Стьюдента с числом степеней свободы n − 1. Чем больше в вашей задаче объем выборки, тем меньше различий между t- и Z-критериями. Это происходит по двум причинам: во-первых, чем больше n, тем точнее выборочная дисперсия S квадрат оценивает теоретическую дисперсию σ квадрат. Во-вторых, с ростом n увеличивается число степеней свободы у нулевого распределения t-критерия. А чем больше степеней свободы у распределения Стьюдента, тем больше оно похоже на стандартное нормальное. Мы говорили о том, что, начиная с числа степеней свободы, равного 30, распределение Стьюдента визуально практически от стандартного нормального неотличимо. Благодаря этим двум фактам для достаточно больших выборок эффект от знания истинного значения дисперсии не очень большой. Давайте теперь вернемся к весу детей при рождении и сформулируем задачу оценки эффективности нашей экспериментальной программы формально. Мы будем проверять нулевую гипотезу о том, что программа неэффективна, то есть математическим языком μ = 2800, то есть вес детей, прошедших экспериментальную программу, средний такой же, как и у детей, живущих за чертой бедности в целом. Эту нулевую гипотезу мы будем проверять против двухсторонней альтернативы о том, что программа как-то влияет на вес детей — μ ≠ 2800. Поскольку мы не знаем теоретическую дисперсию σ квадрат, а знаем только ее выборочную оценку S квадрат, используем t-критерий Стьюдента. С его помощью для такой пары гипотеза-альтернатива мы получаем достигаемый уровень значимости порядка 7 × 10 в −13-й. То есть мы отвергаем нулевую гипотезу о том, что средний вес детей не меняется. Точечная оценка для прироста среднего веса детей в результате использования нашей экспериментальной программы равна просто разности выборочного среднего веса и μ0 и равна 275 граммам. Доверительный интервал для этой величины составляет от 234 до 316 граммов, и этот доверительный интервал инвариантен критерию Стьюдента, который мы применили, и основан на том же самом распределении Стьюдента. Вообще говоря, в этой задаче нулевую гипотезу можно проверять не против двухсторонней, а против односторонней альтернативы. Гипотеза может выглядеть как «программа эффективна», то есть средний вес детей в результате нашей программы повышается — μ больше, чем 2800. Для такой пары гипотеза-альтернатива t-критерий дает достигаемый уровень значимости ровно в 2 раза меньше, порядка 4 × 10 в −13-й. Точечная оценка для прироста среднего веса не меняется и составляет все еще 375 граммов. А вот доверительный интервал становится односторонним, то есть мы утверждаем, что на уровне доверия 95 % наш средний вес увеличивается не меньше, чем на 241 грамм. В примере, который мы только что рассмотрели, мы увидели, что, используя одностороннюю альтернативу вместо двухсторонней, можно получить достигаемый уровень значимости в два раза меньше. В нашей задаче это было не критично, поскольку оба достигаемых уровня значимости очень маленькие. Но иногда может так оказаться, что ваш p-value против двухсторонней альтернативы достаточно большой, больше магического порога в 0.05, а против односторонней альтернативы вы получаете p-value меньше. То есть, используя одностороннюю альтернативу против двухсторонней, вы можете получить отвержение нулевой гипотезы. Казалось бы, почему тогда не использовать всегда одностороннюю альтернативу? Дело в том, что это нечестно. Альтернатива может быть односторонней, только если, во-первых, вы абсолютно уверены в том, что среднее изменится в какую-то определенную сторону и изменение среднего в противоположную сторону не вероятно. Во-вторых, направление этого изменения вы можете определить еще до того, как вы собрали данные. Если вы берете одностороннюю альтернативу, после того как вы посмотрели на данные, выбрав ее так, что ее знак соответствует знаку изменения выборочного среднего относительно μ0, вы переобучились. Так делать нельзя. Итак, в этом видео мы ввели одновыборочные t- и Z- критерии и поговорили о том, как правильно выбирать тип альтернативы: одностороннюю или двухстороннюю. В следующем видео мы перейдем к двухвыборочным задачам и рассмотрим критерий Стьюдента для них.

[БЕЗ_ЗВУКА] Из этого видео вы узнаете, как с помощью двух выборочных критериев Стьюдента сравнивать среднее значение двух выборок из нормального распределения. И эту задачу мы будем рассматривать на данных General Social Survey. Это социологический опрос, который проводится на достаточно больших выборках в США уже больше 40 лет. В этом опросе очень-очень много вопросов, которые респондентам задают. Мы будем рассматривать среди них только один. В 1974 году 108 респондентов этого опроса работали неполный рабочий день. В 2014 году таких среди опрошенных было 196. Для каждого из таких опрошенных известно количество рабочих часов за неделю, предшествующую опросу. Задачу, которую мы хотим решить по этим данным — надо понять, изменилось ли среднее время работы у работающих неполный день за прошедшие 40 лет? Данные, которые мы будем анализировать, визуализированы на вот этом графике. Такой график называется boxplot, или ящик с усами. Это способ визуализации основных характеристик распределения. Он состоит из прямоугольника — ящика, и торчащих из него усов. Посередине прямоугольника проходит черта, которая соответствует выборочной медиане вашей выборки. Ширина ящика равна интерквартильному размаху, то есть его нижняя граница — это 25 %-й квантиль, а верхняя — 75 %-й квантиль. Длина усов составляет 1,5 интерквартильных размаха, однако в разных реализациях боксплота кончик уса может рисоваться в разных местах. Так на графике в нашей задаче усы обрезаются так, что их конец соответствует последнему элементу выборки в этом направлении. Два кружочка, которые вы видите на верхнем боксплоте, это объекты выборки, не попавшие в диапазон 1,5 интерквартильных размаха. Что мы видим на этом графике? Ну мы видим, что выборочные медианы наших двух выборок, соответствующих 1974 и 2014 году, отличаются. В 2014 году люди работают в среднем больше. Но значимо ли это различие? Для того чтобы это проверить, нам нужен статистический критерий. Давайте начнем с Z-критерия. У нас есть две выборки из нормальных распределений. Каждая из выборок своего размера. Первый размер — n1, второй размер — n2. Кроме того, каждая из выборок взята из своего нормального распределения. Первая из распределения с параметрами μ1, σ1, вторая — μ2, σ2. Предположим для начала, что σ1 и σ2 нам известны. Мы хотим проверить нулевую гипотезу о том, что μ1 = μ2, то есть среднее значение двух выборок совпадают. Эту нулевую гипотезу мы можем проверять против любой односторонней или двусторонней альтернативы. Проверять ее мы будем с помощью Z-статистики, которая равна отношению разности выборочных средних x1 и x2 к корню из некоторой дисперсии, равной сумме дисперсии σ1 квадрат и σ2 квадрат, деленных на соответствующие объемы выборок n1 и n2. Если нулевая гипотеза справедлива, Z-статистика имеет стандартное нормальное распределение. Именно поэтому это Z-критерий. Давайте сразу рассмотрим более сложный случай, когда дисперсии нам не известны. Будем действовать по аналогии с одновыборочным случаем. Возьмем формулу для Z-критерия и заменим все неизвестные σ на их выборочные оценки S1 и S2. Такая статистика уже будет не Z, а t-статистикой, и иметь она будет распределение Стьюдента. Однако у этой задачи есть две проблемы. Во-первых, число степеней свободы у этого нулевого распределения Стьюдента ν вычисляется по вот такой достаточно сложной и непонятной формуле. Во-вторых, нулевое распределение нашей статистики не точное, а приближенное. Обратите внимание на знак «приближения» перед распределением Стьюдента в последней строке. Точного решения в этой задаче, то есть точного нулевого распределения для такой статистики, не существует. Это проблема. Эта проблема называется проблемой Беренца-Фишера — сравнивать среднее значение в двух выборках, дисперсии которых вы не знаете, точно невозможно. Однако вот эта аппроксимация, которую мы сейчас рассматриваем, достаточно точна в двух ситуациях. Во-первых, если у вас выборки X1 и X2 одинакового объема, то есть n1 = n2. Во-вторых, если знак неравенства между n1 и n2 такой же, как между σ1 и σ2, то есть у выборки, у которой дисперсия больше, объем всегда не меньше. Вот если это справедливо, можно использовать t-критерий Стьюдента и не переживать о точности аппроксимации. Если это не так — это проблема. Если у вас выборка меньшего объема имеет большую дисперсию, критерий Стьюдента перестает правильно работать, то есть доля ошибок первого рода, которые он совершает, начинает превышать уровень значимости α, то есть вы совершаете ошибку первого рода с вероятностью больше, чем 0,05. Это проблема не только критерия Стьюдента. Она возникает при проверке любым способом гипотезы о равенстве средних в двух выборках с разной дисперсией. Поэтому сравнивая среднее значение в двух выборках, всегда следите за тем, чтобы выборка с большей дисперсией всегда была не меньшего объема, чем вторая выборка. Вернемся к нашему примеру. Проверим нулевую гипотезу о том, что средняя продолжительность рабочей недели у людей, которые работают не полный рабочий день, за прошедшие 40 лет не изменилась, то есть μ1 = μ2. Проверим ее против двусторонней альтернативы μ1 не равно μ2 — среднее время работы изменилось. Мы могли бы здесь взять и какую-нибудь двустороннюю альтернативу. Однако, честно говоря, мы вряд ли заранее уверены в знаке изменения, а на данные мы уже посмотрели. Так что по данным одностороннюю альтернативу выбирать не честно. Критерий Стьюдента в нашей задаче дает достигаемый уровень значимости примерно 0,03, то есть на уровне значимости 0,05 гипотеза о равенстве средних отвергается. Точечная оценка для прироста средней продолжительности рабочей недели составляет 2,57 часов. 95 %-й доверительный интервал для нее от 0,29 до 4,85, то есть люди стали работать в среднем больше, и доверительный интервал для прироста этого времени составляет от получаса до 4,8 часов. Итак, в этом видео мы познакомились с t и Z критериями Стьюдента для двухвыборочного случая, которые позволяют сравнивать среднее значение двух выборок, и узнали, что такое проблема Беренца-Фишера, которая возникает при сравнении средних в выборках с неизвестными дисперсиями. В следующем видео мы поговорим о случае связанных выборок и о двухвыборочном критерии Стьюдента для этого случая.

Это видео посвящено критерию Стьюдента для связанных выборок. С помощью этого критерия мы будем решать задачу оценки эффективности лечения синдрома дефицита внимания и гиперактивности у умственно отсталых детей. В эксперименте участвуют 24 ребенка. Каждый из них неделю принимает плацебо, а неделю принимает препарат метилфенидат. По окончании каждой недели каждый ребенок проходит тест на способность к подавлению импульсивных поведенческих реакций. Данные, которые мы анализируем, перед вами на этой диаграмме рассеяния. По горизонтальной оси здесь отложена способность к подавлению импульсивных поведенческих реакций после недели приема плацебо, по вертикальной — после недели приема препарата. Каждая точка здесь соответсвует одному ребенку. Таким образом, несмотря на то что у нас две выборки, эти выборки не являются независимыми, поскольку значения здесь померяны на одних и тех же объектах. Это и есть случай связанных выборок. Мы хотим понять, эффективно ли лечение с помощью метилфенидата. Большая часть точек на этом графике лежит выше диагонали. Это значит, что после приема метилфенидата у большинства детей способность к подавлению импульсивных поведенческих реакций увеличилась. Но значимо ли это изменение? Для того чтобы ответить на этот вопрос, нам нужен статистический критерий. Будем использовать t-критерий Стьюдента для связанных выборок. Итак, у нас есть две связанные выборки одинакового объема n. Первая — из нормального распределения с параметрами μ1 и σ1, вторая — с параметрами μ2 и σ2. Мы хотим проверять нулевую гипотезу о том, что μ1 и μ2 равны, и мы можем это делать против любой односторонней или двусторонней альтернативы. Проверку мы будем вести с помощью T-статистики, равной отношению разности выборочных средних X1 и X2 к какому-то стандартному отклонению S / √n. Вот это S — это выборочное стандартное отклонение, посчитанное на выборке D попарных разностей между X1 и X2, взятых на соответствующих объектах. Нулевое распределение такой статистики — это распределение Стьюдента с числом степеней свободы n − 1. В числителе здесь стоит разность выборочных средних X1 и X2. Это то же самое, что выборочное среднее разности X1 − X2. Таким образом, t-критерий для двух связанных выборок эквивалентен одновыборочному t-критерию, примененному к выборке попарных разностей. Вернемся к нашей задаче. Нулевая гипотеза, которую мы проверяем, — это отсутствие эффективности нашего лечения: способность к подавлению импульсивных поведенческих реакций не изменилась, μ1 = μ2. Проверять эту гипотезу мы будем против двусторонней альтернативы, поскольку мы не можем исключать, что способность к подавлению импульсивных поведенческих реакций в результате применения нашего препарата уменьшится. t-критерий Стьюдента для связанных выборок дает значение достигаемого уровня значимости p, равное примерно 0,004. То есть нулевая гипотеза о том, что средняя способность к подавлению импульсивных поведенческих реакций не изменилась, отвергается на уровне значимости 0,05. Точечная оценка для изменения признака в результате применения нашего препарата, а это разность выборочных средних, и равна она примерно пяти пунктам. 95 % доверительный интервал для этой величины, построенный с помощью распределения Стьюдента, составляет от 1,8 до 8,1 пунктов. Итак, на протяжении последних трех видео мы рассмотрели пять разновидностей t- и z-критериев Стьюдента. Мы рассмотрели критерии Стьюдента для одновыборочной задачи, для двухвыборочной задачи с независимыми выборками и со связанными выборками. В следующем видео мы поговорим о предположении нормальности, которое лежит в основе всех рассмотренных нами критериев.

В предыдущих видео этого урока мы поговорили про критерии Стьюдента, которые проверяют гипотезы о средних значениях выборок в предположении, что эти выборки взяты из нормального распределения. Из этого видео вы узнаете, как эту нормальность нужно проверять. На самом деле, инструмент для проверки нормальности у нас уже есть. Это критерий согласия Пирсона, или критерий хи-квадрат. Работает он следующим образом. На входе у вас есть выборка длины n и нулевая гипотеза о том, что эта выборка взята из нормального распределения. Мы будем проверять эту гипотезу против общей альтернативы, то есть против альтернативы вида «H0 неверна». Статистика критерия конструируется следующим образом: мы разбиваем область изменения нашей случайной величины на K интервалов, или карманов. Границы этих интервалов задаются величинами ai. Для каждого интервала [ai, ai + 1] мы считаем, во-первых, ni — это число элементов вашей выборки, которое попало в интервал, во-вторых, pi — это теоретическая вероятность попадания в этот интервал при условии справедливости нулевой гипотезы. В данном случае это всего лишь разность функций нормального распределения в точках ai + 1 и ai. А дальше из этих ni и pi конструируется значение статистики следующим образом. Вы суммируете по всем K-интервалам следующую величину: в числителе (ni − n * pi)², то есть разности количества объектов выборки в интервале и ожидаемого количества объектов выборки в интервале при условии справедливости нулевой гипотезы. В знаменателе вот это самое ожидаемое количество объектов выборки в вашем интервале. Если нулевая гипотеза справедлива, то такая статистика имеет распределение хи-квадрат. Причем если μ и σ вашего нормального распределения известны вам откуда-то заранее, то число степеней свободы у распределения хи-квадрат равно K − 1. Если же вы их оцениваете по той же самой выборке, то K − 3. Чтобы посчитать значение достигаемого уровня значимости, вы от распределения хи-квадрат берете интеграл по правому хвосту начиная от значения статистики, которое реализуется в ваших данных. Критерий хи-квадрат обладает несколькими очевидными недостатками. Во-первых, разбиение на интервалы в нём никак не зафиксированы и теоретически, выбирая разные интервалы, вы можете получать разные результаты. Кроме того, он требует достаточно больших выборок. Необходимо, чтобы ожидаемое количество объектов выборки в каждом интервале превышало 5 как минимум для 80 % ячеек. А вот очень удобный способ визуальной проверки предположения нормальности — ку-ку график. Для того чтобы такой график построить, вы превращаете вашу выборку в вариационный ряд, то есть сортируете ее по неубыванию и дальше ставите на этом графике точку для каждого объекта выборки. Значение по вертикальной оси соответствует значению вашего X, а значение по горизонтальной оси — математическому ожиданию квантиля стандартного нормального распределения, посчитанного по выборке такого объема. Чтобы это лучше понять, давайте посмотрим на точку в нижнем левом углу. Эта точка соответствует наименьшему значению в вашей выборке. Пусть у вас выборка объема — 100. Таким образом, эта точка — это минимум из всех 100 элементов. Значение этого минимума отложено по вертикальной оси. По горизонтальной оси отложено математическое ожидание минимума из 100 независимых одинаково распределенных случайных величин из стандартного нормального распределения. Если ваша выборка взята из нормального распределения, точки на ку-ку графике должны лежать примерно на прямой. Если точки лучше описываются какой-то странной кривой или какие-то из точек лежат от прямой очень далеко, скорее всего, распределение вашей выборки отличается от нормального. Формально проверить соответствие распределения вашей выборки нормальному можно еще с помощью критерия Шапиро-Уилка. Этот критерий основан на ку-ку графике, он проверяет фактически, насколько сильно точки на ку-ку графике отклоняются от прямой, проверяет нулевую гипотезу нормальности против общей альтернативы, и делает это с помощью статистики W, которая рассчитывается на основании вариационного ряда, посчитанного по вашей выборке, и некоторых величин a. Эти величины основаны на математических ожиданиях порядковых статистик из стандартного нормального распределения, они табулированы, для них не существует аналитических выражений. Кроме того, табулировано и нулевое распределение статистики критерия Шапиро-Уилка, то есть его невозможно записать аналитически, но тем не менее, достигаемый уровень значимости посчитать по этим таблицам можно, поэтому какая разница. На самом деле, для проверки гипотезы нормальности существуют еще десятки других критериев: критерий Харке-Бера, Колмогорова, он же Лиллиефорса, Крамера-фон Мизеса, Андерсона-Дарлинга и так далее, можно продолжать очень долго. Какие из этих критериев лучше использовать? Для того чтобы ответить на этот вопрос, давайте сначала вернемся на шаг назад и поговорим о том, зачем вообще нужно формально проверять нормальность. Дело в том, что проверка гипотезы нормальности наследует плохие свойства всего аппарата проверки гипотез, которые заключаются в том, что на маленьких выборках нулевая гипотеза у вас, как правило, не отклоняется, а на выборках огромного размера, как правило, отклоняется. То есть если ваша выборка маленькая, вы, формально проверяя нормальность, никогда не сможете ее отклонить, а если выборка огромна, всегда отклоните ее, даже если распределение отличается от нормального совсем чуть-чуть. Дело в том, что многие методы, предполагающие нормальность, в том числе критерии Стьюдента, которые мы рассмотрели, нечувствительны к отклонениями от этой нормальности, то есть распределение истинное вашей выборки может слегка от нормального отличаться, и t-критерий будет всё еще правильно работать. Нормальное распределение — это математический конструкт. Никаких нормальных выборок в природе не существует. Однако как говорил Джордж Бокс: «Все модели неверны, а некоторые полезны». Нормальные модели очень полезны, поэтому их имеет смысл использовать. В итоге, я предлагаю вам использовать следующий алгоритм. Если данные, которые вы анализируете, имеют распределение, явно отличающееся от нормального, например, ваша выборка бинарна или признак, который вы измеряете, — категориальный, не нужно использовать метод, предполагающий нормальность. Выберите метод, специально разработанный именно для такого распределения. Если признак, который вы исследуете, по крайней мере, измерен в непрерывной шкале, постройте ку-ку график. Если на этом графике не видно существенных отклонений от нормальности, точки лежат примерно на прямой, можете сразу использовать методы, устойчивые к небольшим отклонениям от нормальности, например, критерии Стьюдента. Если метод, который вы хотите использовать, чувствителен к отклонениям от нормальности, проверьте нормальность формально, и рекомендуется это делать с помощью метода Шапиро-Уилка. Показано, что критерий Шапиро-Уилка обладает достаточно хорошей мощностью для разных больших и интересных классов альтернатив. Если критерий Шапиро-Уилка формально отвергает нормальность, не нужно использовать методы, чувствительные к отклонениям от нормальности, используйте что-нибудь другое. Итак, в этом видео мы поговорили про нормальность и способы ее проверки. В следующем видео вас ждет пример применения рассмотренных методов в Python.

Привет! В этом видео мы потренируемся применять критерий Стьюдента на практике. Тренироваться будем на известной задаче Treatment effects of methylphenidate. Это известное исследование, в рамках которого 24 пациента с синдромом дефицита внимания и гиперактивностью в течение недели применяли препарат и плацебо. После этого пациенты проходили тест на способность к подавлению импульсивных поведенческих реакций, после чего метилфенидат и плацебо менялись местами, и пациенты вновь проходили такой же тест. В задаче требуется оценить эффективность применения препарата. Таким образом, мы имеем следующие данные. Для каждого пациента мы имеем измерения его способности к подавлению импульсивных поведенческих реакций после приема препарата и после плацебо. Вот давайте эти данные загрузим и попытаемся их визуализировать. По осям X и Y отметим плацебо и метилфенидат соответственно и отметим точки, соответствующие пациентам. Также проведем диагональную прямую и увидим, что практически все точки лежат выше этой прямой. Это дает нам основания предполагать, что применение препарата способно помочь пациентам, но, конечно, мы не можем это оценивать просто по графику. Нам нужен некоторый более строгий критерий для проверки таких гипотез. Вот ровно этим критерием будет выступать критерий Стьюдента. Для начала давайте еще немножко посмотрим на данные, а именно отобразим гистограммы распределения проверяемой способности. Видим, что гистограммы разные, их довольно сложно сравнивать, но вот можем сказать, что, например, минимальное значение способности к подавлению импульсивных реакций при приеме плацебо меньше, чем при приеме препарата, но и максимальное значение при приеме препарата больше, однако это все равно не дает нам возможности формально сказать, что препарат помогает. Итак, давайте начнем с одновыборочного критерия Стьюдента. Исходя из того, что способность к подавлению импульсивных поведенческих реакций измеряется по шкале от 0 до 100, то можно предположить, что в хорошо откалиброванной сбалансированной выборке средняя способность к подавлению импульсивных поведенческих реакций составит 50. Тогда, для того чтобы проверить гипотезу о том, что наши пациенты в выборке действительно нуждаются в лечении, давайте проверим гипотезу о том, что их средняя возможность к подавлению импульсивных поведенческих реакций отличается от 50. Для этого нам понадобится одновыборочный тест Стьюдента. Гипотеза H0 будет следующая: среднее значение способности к подавлению импульсивных поведенческих реакций равна 50. Соответственно альтернатива — не равняется 50. Итак, для того чтобы воспользоваться одновыборочным тестом Стьюдента, нам понадобится библиотека scipy, воспользуемся модулем stats, функция t-test one sample, одновыборочный t-test Стьюдента. Итак, передаем туда наши данные, это data.Placebo, потому что нас интересуют пациенты до применения препарата, и передаем туда параметр 50 — это то значение, с которым мы сравниваемся. Итак, видим, что значение статистики равняется −4,4, и pvalue довольно маленькое. Это позволяет нам уверенно отвергнуть нулевую гипотезу и сказать, что среднее не равно 50. Для того чтобы на это посмотреть, давайте интервально оценим среднее по выборке. Сделаем это с помощью метода zconfint. Ну вот видим, что наш интервал целиком лежит левее 50, что в среднем способность измеряется от 35 до 44 пунктов. Ну это меньше 50. Итак, мы убедились, что действительно наши пациенты нуждаются в некоторой помощи и теперь давайте применим двухвыборочный критерий Стьюдента для независимых выборок, для того чтобы оценить, помогает ли исследуемый препарат. Для того чтобы использовать двухвыборочный критерий Стьюдента, сначала нужно убедиться, что распределения выборок существенно не отличаются от нормального. Для этого давайте построим Q-Q plot для каждого из распределений: для плацебо и для препарата. Итак, Q-Q plot строится достаточно просто, это делается с помощью функции probplot из модуля stats, и давайте его проанализируем. Итак, в общем-то, мы видим, что и в том и в другом случае наши точки не сильно отличаются от прямой, они лежат не очень далеко. Это дает нам основание предполагать, что данные распределены с некоторым распределением, которое сильно от нормального не отличается. Однако для того чтобы проверить это более строго, давайте воспользуемся критерием Шапиро-Уилка. В данном случае нулевая гипотеза будет соответствовать тому, что способность к подавлению реакций распределена нормально, соответственно, альтернатива — распределена по-другому, не нормально. Итак, сначала давайте проверим тест для плацебо. Видим, что pvalue получается 0,003, довольно маленькое значение. И теперь для Шапиро. Видим, что pvalue получается равным 0,05. Ну, в общем-то, значения получаются довольно маленькими, а значит нам придется отвергнуть гипотезу H0. Получается, что данные все-таки не распределены нормально. Однако если мы вернемся к предыдущем рисункам, мы видим, что да, действительно, распределение от нормального отличается, но не очень сильно. А мы знаем, что критерий Стьюдента работает в условиях, когда распределение не является нормальным, но существенно от него не отличается. Значит, давайте все-таки попробуем применить критерий Стьюдента. Итак, в случае применения критерия Стьюдента имеем следующую нулевую гипотезу: среднее значение способности к подавлению импульсивных поведенческих реакций после применения плацебо и после применения препарата не отличаются. Альтернативная гипотеза: средние по выборкам отличаются. Итак, для того чтобы воспользоваться готовой реализацией двухвыборочного теста Стьюдента в случае независимых выборок, нам снова понадобится библиотека scipy, модуль stats. В данном случае мы используем функцию ttest ind, от слова independent. Итак, в метод мы передаем данные, связанные с одной выборкой, с другой выборкой, а также указываем параметр equal var (equal variance) равняется false. Потому что у нас нет данных о том, что дисперсии одинаковые. Итак, давайте посчитаем t-test и увидим, что значение статистики равняется −1,45 и pvalue равняется 0,15, то есть pvalue достаточно большое, а значит, мы не можем отвергнуть нулевую гипотезу. Получается, что вероятнее всего, препарат все-таки помогает. Давайте интервально оценим разность средних по этим двум выборкам. Для этого воспользуемся методом CompareMeans. Видим, что доверительный интервал получился следующим: от −2 до 12. То есть фактически наше среднее все-таки скорее больше, чем 0, однако 0 лежит в этом интервале. Получается, что однозначно сказать все-таки довольно сложно. Итак, давайте вспомним то, что на самом деле мы с вами рассматриваем 24 пациента, каждый из которых одну неделю применял препарат, а другую неделю применял плацебо. Получается, что выборка, связанная с применением плацебо и выборка, связанная с применением препарата являются зависимыми. Таким образом, в данной задаче мы можем использовать двухвыборочный критерий Стьюдента для связанных выборок. Вот давайте его применим. Для того чтобы этот критерий использовать, нам также нужно убедиться в нормальности данных. Давайте рассчитаем попарные разности и убедимся, что распределение попарных разностей существенно не отличается от нормального. Давайте снова нарисуем Q-Q plot, сделаем это с помощью метода probplot, и убедимся, что наши точки находятся очень близко к прямой, значит распределение, скорее всего, похоже на нормальное. Снова применим критерий Шапиро-Уилка, в данном случае нулевая гипотеза — попарные разности распределены нормально, альтернатива — это не так. Итак, применяем критерий с помощью метода stats.shapiro, передаем туда разности и смотрим на значения. Видим, что pvalue получилось большое, 0,89, а значит, нулевую гипотезу отвергать нельзя, данные распределены нормально. Отлично, можно смело применять критерий Стьюдента. В данном случае наша нулевая гипотеза имеет следующий вид: средние значения к подавлению импульсивных поведенческих реакций одинаковы для пациентов, применявших плацебо и применявших препарат. Соответственно, альтернатива: средние значения способности отличаются. Итак, воспользуемся реализацией из модуля stats библиотеки scipy, функция называется ttest rel, от слова relative (зависимые) и передаем внутрь функции данные, связанные с применением плацебо и с применением препарата. Давайте рассчитаем и увидим, что значение статистики составляет 3,2, pvalue — всего лишь 0,004. Это значит, что мы можем уверенно откинуть нулевую гипотезу, отвергнуть ее, и прийти к выводу, что все-таки способности к подавлениям импульсивных поведенческих реакций отличаются. Давайте в данном случае оценим доверительный интервал разности, однако будем помнить, что мы работаем со связанными выборками, поэтому будем использовать соответствующую функциональность, и увидим, что весь доверительный интервал находится правее нуля, а значит, что применение препарата все-таки способствует росту способности подавления импульсивных поведенческих реакций. Видим, что разность в среднем изменяется от 2 до 8. На этом мы с вами заканчиваем, мы научились применять одновыборочный критерий Стьюдента, а также двухвыборочный критерий в случае независимых и связанных выборок, а на следующем уроке мы поговорим о гипотезах о долях.

[БЕЗ_ЗВУКА] В этом видео мы рассмотрим еще одно семейство параметрических критериев — это критерии, которые работают с распределениями Бернулли, то есть они принимают на вход какие-то выборки из нулей и единиц и проверяют гипотезы о параметрах p этих бернуллиевских распределений, то есть о параметрах, определяющих вероятность появления единицы в выборке. С распределением Бернулли работать удобно, потому что когда перед вами выборка из этого распределения, вы сразу это понимаете. В отличие от нормального распределения, например, не нужно никаких специальных механизмов, для того чтобы проверять, действительно ли ваша выборка ему соответствует. Если ваша выборка принимает только два значения — это распределение Бернулли. Мы рассмотрим три критерия, решающие три задачи: одновыборочную, двухвыброчную с независимыми выборками и двухвыборочную со связанными выборками. Давайте начнем со следующего примера. В 70-х годах известный педиатр и автор книг по воспитанию детей Бенджамин Спок был арестован за участие в антивоенной демонстрации в Бостоне. Его дело должен был рассматривать суд присяжных. Отбор присяжных — это сложная многоступенчатая процедура. И вот на очередном этапе там оказывается 300 человек, из которых дальше каким-то образом отбираются финальные 12. В процессе Бенджамина Спока среди этих 300 только 90 были женщинами, и адвокаты падали протест. Поскольку в те времена воспитанием детей занимались в основном женщины, Бенджамин Спок среди них был более популярен, поэтому адвокаты заподозрили, что обвинение каким-то образом специально пытается сделать финальный состав присяжных менее благосклонным к подсудимому. Как проверить на таких данных, что отбор был или не был беспристрастным? Для этого нужен статистический критерий. Это делает Z-критерий для доли, он принимает на вход выборку длины n из распределения Бернулли, с каким-то параметром p, нам неизвестным, и проверяет гипотезу о том, что значение этого параметра равно некоторой константе p0. Это можно делать против любой односторонней или двусторонней альтернативы. Делает критерий это с помощью Z статистики, равной отношению разности p с крышкой и p0 к корню из дисперсии p с крышкой при справедливости нулевой гипотезы. То есть p0 * (1 – p0) / n. p с крышкой, напомню, это просто выборочное среднее нашей выборки, то есть доля единиц в ней. Нулевой распределение статистики Z-критерия — стандартное нормальное. В задаче с отбором присяжных нулевая гипотеза о том, что значение параметра равно ½, то есть процедура отбора беспристрастна, женщины попадают в выборку с вероятностью 0,5, против двусторонней альтернативы уверенно отвергается. Достигаемый уровень значимости составляет порядка 5 на 10 в –12. Точечная оценка для вероятности попадания женщин в нашу выборку составляет 0,3. 95-процентный интервал для этой вероятности — от 0,25 до 0,35, примерно. Эта выборка достаточно большая, поэтому неизвестную долю мы можем оценивать уже с погрешностью порядка 10 %. Следующая задача. У нас есть 1600 граждан Великобритании с правом голоса. Мы их опрашиваем и спрашиваем у них: одобряют ли они деятельность премьер-министра? 944 из них говорят, что одобряют. Через 6 месяцев опрос повторяется. На этот раз из 1600 опрошенных 880 говорят, что поддерживают премьер-министра. Изменился ли рейтинг премьер-министра за эти 6 месяцев? Чтобы ответить на этот вопрос, нам нужен статистический критерий. Z-критерий для двух долей принимает на вход две бернуллиевские выборки потенциально разного размера, каждая со своим параметром p1 и p2 проверяют нулевую гипотезу о том, что p1 и p2 равны. Это можно делать против любой односторонней или двусторонней альтернативы. Статистика критерия представляет собой отношение разности p1 с крышкой и p2 с крышкой к дисперсии этой разности при условии, что нулевая гипотеза справедлива и p1 действительно равно p2. Эта статистика при условии справедливости нулевой гипотезы распределена нормально со средним 0 и дисперсией 1. Данные в подобных задачах можно записать при помощи таблицы сопряженности 2 на 2. В ней по столбцам будут стоять выборки, а по строкам — исходы. Обратите внимание, что наш Z-критерий среди этих четырех чисел в таблице сопряженности abcd использует только два, стоящие в первой строчке, это количество единиц в первой и во второй выборках. Задача с оценкой изменения рейтинга премьер-министра, нулевая гипотеза о том, что рейтинг не изменился, против двусторонней альтернативы с Z-критерием отвергается. С уровнем значимости порядка 0,02, меньше чем 0,05. Рейтинг у нас упал на 4 %. 95-процентный доверительный интервал для изменения составляет от 0,6 до 7,4 %. А теперь внезапный сюжетный поворот. На самом деле в двух опросах, которые мы рассматриваем, участвовали одни и те же люди, то есть выборки, по сути, являются связанными, поскольку значения наших признаков померяны на одних и тех же объектах. Таблица 2 на 2, с помощью которой можно записать имеющиеся у нас данные, слегка меняет свой вид. Теперь здесь по строкам стоят результаты первого опроса, по столбцам — результаты второго, а в каждой ячейке — количество людей, которые в первом и втором опросе ответили именно так. То есть у нас есть 794 человека, которые премьер-министра поддерживали и продолжают поддерживать; 150 человек, которые поддерживали в первом опросе, но перестали во втором и так далее. Как эти новые данные использовать для проверки гипотезы о том, что рейтинг не изменился? Нужно использовать модифицированную версию Z-критерия для связанных выборок. Давайте в нашей таблице 2 на 2 обозначим за e, g, f, и h количество объектов выборки, которое вот в эти ячейки попадает. Z-критерий для связанных выборок принимает на вход точно так же две бернуллиевские выборки со своими параметрами p1 и p2, но эти выборки связанные, а значит, естественно, как минимум одного размера, проверяют нулевую гипотезу о том, что p1 и p2 совпадают, против любой из односторонних или двусторонней альтернативы, и делает это с помощью статистики, имеющей стандартное нормальное нулевое распределение, которая вычисляется исключительно через f и g. То есть в вычислении статистики используется исключительно внедиагональные элементы нашей таблицы 2 на 2. То есть только те объекты, на которых значения двух наших признаков отличаются, e и h, объекты на которых значения признаков совпадают, нас вообще интересовать не будут. Задача с рейтингом премьер-министра, Z-критерий для связанных выборок, нулевую гипотезу о том, что рейтинг не изменился, против двусторонней альтернативы уверенно отвергает, с достигаемым уровнем значимости порядка 3 на 10 в –5. Это существенно меньше, чем когда мы не учитывали связанность. Рейтинг упал на 4 %, точечная оценка не меняется, а вот 95-процентный доверительный интервал для изменения уже другой — от 2,1 до 5,8 %. Этот интервал уже и его край дальше отстоит от 0, который соответствует нулевой гипотезе. Итак, в этом видео мы поговорили про Z-критерии, которые проверяют нулевые гипотезы о параметрах распределений Бернулли. Мы обсудили, как это делать для одновыборочной и двухвыборочной с независимыми выборками и двухвыборочной со связанными выборками задач. В следующем видео вы увидите, как это все применяется в Python.

Привет! В этом видео мы научимся считать z-критерий для двух долей. Давайте снова рассмотрим задачу про баннеры. Напомню условия. Предположим, что мы хотим рекламировать некоторую услугу или товар с помощью рекламного баннера. Для этого у нас уже есть некоторый стандартный баннер, но дизайнеры разработали для нас новый, более прекрасный баннер. Нам с вами хочется проверить, правда ли, что новый баннер действительно лучше, чем старый, и нам имеет смысл заменить старый баннер на новый. А может быть, это не так, и имеет смысл все-таки остаться со старым. Для того чтобы это понять, мы можем провести следующий эксперимент. Создаем простую веб-формочку, в которую размещаем оба этих баннера. Далее просим некоторое количество людей, например, 1000 человек, на эти баннеры посмотреть и нажать на кнопочку like, если баннер им понравился. В результате этого эксперимента мы получим следующую выборку данных: последовательность нулей и единиц для каждого баннера, где ноль будет обозначать отсутствие клика, то есть ситуацию, когда человеку баннер не понравился, а единичка — наличие клика, ситуация, когда баннер человеку понравился. Итак, давайте загрузим соответствующие данные. Делаем это с помощью библиотеки pandas. И давайте посмотрим, как они выглядят. Мы увидим, что у нас ожидаемо два столбца. Каждый столбец соотвествует своему баннеру, и каждый столбец состоит из нулей и единиц. Ноль, если баннер не понравился, то есть клика не было, единичка, если клик был. Соответственно, нам с вами интересно оценить долю кликов или долю единичек в каждом случае. Давайте посмотрим на некоторые простые статистики по нашим данным. Видим, что количество наблюдений у нас совпадает, по тысяче наблюдений, и доля кликов в первом случае меньше, чем во втором. Остальные статистики нам не очень интересны, потому что они очевидные. Минимально-максимально ноль и единица, квантили тоже сильно ни о чем в данном случае нам не скажут. Итак, самое первое и самое простое, что мы можем сделать, это построить интервальную оценку для доли. То есть посмотреть, в каком диапазоне эта доля изменяется. Вот, напоминаю формулу Уилсона для оценки, для интервальной оценки доли. В данном случае она нам подходит больше, потому что значение нашей доли довольно близко к нулю. Мы это увидели в предыдущей таблице. Вот давайте рассчитаем интервальную оценку с помощью метода proportion_confint из модуля Stats Models и выведем результаты. Видим, что мы получили два интервала. Они довольно узкие, но проблема в том, что они пересекаются. Давайте рассчитаем некоторые критерии, которые позволят нам проверить гипотезу о том, что доли действительно отличаются, что они не равны. Мы с вами будем рассматривать z-критерий для разности долей. Для того чтобы его посчитать для начала нам нужно рассчитать следующую матрицу. Она довольно простая. Нам нужно посчитать количество единиц и количество нулей отдельно для каждого из баннеров. Далее, используя эти баннеры, мы с вами, с одной стороны, можем рассчитать доверительный интервал для разности долей, мы уже учились это делать. Напоминаю формулу, она перед вами. А также мы можем рассчитать z-статистику. Она также считается довольно просто, можете посмотреть на формулы. И далее, зная z-статистику, мы с вами можем оценить p.value по z-критерию, для z-критерия. Вот давайте это сделаем. Сначала давайте реализуем функцию для рассчета доверительного интервала, она довольно простая. В этой функции мы с вами рассчитаем все необходимые слагаемые, а далее подставим их вот в эту формулу для того чтобы получить левую и правую границы интервала. Вот давайте это сделаем. Реализация довольно простая. И теперь нам нужно с вами реализовать функцию для подсчета z-критерия. Ну, давайте посмотрим повнимательней. Чтобы эту функцию реализовать, нам нужно знать две вещи. Во-первых, нам нужно знать значение z-статистики, формула все еще перед вами. А во-вторых, нам с вами нужно понимать, на каком уровне мы хотим этот критерий проверить и рассчитать p.value для того чтобы понять, можем мы принять нулевую гипотезу или мы должны ее отклонить. Вот, давайте для начала рассчитаем z-статистику. Это довольно просто. Нам с вами нужно знать следующие параметры: N1 и N2 они очевидным образом получаются из размеров наших выборок. Дальше рассчитываем P1 и P2, P большое, и подставляем все это в формулу, таким образом, функция для рассчета z-статистики готова. Теперь давайте реализуем функцию для подсчета p.value. Функция получается довольно простая. В качестве первого аргумента мы передаем в нее метод для рассчета z-статистики, и, действительно, статистики же можно считать разные, можно их оценивать по-разному, поэтому давайте использовать метод для рассчета z-статистики в качестве аргумента этой функции. И вторым аргументом будет вид альтернативы. Ведь мы с вами сможем рассматривать как двустороннюю альтернативу, ну, например, так: гипотеза h0 в этом случае будет то, что у нас доли одинаковые, а альтернатива — то, что доли разные, неодинаковые. А также можем рассмотреть два вида односторонних гипотез, less и greater, меньше и больше. В этом случае альтернативная гипотеза была бы, что первая доля больше, чем другая, в противоположном — первая доля меньше, чем другая. Как это посчитать? Ну, давайте сначала сделаем небольшую проверку, что корректно введен тип альтернативы, проверим, что наши альтернативы, введенные альтернативы находятся среди трех возможных, и если это не так, выкинем в исключение ValueError, в котором напишем, что нужно задать одну из трех предусмотренных альтернатив. Если мы с вами рассматриваем двустороннюю альтернативу, то сначала нам нужно посчитать, значение функции распределения стандартного нормального распределения в точке z-stat, то есть в той точке, которая соответствует значению z-статистики, рассчитанной на ??? Дальше нам нужно из единицы вычесть это значение и, воспользовавшись свойством симметричности, просто умножить это на два. В случае, если мы рассматриваем альтернативу less, нам нужно просто посчитать значение функции распределения в точке z-stat, и если мы рассматриваем альтернативу greater, мы с вами рассматриваем другой конец, соответственно, считаем единичку минус значение функции распределения в точке z-stat. Видим, что реализация довольно простая. Итак, давайте сначала выведем доверительный интервал на разность двух долей, вот он перед вами, видим, что он включает ноль, и теперь давайте проверим критерии. Сначала давайте тестировать двустороннюю альтернативу. Соответственно, гипотеза того, что доли одинаковые, против гипотезы, что доли неодинаковые. Итак, вводим p.value, видим, что p.value равняется 0.08. Ну, понимаем, что на уровне значимости 95 мы не можем отвергнуть нулевую гипотезу, ну, по крайней мере, на уровне значимости 0,9 можем. Что, если мы с вами воспользуемся предположением, что новый баннер все-таки лучше, чем старый, ну, он же более красивый, с котиками, и проверим гипотезу против альтернативы less. Да, видим, что в этом случае p.value уже равняется 0,04, а значит, мы можем отвергнуть гипотезу h0 о том, что доли одинаковые, на уровне значимости 95. Теперь давайте рассмотрим следующий случай. Предположим, что люди, которые оценивали 1 и 2 баннер, это одни и те же люди. То есть мы зафиксировали выборку людей и попросили каждого из них посмотреть на оба баннера и нажать на like, если какой-то из них им понравился. Для того чтобы рассчитать z-критерий для разности долей в случае связанных выборок, нам с вами нужно рассчитать таблицу сопряженности. Фиксируем значение единицы и ноль для первого и для второго баннера и дальше рассчитываем количество наблюдений, которые этим значениям соответствуют. Напомню формулу для рассчета доверительного интервала, мы с вами с ней уже знакомы. И z-статистика принимает следующий вид. Давайте это реализуем. Для начала реализуем формулу для оценки доверительного интервала. Тоже это делается довольно просто. Сначала рассчитываем все те слагаемые, которые нам нужны. Дальше аккуратненько выписываем левую и правую границы интервала. И теперь давайте реализуем формулу для подсчета z-статистики. Опять же смотрим на формулу, которая перед нами, понимаем, что нам нужно знать слагаемые f, g и n рассчитываемых, и дальше выписываем выражение для z-статистики. Для того, чтобы рассчитать p.value мы можем воспользоваться функцией, которую мы уже ранее реализовали, разница будет в том, что для оценки p.value мы просто передадим в предыдущую функцию в качестве аргумента другую статистику, ту, которую мы только что реализовали. Итак, выписываем доверительный интервал. Мы видим, что весь доверительный интервал лежит левее нуля. Это дает нам основание предполагать, что новый баннер действительно лучше, чем старый. Ну, теперь давайте это проверим с помощью z-критерия. Итак, сначала будем использовать двустороннюю альтернативу, проверим гипотезу h0, что у нас доли одинаковые для двух баннеров против гипотезы, что доли неодинаковые. Итак, проверяем наш z-test, видим, что p.value получается довольно маленьким, всего 0,003. Получается, что уже на уровне значимости 99 мы можем опровергнуть гипотезу h0, но так как мы с вами изначально предполагаем, что новый баннер лучше, чем старый, давайте также выпишем p.value для односторонней альтернативы less. Итак, видим, что p.value стал еще меньше, значит мы еще уверенней можем отвергнуть нулевую гипотезу. На этом мы с вами заканчиваем. Мы научились считать z-критерий для двух долей в случае связанных и несвязанных выборок, а на следующем занятии вы познакомитесь с непараметрическими критериями для проверки статистических гипотез.
[БЕЗ ЗВУКА] Этот урок посвящен проблеме множественной проверке гипотез. Для того чтобы понять, в чем эта проблема заключается, давайте рассмотрим несколько примеров. Первый из них связан с исследованиями Джозефа Райна. Это американский ученый 50-х годов, который занимался исследованиями возможностей экстрасенсорного восприятия. Для того чтобы исследовать экстрасенсов, нужно сначала где-то их взять. Поэтому первый этап таких исследований — это всегда поиск экстрасенсов. Джозеф Райн придумал следующий эксперимент. Испытуемому предлагалось угадать цвета десяти карт, лежащих рубашкой вверх. Проверялась нулевая гипотеза о том, что испытуемый выбирает свой ответ наугад. Против альтернативы, что он может предсказывать цвета карт. Статистика t — число карт, цвета которых угаданы при справедливости нулевой гипотезы имеет биномиальное распределение с параметрами 10 (это объем выборки) и 1/2, поскольку цвета у нас только два, и они называются наугад. Сумма вероятности исходов от 9 и больше в этом биномиальном нулевом распределении равна 11 * 1/2 в десятой. Это примерно 0,01. То есть, если испытуемый угадывает 9 карт, мы получаем достигаемый уровень значимости 0,01 и можем с чистой совестью отклонять нулевую гипотезу в пользу односторонней альтернативы. В экспериментах Джозефа Райна процедуру отбора прошли 1000 человек. Девять из них угадали цвета 9 из 10 карт, еще двое угадали все 10 карт. Ни один из этих испытуемых в последующих экспериментах не подтвердил своих способностей, из чего Джозеф Райн сделал вывод, что экстрасенсам нельзя говорить о том, что они экстрасенсы, потому что от этого их способности сразу пропадают. Мы с вами понимаем, что проблема в чем-то другом. Давайте примем гипотезу о том, что экстрасенсов не существует. В этом случае вероятность того, что из тысячи человек хотя бы один случайно угадает цвета 9 или 10 из 10 карт равна 1 − (1 − 11 * 1/2 в десятой) и все это в степени 1000. Эта вероятность равна примерно 1. Если мы посмотрим, как эта вероятность ведет себя в зависимости от количества испытуемых, мы увидим, что она растет очень быстро. Уже при 100 испытуемых мы найдем хотя бы одного экстрасенса с вероятностью больше 1/2. При 500 испытуемых вероятность найти хотя бы одного экстрасенса этой процедурой уже равна примерно единице. То, что с помощью этой статистической процедуры мы находим экстрасенсов, является прекрасным примером эффекта множественной проверки гипотез. Если мы проверяем одновременно большое количество гипотез, у нас вероятность совершить хотя бы одну ошибку первого рода, то есть ложно отвергнуть верную нулевую гипотезу, становится очень большой. Еще один яркий пример действия эффекта множественной проверки гипотез можно найти в нейронауке. Представьте, что мы анализируем данные позитронно-эмиссионной томографии или функциональной магнитно-резонансной томографии. Типичный дизайн эксперимента с такими данными следующий: мы берем контрольную группу испытуемых, с которыми ничего не происходит, и измеряем активность их мозга. Потом мы берем группу испытуемых, состояние которых мы каким-то образом поменяли, измеряем также их активность мозга. Дальше сравниваем эти две выборки данных, пытаясь выяснить, на какие области мозга подействовало различие между нашими двумя экспериментальными условиями. Решение такой задачи связано с проверкой очень большого количества гипотез. Фактически для двумерного изображения мозга мы проверяем гипотезу в каждой точке, для трехмерного изображения мозга, которая возникает при магнитно-резонансной томографии, мы проверяем гипотезу в каждом вокселе, то есть в каждом трехмерном пикселе трехмерного изображения мозга. Пикселей могут быть тысячи, вокселей могут быть миллионы. Таким образом, нам нужно проверить очень много гипотез. И если ничего не делать, эффект множественной проверки гипотез будет проявляться очень ярко. Лучше всего это видно на следующем примере. В нем команда исследователей воспроизвела один из типичных дизайнов нейронаучных экспериментов, в котором испытуемому последовательно и много раз демонстрируются похожие стимулы, затем активность его мозга в ответ на эти стимулы сравнивается с активностью его мозга в состоянии покоя. В эксперименте роль испытуемого играл мертвый лосось. В качестве стимула ему показывали картинки с изображениями людей в различных социальных ситуациях. Как мы видим, задача поиска областей, которые реагируют на этот стимул, была решена успешно. В мозге лосося, в том числе и, кажется, в спинном, были выявлены некоторые области, которые на рисунке обозначены красным, в которых активность значимо изменилась. За последнее десятилетие методы анализа данных в нейронауке, в том числе методы поправки на множественную проверку гипотез, существенно улучшились. Вот о таких методах в этом уроке мы и будем говорить. О том, что делать в ситуациях, когда вы проверяете много гипотез и как вам сделать меньше нелепых выводов при этом.

В этом видео мы дадим математическую постановку задачи множественной проверки гипотез. Для этого давайте сначала вспомним, как ставится задача проверки гипотез однократной. У нас есть некоторая выборка X объема n из неизвестного распределения F. И про это распределение F у нас есть некая гипотеза о том, что F ∈ ω. Мы будем эту гипотезу проверять против общей альтернативы, что F ∉ ω. Это делать будем мы с помощью статистики T, которая является просто какой-то функцией от выборки X. Для этой статистики мы знаем нулевое распределение, то есть распределение при справедливости нулевой гипотезы. По этому нулевому распределению, по его хвостам разным в зависимости от типа альтернативы мы вычисляет достигаемый уровень значимости, то есть вероятность получить такое или ещё более экстремальное значение статистики, как мы получили в эксперименте. Достигаемый уровень значимости сравнивается с порогом α — с уровнем значимости — типичное значение 0.05. Если достигаемый уровень значимости меньше, чем α, гипотеза отвергается в пользу альтернативы. При однократной проверке гипотезы у нас всегда есть вероятность, что мы совершим ошибку первого или второго рода. И больше всего нас пугает именно ошибка первого рода. Механизм проверки гипотез построен так, что вероятность ошибки первого рода, то есть вероятность ложно отвергнуть верную нулевую гипотезу, сверху ограничена достигаемым уровнем значимости α. Давайте теперь проверять много гипотез. Пусть у нас есть m выборок. Каждая своего размера из своего распределения, и каждой выборке соответствует своя гипотеза Hi о том, что Fi ∈ ωi. Каждую из гипотез мы будем проверять своей какой-то статистикой Ti. Для каждой из статистик мы знаем свое нулевое распределение. Таким образом, мы можем посчитать достигаемые уровни значимости всех гипотез. Это будут pi с индексами i от 1 до m. Введем следующее обозначение. Пусть M — это множество индексов от 1 до m. M0 — это множество индексов верных нулевых гипотез. Мощность этого множества пусть равна m0. Естественно, это множество нам неизвестно. Если бы мы знали, какие гипотезы верны, а какие не верны, мы бы гипотезы не проверяли. Пусть R — это множество индексов гипотез, которые мы отвергаем. И мощность этого множества пусть равна R. Тогда пересечение множеств R и M0 даёт нам гипотезы, которые мы неверно отвергли. Мощность этого множества мы будем обозначать V, и это есть число ошибок первого рода. По аналогии с однократной проверкой гипотез составим вот такую таблицу 2х2, в которой будет стоят количество верных и неверных, принятых и отвергнутых гипотез. Из всех величин, которые в этой таблице записаны, нам известно только m — общее количество гипотез. А единственный параметр, которым мы здесь можем управлять, — это R — количество гипотез, которые мы отвергаем. При этом величина, которая нас пугает больше всего, — это V — количество ошибок первого рода. Мы хотим совершать мало ошибок первого рода. Нам нужно, чтобы V было маленьким. Но при этом единственное, что мы можем делать, — это перераспределять по этой таблице наши гипотезы из 2-й строки в 1-ю. То есть, если мы хотим совершить мало ошибок первого рода, нам нужно отвергать меньше гипотез. Как именно это делать, мы обсудим в следующих видео.

[БЕЗ_ЗВУКА] Задача множественной проверки гипотез поставлена, давайте ее решать. Нас интересует некоторая статистическая процедура, которая дает нам гарантии на V. V не должно быть слишком большим. Но напрямую с V работать не очень удобно, поэтому, как правило, берут некоторые меры определенные над V и именно с ними работают. Одна из самых распространенных таких мер — это familywise error rate, групповая вероятность ошибки первого рода. По определению это вероятность того, что V > 0, то есть вероятность совершить хотя бы одну ошибку первого рода. Эту величину (familywise error rate) мы хотим контролировать на уровне α. То есть мы хотим построить такую статистическую процедуру, что вероятность совершить хотя бы одну ошибку первого рода будет не больше, чем α. Как этого можно добиться? Единственный инструмент, который у нас есть, — это уровни значимости α1, ..., αm, на которых проверяются наши гипотезы H1, ..., Hm. Никаких других параметров в проверке гипотез нет. Наша задача — выбрать эти уровни так, чтобы обеспечить ограничение familywise error rate уровнем α. И самый простой способ эту задачу решить — это поправка Бонферрони. В методе Бонферрони достигаемые уровни значимости всех гипотез сравниваются с величиной α / m, то есть уровни значимости проверки всех гипотез одинаковы и равны α / m. В качестве альтернативы мы можем просто все достигаемые уровни значимости (p-value) на m умножить, и возьмем еще максимум с 1, чтобы не получить странного. И вот эти модифицированные достигаемые уровни значимости мы будем сравнивать с исходным порогом α. При такой процедуре точно так же мы будем контролировать familywise error rate. То, что метод Бонферрони контролирует familywise error rate на уровне α, показать очень легко. Это настолько легко, что мы это сделаем прямо сейчас. Это будет единственная теорема в этом курсе. Теорема утверждает, что если все гипотезы Hi проверяются на уровне значимости α / m, то familywise error rate ограничена сверху величиной α. Покажем это. Familywise error rate по определению — это вероятность хотя бы одной ошибки первого рода. То есть это вероятность того, что хотя бы для одной из верных нулевых гипотез достигаемый уровень значимости окажется меньше, чем α / m. Оценим вероятность объединения событий сверху через сумму вероятностей этих событий. Это неравенство Буля. Для перехода к третьей строчке воспользуемся свойством достигаемого уровня значимости. Вероятность того, что pi ≤ α / m, ≤ α / m. Таким образом мы получаем, что наша familywise error rate ограничена сверху величиной (m0 / m) * α, поскольку m0 — это часть m, m0 всегда меньше m, поэтому эта величина не больше, чем α. Доказательство получено. Если вы когда-нибудь сталкивались с неравенством Буля, вы знаете, что оценка вероятности объединения событий через сумму вероятностей этих событий очень завышенная. Действительно, чтобы получить там точное равенство, нужно вычесть еще вероятности всех возможных пересечений. Эта цепочка неравенств показывает, что при использовании метода Бонферрони familywise error rate не просто меньше, чем α, а намного меньше, чем α. То есть мы в идеале хотим, чтобы familywise error rate, вероятность совершить одну ошибку первого рода хотя бы, была равна α в точности. При использовании метода Бонферрони мы на самом деле ограничим эту вероятность гораздо более низкой величиной, чем наша α. Это плохо, потому что перестраховываясь в отношении ошибки первого рода, мы неизбежно совершаем больше ошибок второго рода. То есть мощность такой статистической процедуры снижается. Чтобы это увидеть, давайте проведем модельный эксперимент. Возьмем 50 выборок из нормального распределения с дисперсией 1 и средним 1 и еще 150 из нормального распределения стандартного (со средним 0). Все выборки будут объема 20. На каждой из них будем проверять гипотезу о равенстве среднего 0 против двусторонней альтернативы с помощью критерия Стьюдента. Сгенерируем данные, проверим гипотезы. Если мы не будем делать никакой поправки на множественную проверку, мы получим верхнюю таблицу. Видно, что мы отвергли все 50 неверных гипотез, но, к сожалению, вместе с ними отвергли еще и восемь верных, то есть мы совершили восемь ошибок первого рода. Если мы делаем поправку методом Бонферрони, мы перераспределяем гипотезы из второй строчки этой таблицы в первую. Мы в этом случае не отвергаем ни одной верной нулевой гипотезы, то есть не совершаем ни одной ошибки первого рода. Но, к сожалению, вместе с этим мы потеряли возможность отвергнуть больше половины неверных нулевых гипотез: из 50 нам удалось отвергнуть только 23. То есть за гарантии в отношении ошибки первого рода мы заплатили тем, что нашли меньше неверных нулевых гипотез. Итак, в этом видео мы дали определение familywise error rate — групповой вероятности ошибки первого рода. Это вероятность отвергнуть хотя бы одну нулевую гипотезу неверно. Мы рассмотрели метод контроля этой величины (поправку Бонферрони), и выяснили, что его просто применять, что он работает всегда, но обладает низкой мощностью. В следующем видео мы поговорим про метод Холма контроля familywise error rate.

В прошлом видео мы определили familywise error rate (FWER) — вероятность совершения хотя бы одной ошибки первого рода. И разобрали первый способ контроля над ней — метод Бонферрони. Метод Бонферрони все уровни значимости α1, ..., αm для всех гипотез выбирает одинаковыми и равными α / m. Оказывается, что можно сделать лучше, если эти αi-тые брать не одинаковыми, а разными. Для того чтобы это сделать, нам нужна нисходящая процедура множественной проверки гипотез. В общем виде она выглядит так: мы берём достигаемые уровни значимости и составляем из них вариационный ряд, переобозначим все гипотезы так, чтобы их номера соответствовали номерам достигаемых уровней значимости в этом вариационном ряду. Дальше будем действовать следующим образом: возьмём самый маленький достигаемый уровень значимости p(1) и сравним его со своим уровнем значимости α1. Если p(1) > α1 — примем все нулевые гипотезы и остановимся. Если p(1) < α1 — отклоним H(1) и продолжим процедуру. На втором шаге мы будем сравнивать p(2) с α2. Если p(2) > α2 — мы примем все оставшиеся гипотезы. Если нет — отвергнем H(2) и продолжим и так далее. Вот так в общем виде выглядит нисходящая процедура множественной проверки гипотез. Процедура называется нисходящей, несмотря на то, что мы перебираем нулевые гипотезы по возрастанию. Это немного странно и может смущать. Но идея здесь заключается в том, что мы отвергаем нулевые гипотезы последовательно, начиная с наиболее значимых, то есть мы движемся по убыванию значимости. Метод Холма — это нисходящая процедура множественной проверки гипотез с вот такими уровнями значимости. α1 в ней — это α / m. α2 — это α / (m − 1) и так далее. Самая последняя альфа — αm — равна исходному α. Этот метод обеспечивает безусловный контроль над familywise error rate. Это показать немного сложнее, поэтому мы не будем этого делать. Просто поверьте мне на слово. Вместо того чтобы сравнивать исходные достигаемые уровни значимости вот с этими α, мы можем точно так же перейти к модифицированным и сравнивать их с исходным порогом α. Вот так выглядит формула для модифицированных достигаемых уровней значимости метода Холма. Метод Холма всегда мощнее, чем метод Бонферрони. То есть он всегда отвергает не меньше гипотез, чем метод Бонферрони просто потому, что его уровни значимости α не меньше, чем αm из метода Бонферрони. Давайте вернёмся к нашему модельному эксперименту с 200 гипотезами. Здесь на этом графике показаны достигаемые уровни значимости. По горизонтальной оси отложен номер в вариационном ряду, а по вертикальной оси — значения соответствующего достигаемого уровня значимости. Красные точки здесь — это неверные гипотезы. Синие точки — это верные гипотезы. Это типичный вид такого графика. На нём вы видите как будто бы смесь двух треугольников: большого синего, соответствующего верным нулевым гипотезам, и маленького красного, соответствующего неверным. Вот где-то здесь в месте соединения двух треугольников они смешиваются. И наша задача — где-то в этом месте правильно поставить порог, чтобы обеспечить некоторые теоретические гарантии на число ошибок первого рода. Вот так выглядят модифицированные достигаемые уровни значимости, отсортированные по неубыванию, при использовании поправки Бонферрони. Таблицу внизу мы уже видели. Мы отвергаем 23 неверных нулевых гипотезы из 50 и ни одной верной. Вот так выглядят модифицированные достигаемые уровни значимости метода Холма. Метод Холма позволяет нам отвергнуть 26 из 50 гипотез и всё ещё не совершить ни одной ошибки первого рода при этом. На самом деле, разница между этими двумя методами, с одной стороны, не такая уж и большая. Метод Холма не позволил нам совершить какого-то чуда и отвергнуть внезапно все неверные нулевые гипотезы. С другой стороны, метод Холма, не делая никаких дополнительных предположений, дал нам ещё три научных открытия. Ещё три гипотезы нам удалось отвергнуть абсолютно бесплатно. Разве это не повод его использовать? Итак, в этом видео мы изучили метод Холма. Это метод, контролирующий familywise error rate. Этот метод немного сложнее, но всегда лучше поправки Бонферрони и точно так же всегда работает без всяких дополнительных предположений. В следующем видео мы поговорим про ещё одну меру числа ошибок первого рода, которая называется False Discovery Rate (FDR).

В этом видео мы обсудим еще одну используемую при множественной проверке гипотез меру числа ошибок первого рода, а также способ ее контролировать. Напомню, что при множественной проверке гипотез мы имеем дело вот с такой таблицей два на два, в которой больше всего нас волнует величина V (число ошибок первого рода). Если мы работаем с групповой вероятностью ошибки — familywise error rate, мы ограничиваем вероятность того, что мы совершаем хотя бы одну ошибку первого рода. В некоторых ситуациях, например, когда проверяются десятки тысяч или миллионы гипотез, мы готовы допустить какое-то количество ошибок первого рода просто ради того, чтобы увеличить мощность процедуры и отвергнуть больше неверных гипотез, совершить меньше ошибок второго рода. В таких ситуациях выгоднее оказывается использовать другую меру: не familywise error rate, а false discovery rate — ожидаемую долю ложных отклонений, просто математическое ожидание отношения V (количества ошибок первого рода) к R (количеству отклоняемых гипотез). Для любой фиксированной процедуры множественной проверки гипотез false discovery rate всегда не больше, чем familywise error rate. За счет этого, если мы контролируем false discovery rate, а не familywise error rate, мы получаем более мощную процедуру, поскольку она позволяет отвергать больше гипотез. Методы, которые контролируют false discovery rate, как правило, восходящие. В каком-то смысле это противоположность нисходящих методов типа метода Холма, который мы рассматривали до этого. Восходящие методы работают с тем же самым вариационным рядом достигаемых уровней значимости, что и нисходящие, но идут по этому ряду с другого конца. На первом шаге мы берем самый большой p-value — pm и сравниваем его со своей константой αm. Если pm ≤ αm, то все нулевые гипотезы от 1-й до m-й отвергаются, и процедура останавливается. Иначе мы принимаем самую последнюю гипотезу Hm и продолжаем. На следующем шаге мы сравниваем p(m − 1 ) и αm − 1. Если p < α, то все нулевые гипотезы с 1-й до (m-1)-й отвергаются и мы останавливаемся, иначе мы принимаем Hm − 1, и процедура продолжается. И так далее. Если для одних и тех же α1, ..., αm мы построим восходящую и нисходящую процедуру, мы увидим, что восходящая процедура всегда будет отвергать не меньше гипотез, чем нисходящая. Вот на нашем модельном примере с девятью гипотезами точечками обозначены достигаемые уровни значимости, а прямой — порог, с которыми мы их сравниваем, α фактически. Если мы используем процедуру восходящую, мы движемся от самого большого p-value в сторону самого маленького и принимаем девятую, восьмую и седьмую гипотезы, и таким образом отвергаем первые шесть. Если мы используем процедуру нисходящую, мы, наоборот, начинаем с самого маленького p-value и отвергаем первые две гипотезы, принимаем оставшиеся семь. Таким образом, в нашем примере восходящая процедура отвергла в три раза больше гипотез. Это может просходить из-за того, что линия, соединяющая отсортированные достигаемые уровни значимости, может пересекать линию, задающую критические значения α, несколько раз. Для контроля над false discovery rate чаще всего используется метод Бенджамини-Хохберга. Это восходящая процедура с уровнями значимости α1 = α / m, αm = α. Крайние уровни значимости точно также же, как и в методе Холма, а вот то, что происходит между краями, совершенно другое. Уровни значимости между α1 и αm в методе Бенджамини-Хохберга меняются линейно, в то время как в методе Холма — по гиперболе. Вот так выглядят модифицированные достигаемые уровни значимости для метода Бенджамини-Хохберга. Поскольку процедура восходящая, для того чтобы убедиться, что каждый следующий p-value в нашей процедуре не стал больше, чем предыдущий, мы берем минимум от (pi * m) / i и p(i + 1) модифицированного. Метод Бенджамини-Хохберга обеспечивает контроль над false discovery rate на уровне α, но не всегда, а только при условии, что проверяющие гипотезы статистики независимы. Это требование достаточно сильное. Иногда его можно ослабить, и в некоторых задачах выполняется это ослабленное требование, но тем не менее, важно подчеркнуть, что процедура Бенджамини-Хохберга не является универсальной, она не применима безусловно, в отличие от того же метода Холма. Давайте вернемся к нашему модельному эксперименту из предыдущих видео. Вот отсортированные достигаемые уровни значимости, которые мы получили на наших модельных данных, а вот модифицированные достигаемые уровни значимости, полученные методом Холма. Вот так выглядят модифицированные достигаемые уровни значимости метода Бенджамини-Хохберга. Они отличаются довольно сильно. Методом Холма мы отвергаем 26 неверных гипотез, не совершая при этом ни одной ошибки первого рода. Методом Бенджамини-Хохберга мы отвергаем 46 неверных гипотез, совершая при этом две ошибки первого рода. Две из 48 — это примерно 0,04. Это меньше, чем 0,05. В модельном эксперименте, напомню, выборки мы генерировали независимо, поэтому метод Бенджамини-Хохберга действительно применим. Итак, в этом видео мы узнали, что контролируя false discovery rate вместо familywise error rate, мы позволяем больше ошибок первого рода, но за счет этого можем критически увеличить количество неверных нулевых гипотез, которые мы отвергаем. Метод Бенджамини-Хохберга используется повсеместно, несмотря на то, что он работает далеко не всегда. Очень часто его применяют без проверки необходимого условия его корректности. Так делать не стоит. В следующем видео мы поговорим про анализ подгрупп.

В этом видео мы продолжим анализировать взаимосвязи в данных и теперь поговорим про множественную проверку гипотез. Анализировать мы будем тот же набор данных, что и на прошлом занятии — foodmart product sales. Это данные о том, сколько продуктов было продано в каждом магазине за известные нам даты. Давайте традиционно начнем с загрузки набора данных. Напомню, как это выглядит. Видим таблицу, состоящую из четырех столбцов: ID продукта, ID магазина, дата и количество продаж этого продукта. Нам также понадобится дополнительная информация о продуктах, в частности нас будет интересовать название каждого продукта, чтобы мы понимали, о каких данных идет речь. И давайте теперь объединим эти две таблицы, чтобы добавить в первую таблицу информацию о названии. Делаем это с помощью метода merge. Посмотрим, что получилось. Видим, что у нас добавилась еще одна колонка с названием. Теперь давайте перейдем непосредственно к анализу данных. Так же, как и в прошлый раз, нам придется видоизменить таблицу, чтобы было удобнее с ней работать. В данном случае нам захочется представить таблицу в таком виде, чтобы каждому продукту соответствовал отдельный столбец. Соответственно, значения будут соответствовать количеству продаж данного продукта в некотором магазине за известную дату. Давайте такую таблицу получим. Снова используем метод pivot_table и посмотрим, как она выглядит. Видим, что появилось очень много столбцов, соответствующих каждому продукту, и в качестве значений мы видим количество продаж. Теперь давайте рассчитаем корреляцию. Какую задачу мы с вами ставим? Мы хотим проверить, есть ли корреляция между покупками пары продуктов. При этом мы хотим не только посчитать значение корреляции, а также проверить гипотезу о том, что корреляция присутствует. Для расчета корреляции мы можем воспользоваться методом corr класса DataFrame, однако в данном случае нам интересно не только само значение корреляции, но и также p-value, потому что мы с вами хотим проверить гипотезу о том, что корреляция присутствует, против альтернативы о том, что ее нет. Для того чтобы это получить, нам понадобится функция pearsonr, это функция модуля stats библиотеки SciPy, поэтому мы с вами сделаем следующее: мы пройдемся циклом по парам продуктов и для каждой пары рассчитаем корреляцию и значение p-value, и дальше соберем всё это в удобный DataFrame. В DataFrame мы хотим видеть четыре столбца. Первые два столбца должны соответствовать названиям продуктов, в третий мы запишем корреляцию, и в четвертый — значение p-value. Вот давайте это сделаем. Эта процедура занимает существенное время, потому что у нас довольно много продуктов — порядка 1500. Соответственно, для всех пар мы с вами хотим получить корреляцию. Давайте подождем. Итак, расчет завершен. Мы видим, что на это потребовалось порядка двух минут, и теперь давайте посмотрим на DataFrame, который мы получили. Мы видим его начало, видим, что действительно в нем четыре столбца, первые два соответствуют названиям продуктов, в третьем мы видим значение корреляции, и в четвертом — p-value. Теперь давайте посчитаем, сколько же гипотез об отсутствии корреляции отвергает без правки на множественную проверку гипотез. Сделаем это с помощью метода value_counts(), посмотрим, сколько мы видим p-value больше и меньше, чем 0,05. Мы видим, что отвергается довольно много гипотез, порядка 200000. Теперь давайте сделаем правку на множественную проверку гипотез и посмотрим, насколько ситуация изменится. Первая поправка на множественную проверку гипотез, которой мы будем пользоваться, называется метод Холма. В рамках этой поправки мы ограничиваем вероятность того, что хотя бы на одном объекте будет ошибка, 5 %. Вот давайте эту правку применим, это делается довольно просто, соответствующий метод реализован в библиотеке StatsModels, он называется multipletests, и для того чтобы передать внутрь набор наших p-value, мы их уже получили, также нужно передать уровень значимости, с которым мы работаем. Ну вот если мы хотим ограничить вероятность ошибки 5 %, тогда нам нужно передать уровень значимости 0,05. И также нужно указать метод, с помощью которого будет делаться правка. Мы используем метод Холма. Итак, давайте это рассчитаем. Данный метод возвращает нам результат, должны ли мы отвернуть гипотезу или нет, то есть этот результат типа true/false, и также скорректированное значение p-value. Давайте полученное значение добавим к нашему DataFrame в виде пятого и шестого столбца, это довольно просто делается, и посмотрим, как это выглядит. Ну вот, видим, что после оригинального значения функции p-value, которое мы рассчитали с помощью pearsonr, мы получили скорректированное значение p-value с учетом поправки на множественную проверку гипотез, а также результат, должны ли мы отвергнуть или принять гипотезу о том, что корреляции нет. Теперь давайте посчитаем, сколько гипотез об отсутствии корреляции отвергаются с учетом правки на множественную проверку гипотез методом Холма. Делаем это с помощью метода value_counts(), но уже делаем это по столбцу reject. Видим, что результат очень сильно отличается. В данном случае мы с вами отвергаем всего 1700 гипотез, то есть намного меньше. Давайте посмотрим, как это выглядит. Возьмем только те гипотезы, которые мы отвергаем, это делается с помощью ограничения reject == True, а также давайте их отсортируем по корреляции, сортировать будем в порядке убывания. Видим, что на самом деле значение p-value скорректированное от оригинального отличается на несколько порядков, то есть довольно большая разница. Теперь давайте сделаем поправку на множественную проверку гипотез другим методом, например, давайте воспользуемся методом Бенджамини-Хохберга. Если в случае метода Холма мы с вами ограничивали вероятность сделать хотя бы одну ошибку, то в данном случае мы будем пытаться ограничить среднюю вероятность ошибок. Вот давайте ограничим среднюю вероятность ошибок 5 %, для этого нам снова придется использоваться коэффициент α = 0,05, и построим скорректированное значение p-value, а также снова рассчитаем, сколько же гипотез мы отвергнем с учетом данной правки. Для того чтобы это посчитать, нам снова придется воспользоваться той же самой функцией (функция multipletests из библиотеки StatsModels), однако в этом случае нам нужно передать ей другой метод (название перед вами). Давайте это рассчитаем и заменим столбцы p_corrected и rejected, которые мы с вами рассчитали предыдущим методом, на новые значения. Итак, заменяем и смотрим, как изменился DataFrame, как изменилась таблица. Структура осталась та же самая, единственное что скорректированные значения p-value и reject у нас теперь рассчитаны другим методом. Вот давайте посчитаем, сколько же гипотез мы отклоним в этом случае. Так, смотрим, что в этом случае мы отклоним на порядок больше — 76000 гипотез, ну потому что вместо того, чтобы ограничивать вероятность хотя бы одной ошибки, мы ограничивали среднюю вероятность ошибок. Вот давайте посмотрим, как меняются p-value. Для тех случаев, когда мы с вами отклоняем гипотезу, видим, что p-value всё еще меняется на несколько порядков. Итак, мы с вами договорили про поправку на множественную проверку гипотез, а также научились ее рассчитывать с помощью функции multipletests из библиотеки StatsModels. Мы потренировались рассчитывать поправку методом Холма, а также методом Бенджамини-Хохберга.

В этом видео мы поговорим еще об одном ярком проявлении эффекта множественной проверки гипотез, которое возникает при анализе подгрупп. Давайте для примера рассмотрим следующее исследование. У нас есть 1073 пациента с ишемической болезнью сердца. Мы делим их на 2 подгруппы по типу лечения и исследуется взаимосвязь между выживаемостью и типом лечения. Мы хотим понять, какой их двух типов лучше. Важные факторы, которые влияют на выживаемость при ишемической болезни сердца — это число пораженных артерий, может быть 1, 2 или 3, и тип сокращений левого желудочка (нормальный и абнормальный). В таких ситуациях исследователи часто хотят посмотреть на сравнительную эффективность типов лечения отдельно во всех подгруппах по уровням важных факторов. В данном случае наши два фактора порождают 6 подгрупп, в каждой из них мы сравниваем выживаемость пациентов по двум типам лечения. Действительно, в одной из 6 подгрупп были обнаружены значимые различия в выживаемости пациентов при лечении первого типа и второго типа. Перед вами кривые выживаемости для этой подгруппы. По ним видно, что в группе лечения A к концу исследования после 6 лет наблюдений выжило только меньше 40 % пациентов, а в группе соответствующей лечению B, в районе 60 % — это различие статистически значимо. Кажется, что для пациентов с таким числом пораженных артерий и с таким типом сокращения левого желудочка лечение B действительно существенно эффективнее. На самом деле эти два лечения отличаются только названием. По сути, эти две группы пациентов лечились абсолютно одинаково. Эта статья была написана с целью показать необходимость поправки на множественную проверку гипотез при анализе подгрупп. Действительно, когда мы рассматриваем и сравниваем кривые выживаемости во всех 6 подгруппах, мы проверяем 6 абсолютно независимых гипотез и возникает эффект множественной проверки. Если подгрупп достаточно много, мы всегда получим какие-то значимые отклонения. Более свежий пример настоящего исследования, в котором такая ошибка в анализе подгрупп была совершена на самом деле — это исследование 2008 года, в котором исследовалась связь потребления кофеина и риска возникновения рака груди. В этой статье всего было около 50 разных подгрупп, по самым разным уровням самых разных факторов. Было, в частности, показано, что употребление более чем четырех чашек кофе в день связано с увеличением риска злокачественного рака груди, с достигаемым уровнем значимости 0,08. Это больше, чем стандартный уровень значимости 0,05, но меньше чем либеральный уровень значимости 0,1. Кроме того, потребление кофеина связано с увеличением риска возникновения эстроген- и прогестерон- независимых опухолей, а так же опухолей размером больше 2 сантиметров. Достигаемый уровень значимости 0,02. Еще одно открытие — потребление кофе без кофеина связано со снижением риска возникновения рака груди у женщин в постменопаузе, принимающих гормоны. Достигаемый уровень значимости 0,02. Ясно, что за счет большого количества подгрупп, которые мы рассматриваем, всегда можно получить какие-то значимые отклонения, если не делать поправку на множественную проверку, какие-то из них с большой вероятностью окажутся ложными. В каком-то смысле это напоминает переобучение. Мы пытаемся оценить эффективность лечения в разных подгруппах в зависимости от каких-то признаков пациента и если эти признаки слишком сложные и их слишком большое количество, то мы просто переобучаемся под выборку, которую мы анализируем. В качестве экстремального примера такого переобучения можно вспомнить цитату из Галена, II века до нашей эры: «Все больные, принявшие это средство, вскоре выздоровели, за исключением тех, кому оно не помогло — они умерли. Отсюда очевидно, что средство помогает во всех случаях, кроме безнадежных». В заключение обсуждения эффекта множественной проверки гипотез давайте обсудим еще один вот такой гипотетический пример. Представьте, что у вас есть 100 больных людей и 100 здоровых, и вы хотите исследовать связь между болезнью и какой-то мутацией. В вашей контрольной выборки из 100 человек у одного есть мутация, а в выборке больных — у 8 есть мутация. По всей видимости, эта мутация достаточно редкая. Если мы сравним доли людей с мутацией в выборках больных и здоровых, мы получим достигаемый уровень значимости 0,03, и гипотеза об отсутствии связи между мутацией и болезнью отвергается. Пусть теперь у нас есть еще одна гипотеза — наличие заболевания связано с тем, с гласной или согласной буквы у пациентов начинаются фамилии. В нашей контрольной выборке здоровых людей у 36 человек фамилия начинается с гласной буквы, а в выборке больных — у 40 из 100. Если мы сравним эти доли биномиальным критерием, мы получим достигаемый уровень значимости 0,66. Эта гипотеза ни в каком случае отклонена не будет. Проблема, однако, заключается в том, что теперь в нашем исследовании проверяются две гипотезы. И нам нужно делать поправку на множественность этой проверки. Какой метод поправки мы бы не использовали, будь то метод Бонферрони, Холма или Бенджамини Хохберга, самый маленький достигаемый уровень значимости во всех них сравнивается с α / m. Таким образом, если мы хотим обеспечить контроль над какой-то мерой числа ошибок первого рода на уровне 0,05, нам нужно сравнивать наше самое маленькое α с 0,025. Самое маленькое α у нас 0,03. Таким образом, вот эта нелепая гипотеза, которую мы в наше исследование добавили, замаскировала, возможно, неверную нулевую гипотезу, связанную с мутацией. Отсюда вытекает рецепт лучшего способа борьбы с эффектом множественной проверки гипотез — просто проверять меньше гипотез. Перед тем, как вы собрали данные до того, как ваше исследование началось, подумайте, какие из гипотез, которые вы можете рассмотреть, вам на самом деле не интересны. И откажитесь от их рассмотрения. За счет этого вы сможете сделать более либеральную поправку на множественность и отвергнуть больше действительно неверных гипотез, совершить больше действительно интересных открытий. Здесь важно, что такая фильтрация гипотез должна осуществляться именно до сбора данных. Если вы будете выбрасывать гипотезы уже после того, как вы посмотрели на достигаемый уровень значимости, вы переобучитесь. Итак, в этом видео мы обсудили эффект множественной проверки гипотез, возникающий при анализе подгрупп, а так же обсудили, что лучший способ борьбы с эффектом множественной проверки — это просто проверять меньше гипотез. На этом заканчивается теоретический материал про множественную проверку гипотез.
Этот урок посвящен проверке гипотез. Это важнейший статистический инструмент, которым вы должны владеть в совершенстве, если вы занимаетесь анализом данных. Чтобы вы всё хорошо поняли, мы подробно разберем все компоненты, из которых этот инструмент состоит, а пока давайте начнем с примера. Представьте, что вы познакомились с человеком, который утверждает, что он может предсказывать будущее. Не так важно, как он это делает: может быть, он использует гадание на кофейной гуще, может быть, обучение с учителем с хорошо измеренными признаками и делает свои предсказания на основании исторической информации. Как можно проверить его утверждение о том, что он действительно может предсказывать? Нужно провести эксперимент. Вы записываете предсказания, генерируете соответствующие им события или ждете, пока они произойдут или не произойдут, а затем проверяете правильность предсказаний. Эксперимент, таким образом, порождает выборку, которая может состоять, например, из 0 и 1, если 1 — это в случае, когда предсказание сбылось, а 0 — когда предсказание не сбылось, или это может быть выборка из точностей предсказания, то есть разностей между фактом и прогнозным значением. Предсказатель полезен, если он предсказывает лучше, чем генератор случайных чисел. Давайте рассмотрим гипотезу, что предсказатель — это и есть генератор случайных чисел. Посмотрим на данные и подумаем, что они говорят, свидетельствуют ли они против такого предположения. Вот именно так примерно и используется проверка гипотез. Давайте теперь формально введем все необходимые компоненты механизма проверки гипотез. Итак, у вас есть некоторая выборка Xn из случайной величины X, которая имеет неизвестное вам распределение P. Кроме того, у вас есть какая-то нулевая гипотеза об этом распределении, например, что P ∈ ω. Кроме того, у вас есть альтернативная гипотеза: например, что P ∉ ω. Мы хотим проверить, какая из двух гипотез, нулевая или альтернативная, более вероятна, глядя на данные, которые мы собрали. Для этого мы используем некоторую статистику T, которая обладает очень важным свойством: если нулевая гипотеза справедлива, мы точно знаем, какое у статистики распределение, это распределение обозначим за F(x). Кроме того, если нулевая гипотеза не справедлива, а справедлива альтернативная гипотеза, то статистика имеет распределение не F(x), а какое-то другое. Распределение F(x) называется нулевым распределением статистики, а пара статистика и нулевое распределение образует статистический критерий для проверки нулевой гипотезы против альтернативы. Вы собрали выборку, посчитали на этой выборке значение статистики t — обозначим его за t. Давайте теперь подумаем, с какой вероятностью при справедливости нулевой гипотезы вы могли получить именно такое значение статистики. Вообще говоря, если распределение нулевое нашей статистики непрерывно, то каждому конкретному значению соответствует вероятность, в точности равная 0, поэтому этот вопрос не совсем корректен. Чтобы его немного переформулировать, давайте подумаем, какие значения статистики соответствуют альтернативной гипотезе? Допустим, например, что при справедливости альтернативы более вероятны большие значения статистики. Давайте теперь зададимся вопросом, с какой вероятностью при справедливости H0 вы могли получить значение статистики, равное t или больше? Вот эта вероятность — это ключевой компонент механизма проверки гипотез, который называется достигаемый уровень значимости, или p-value. Достигаемый уровень значимости — это вероятность получить значение статистики такое, как получилось в вашем эксперименте или еще более экстремальное при справедливости нулевой гипотезы. Еще более экстремальное определяется относительно альтернативной гипотезы, то есть с учетом того, какие значения статистики более вероятны при альтернативе. Зная нулевое распределение статистики, зная значение статистики, которое реализовалось в эксперименте, можно посчитать p-value. В случае, когда критическими, то есть соответствующими альтернативе, являются большие значения статистики, p-value — это интеграл от плотности нулевого распределения по правому хвосту начиная с t и до ∞. Если значение p-value, которое у вас получилось, мало, это значит, что данные свидетельствуют против нулевой гипотезы в пользу альтернативы, поскольку вероятность получить такие данные при условии, что нулевая гипотеза справедлива, мала. Будем сравнивать p-value с порогом α, который называется уровнем значимости. Чаще всего в качестве уровня значимости берут 0,05. Если p ≤ α, то нулевая гипотеза отвергается в пользу альтернативы. Если p > α, то нулевая гипотеза не отвергается. Вот и всё, механизм проверки гипотез достроен. В этом видео мы разобрались, из каких компонент он состоит. Чтобы проверять гипотезы, вам нужны пара гипотеза и альтернатива, вам нужна какая-то статистика, для которой вы знаете нулевое распределение, то есть распределение при справедливости нулевой гипотезы. Пара статистика и нулевое распределение вместе называются статистическим критерием. Используя этот аппарат, вы считаете достигаемый уровень значимости, или p-value, и сравнивая p-value с порогом α, вы принимаете решение о том, принимается нулевая гипотеза или отвергается. На протяжении следующих видео мы будем подробно разбирать эти компоненты. В следующем мы поговорим про ошибку первого и второго рода.

В этом видео мы поговорим про существенную особенность механизма проверки гипотез — это его несимметричность относительно пары нулевая гипотеза – альтернатива. Эта особенность тесно связана с понятиями ошибок первого и второго рода. Нулевая гипотеза может быть либо верна, либо неверна. В результате проверки гипотез вы можете ее либо принять, либо отвергнуть. Таким образом, возникает вот такая таблица два на два. На диагонали здесь все хорошо, вы принимаете верные решения: либо принимаете верную нулевую гипотезу, либо отвергаете неверную нулевую гипотезу. А вот на побочной диагонали вы совершаете ошибку. Если вы отвергаете верную нулевую гипотезу, говорят, что вы совершаете ошибку первого рода. Если вы принимаете неверную нулевую гипотезу, вы совершаете ошибку второго рода. Так вот, в механизме проверки гипотез ошибки первого и второго рода неравнозначны. Ошибка первого рода критичнее. Вероятность ошибки первого рода, то есть отвержение нулевой гипотезы в случае, когда она верна, жестко ограничивается. Если вы отвергаете нулевую гипотезу при достигаемом уровне значимости меньше чем α, то вероятность ошибки первого рода, как нетрудно показать, получается ограниченной сверху вот этой самой величиной α. Таким образом, любой хорошо построенный корректный критерий имеет вероятность ошибки первого рода не больше чем α. Что касается ошибки второго рода, то она минимизируется по остаточному принципу. И вот понятие ошибки второго рода связано с понятием мощности статистического критерия. Мощность — это вероятность отвергнуть неверную нулевую гипотезу, то есть единица минус вероятность ошибки второго рода. Среди всех критериев, которые корректны, мы выбираем критерий с максимальной мощностью, и вот это и есть идеальный критерий для проверки нашей пары нулевая гипотеза – альтернатива. Неравнозначность нулевой гипотезы и альтернативной гипотезы видна уже на терминологическом уровне. Если достигаемый уровень значимости у вас маленький, меньше чем α, то говорят, что нулевая гипотеза отвергается в пользу альтернативы. Если достигаемый уровень значимости больше чем α, то нулевая гипотеза не отвергается. При этом она может быть и верна. Когда нулевая гипотеза не отвергается, у вас просто нет доказательств тому, что она неверна. Но отсутствие доказательств не является доказательством ее верности. Лучше это понять можно на примере с судебным процессом. Презумпция невиновности утверждает, что подсудимый по умолчанию невиновен, это нулевая гипотеза, и если доказательств обратному нет, то мы не можем утверждать, что он преступник, даже если на самом деле он совершил преступление. Итак, в этом видео мы разобрались, в чем существенное отличие между нулевой гипотезой и альтернативой и как это связано с понятиями ошибок первого и второго рода. В следующем видео мы поговорим еще про достигаемый уровень значимости.

[БЕЗ ЗВУКА] В этом видео мы поговорим про достигаемый уровень значимости. Это достаточно сложная теоретическая концепция, которую даже многие люди, которые регулярно пользуются статистикой и проверкой гипотез, понимают неправильно. Например, авторы статистического блога «5/38» как-то раз на одной из прикладных конференций устроили опрос учёных, которые туда приехали, и спрашивали у них, как они понимают достигаемый уровень значимости, и собрали очень много неправильных и странных ответов. Достигаемый уровень значимости — это вероятность получить значение статистики такое, какое у вас получилась в эксперименте или ещё более экстремальное при справедливости нулевой гипотезы. Чем ниже достигаемый уровень значимости, тем сильнее данные свидетельствуют против нулевой гипотезы в пользу альтернативы. Проблема определения p-value в том, что оно длинное, но из него ничего нельзя выбросить так, чтобы оно не стало неправильным. Например, часто хочется думать, что p-value — это вероятность справедливости нулевой гипотезы, или условная вероятность справедливости нулевой гипотезы, при условии, что данные вот такие, как мы получили. Это в корне неверно. Это понятно из следующего примера: в 2010 году осьминог Поль угадывал результаты матча чемпионата мира по футболу с участием сборной Германии. Угадывал он, выбирая из двух кормушек кормушку с флагом страны победителя. Из 13-ти матчей, в которых он пробовал свои силы, результаты 11-ти ему удалось угадать. Используя эти данные как выборку, можно проверять нулевую гипотезу о том, что он выбирал кормушку наугад. Критерий, которым эта нулевая гипотеза проверяется против альтернативы, что у него, действительно, есть какие-то сверхспособности, и он предсказывает результаты матчей, мы разберем очень скоро. А пока просто поверьте мне, что, если его применить, вы получите достигаемый уровень значимости, равный примерно 0.01. Вот это 0.01 — это не вероятность, что осьминог выбирает кормушку наугад. Вероятность того, что осьминог выбирает кормушку наугад, равна единице. Мы это знаем точно, потому что осьминог выбирает кормушку наугад. Эта вероятность — это именно вероятность получить такие или ещё более экстремальные данные при условии справедливости нулевой гипотезы. Эта вероятность достаточно мала, но редкие события тоже происходят. И, как правило, именно о них пишут в газетах. Теперь вы знаете, как не сделать ошибки в интерпретации достигаемого уровня значимости. Самый надежный способ не ошибиться — это использовать ровно то определение, которое записано в учебниках, и то, которое мы с вами разобрали. В следующем видео мы поговорим про различия между статистической и практической значимостью.

[БЕЗ ЗВУКА] В этом видео мы поговорим про различия между статистической и практической значимостью. На самом деле, когда вы проводите эксперимент, p-value само по себе никакого интереса не представляет. То, что вас интересует — это размер эффекта, то есть степень отклонения данных от нулевой гипотезы. Например, если ваш эксперимент связан с проверкой способностей предсказателя будущего, то размер эффекта — это вероятность верного предсказания среди предсказаний, которые он делает. Если вы проверяете эффективность какого-то лекарства, то размер эффекта — это вероятность выздоровления пациента, который это лекарство принимает, минус вероятность выздоровления пациента, который принимает плацебо. Если вы запускаете программу лояльности для пользователей интернет-магазина, то ваш размер эффекта — это увеличение среднего чека, которое происходит при запуске этой программы. Размер эффекта — это величина, определенная на генеральной совокупности. Но всей генеральной совокупности у вас нет. У вас есть только небольшая выборка из нее. И оценка размера эффекта по выборке — это случайная величина. Достигаемый уровень значимости нужен для того, чтобы убедиться, что такую оценку размера эффекта, как мы получаем по выборке, нельзя было получить случайно или можно было получить случайно только с маленькой вероятностью. Достигаемый уровень значимости (p) зависит не только от размера эффекта, но и от объема выборки, по которой вы этот эффект оцениваете. Если у вас выборка небольшая, скорее всего, нулевую гипотезу, если только она не слишком дикая, вы на ней не отвергаете. Но с ростом объема выборки вы начинаете постепенно замечать все более тонкие отклонения данных от нулевой гипотезы, и на выборке, которая достаточно велика, с большой вероятностью большую часть разумных нулевых гипотез вы отвергните. Именно поэтому, даже если вы отвергли нулевую гипотезу, это еще не значит, что эффект, который вы намерили, имеет какую-то практическую значимость. Ее нужно оценивать совершенно отдельно. Давайте рассмотрим несколько примеров. Первый пример связан с большим исследованием, в котором на протяжении трех лет у большой выборки женщин измеряли вес, а также оценивали, насколько активно они занимаются спортом. По итогам исследования выяснялось, что женщины, которые в течение этих трех лет упражнялись не меньше часа в день, набрали значимо меньше веса, чем женщины, которые упражнялись меньше 20 минут в день. Причем значимость этого результата статистическая была достаточно высокая, то есть p-value получился меньше, чем 0,001. Проблема здесь в размере эффекта. Дело в том, что разница в набранном весе между двумя исследуемыми группами женщин составила всего 150 граммов. 150 граммов за 3 года — это не очень много. Крайне сомнительно, что этот эффект имеет какую-то практическую значимость. Еще один пример связан с клиническими испытаниями гормонального препарата «Премарин», который облегчает симптомы менопаузы. В 2002 году эти испытания были прерваны досрочно, поскольку было обнаружено, что прием препарата ведет к значимому увеличению риска развития рака груди (на 0,08 %), риска инсульта (на 0,08 %) и риска инфаркта (на 0,07 %). Этот эффект статистически значим. Но значим ли он практически? На первый взгляд кажется, что эти размеры эффектов ничтожны. Например, если вам скажут, что ваши любимые конфеты повышают риск возникновения инфаркта на 0,07 %, вряд ли это вас побудит от конфет отказаться. Тем не менее, если мы пересчитываем эти размеры эффектов на всю популяцию людей, к которым наш препарат может быть потенциально предписан, мы получаем тысячи дополнительных смертей. Мы не можем взять на себя эту ответственность. Поэтому такой препарат мы разрешить не можем. Мы должны немедленно его запретить и снять с рынка. Этот пример показывает, что практическая значимость — это не что-то, что можно определить на глаз. Она всегда должна считаться относительно к каждой конкретной задаче. В идеале практическая значимость должна определяться человеком, который задачу поставил, то есть человеком, который понимает в предметной области. Еще один пример — это испытание лекарства, которое замедляет ослабление интеллекта у больных Альцгеймером. Это исследование, в котором размер эффекта померить очень сложно, то есть нужно подождать много лет, на протяжении которых ваши испытуемые будут принимать либо лекарства, либо плацебо, а затем сравнить эти две группы. Ясно, что такое исследование делать долго и дорого. Если при испытании оказывается, что разница между снижением IQ в вашей контрольной группе, где люди принимали плацебо, и тестовой группе, где люди принимали препарат, составляет 13 пунктов, это различие очень большое. Практически этот эффект крайне значим. При этом вполне могло оказаться, что статистическая значимость у вас не получилась, то есть p-value у вас получилось достаточно большое — больше, чем α — и нулевую гипотезу об отсутствии эффекта лекарства вы формально не отвергли. Если вы оказываетесь в таких ситуациях, и вопрос, с которым связан ваш эксперимент, какой-то очень важный, возможно, вам стоит продолжать исследования: набрать еще выборку, уменьшить дисперсию оценки размера эффекта и убедиться в том, что вы не пропускаете какое-то очень важное открытие. Итак, в этом видео мы поговорили про статистическую и практическую значимость. Понятие практической значимости связано с размером эффекта, а понятие статистической значимости — с достигаемым уровнем значимости. Достигаемый уровень значимости показывает в каком-то смысле, с какой вероятностью такую оценку размера эффекта, как мы получили, можно было бы получить случайно. Понятие практической и статистической значимости комплементарны. Поэтому всегда, когда вы анализируете данные, нужно оценивать и то и другое. На этом мы наконец заканчиваем рассмотрение теоретических аспектов аппарата проверки гипотез. Начиная со следующего видео, мы разберем несколько примеров конкретных статистических критериев.

В этом видео мы потренируемся строить биномиальный критерий для доли. Ранее мы уже научились строить доверительные интервалы для доли с помощью нормального распределения, а также методом Уилсона. В этом видео потренируемся строить критерий. Давайте рассмотрим следующую задачу. Наверняка многие помнят, что Джеймс Бонд утверждает, что он предпочитает пить мартини взболтанным, но не смешанным. Как бы мы могли проверить это на практике? Можно было бы предложить Джеймсу Бонду пройти так называемый blind test, или слепое тестирование. Можно было бы завязать ему глаза, несколько раз предложить на выбор взболтанный и смешанный мартини, а после этого спросить, какой напиток он предпочитает. В данном случае если бы Джеймс Бонд выбирал взболтанный напиток, мы бы говорили, что это успех, потому что его выбор соответствует его утверждению. В противном случае мы бы говорили, что произошла неудача, так как выбор утверждению не соответствует. Как в данном случае выглядела бы проверка гипотез? Мы бы проверяли нулевую гипотезу о том, что Джеймс Бонд не различает два вида напитков и выбирает наугад, против некоторой альтернативы. Но альтернатива, вообще говоря, могла бы быть разной. С одной стороны, мы могли бы рассматривать двустороннюю альтернативу — Джеймс Бонд отличает два вида напитков, и у него есть некоторые предпочтения, — или одну из односторонних — Джеймс Бонд предпочитает взболтанный мартини, так, как он утверждает, или Джеймс Бонд предпочитает смешанный. Такой эксперимент мы провели бы n раз и в качестве T-статистики использовали бы количество единиц выборки или сумму элементов выборки. Если наша нулевая гипотеза справедлива, то есть Джеймс Бонд выбирает напиток наугад, то мы могли бы равновероятно получить любую комбинацию из нулей и единиц. Таких комбинаций ровно 2 в степени n, поэтому для того чтобы получить нулевое распределение, мы могли бы с вами сгенерировать все эти наборы данных, на каждом посчитать значение этой статистики и таким образом получить наше распределение. На самом деле, в данном случае этот шаг мы можем пропустить. Почему? Потому что мы имеем дело с выборкой, состоящей из нулей и единиц из распределения Бернулли с вероятностью успеха p. В данном случае вероятность успеха p = 0,5, потому что если нулевая гипотеза справедлива, то успех и неудачи просходят равновероятно. Соответственно, мы с вами работаем с выборкой, которая представляет из себя сумму n независимых одинаково распределенных величин из распределения Бернулли. Соответственно, нулевое распределение статистики — это биномиальное распределение с параметрами n, количество экспериментов, и p, вероятность успеха. Соответственно, давайте возьмем n, равное 16, и вероятность успеха — 0,5. Вот давайте посмотрим, как распределение нулевой статистики могло бы выглядеть. Давайте для начала его построим, это можно сделать с помощью функции binom, которой мы передаем количество испытаний и вероятность успеха. И дальше давайте просто посмотрим распределение. Видим, что получили распределение ровно такое, которое мы ожидаем — пик в центре. Так как у нас 16 испытаний, вероятность успеха — 0,5, то пик должен приходиться на 8. Ровно это мы здесь и видим. Теперь давайте перейдем непосредственно к проверке гипотез. Так как Джеймс Бонд утверждает, что он предпочитает взболтанный мартини, то давайте с этого и начнем и будем тестировать гипотезу H0 против односторонней альтернативы. Соответственно, гипотеза H1: Джеймс Бонд предпочитает взболтанный мартини. При такой альтернативе более вероятно попасть в правый конец распределения, то есть более вероятно в нашей выборке получить много единиц. А вот давайте предположим, что мы действительно провели 16 испытаний и при этом в 12 из 16 испытаний Джеймс Бонд выбрал взболтанный мартини, то есть произошел успех. Давайте построим соответствующее нулевое распределение, и видим, что в данном случае наша T-статистика была бы равна 12 и нас бы интересовал правый «хвост» из нашего распределения. В данном случае нам нужно просуммировать высоту столбцов, начиная со столбца, соответствующего 12, и правее, то есть правый «хвост» нашего распределения, и использовать полученное значение при расчете достигаемого уровня значимости. Итак, давайте это сделаем. В данном случае передаем в метод binom_test из модуля stats следующие параметры: первый параметр — это 12, количество успехов, соответственно, следующий параметр — 16, количество испытаний, величина 0,5 — это величина p. И соответственно, вид альтернативы, в данном случае односторонняя альтернатива greater. Итак, давайте посмотрим на значение p-value и увидим, что p-value достаточно маленькое — 0,04. Это говорит о том, что на уровне значимости 0,05 мы можем отвергать нулевую гипотезу. То есть если 12 раз из 16 у нас произойдет успех, то мы с вами можем сделать вывод о том, что Джеймс Бонд предпочитает взболтанный мартини. Так, давайте посмотрим, что было бы, если бы успехов было немножечко меньше, например, 11. Могли бы мы в этом случае прийти к такому же выводу? Ну давайте построим соответствующую гистограмму и увидим, что добавился еще один столбец по сравнению с предыдущим рисунком. Ну а теперь давайте рассчитаем значение p-value. Как вы думаете, мы получим значение больше или меньше? Давайте посмотрим. Видим, что значение p-value стало больше — теперь это 0,1, то есть на уровне значимости 0,05 мы уже не можем отвергнуть нулевую альтернативу. Теперь давайте перейдем к двусторонней альтернативе. В данном случае гипотеза H1 переформулируется следующим образом: Джеймс Бонд предпочитает какой-то один определенный вид мартини, при этом мы не выбираем, какой именно. При такой альтернативе будут очень вероятны либо большие значения этой статистики, либо очень маленькие. При расчете достигаемого уровня значимости мы с вами будем учитывать как правый, так и левый конец нашего распределения. Соответственно, мы будем суммировать высоту правых и левых столбцов. Вот давайте для начала предположим снова, что у нас произошло 12 успехов, то есть 12 раз Джеймс Бонд выбрал взболтанный мартини, и посмотрим, какие столбцы мы с вами будем суммировать. Видим, что мы снова суммируем тот же самый правый конец, но теперь к нему добавляется и левый конец. Теперь давайте рассчитаем значение p-value. Делаем мы это с помощью той же самой функции, однако теперь меняем вид альтернативы — она двусторонняя. И смотрим на значение p-value. Видим, что значение p-value — почти 0,08. То есть это больше, чем было в том случае, когда мы проверяли гипотезу H0 против односторонней альтернативы greater. Соответственно, в данном случае мы не можем отвергнуть гипотезу на уровне значимости 0,05, однако мы можем отвергнуть нулевую гипотезу на уровне значимости 0,1. Итак, давайте посмотрим, что было бы, если бы у нас произошло 13 испытаний — может быть, их достаточно для того, чтобы отвергнуть нулевую гипотезу на уровне 0,05. Смотрим и видим, что мы суммируем значения, соответствующие правому левому концу, в данном случае столбцов. Красных столбцов уже меньше, то есть мы видим, что значение статистики более экстремальное. И теперь давайте посмотрим на значение p-value. Видим, что всего лишь 0,02. Соответственно, мы можем отвергнуть нулевую гипотезу на уровне значимости 0,05. Итак, мы с вами научились применять биномиальный критерий для доли, мы научились тестировать нулевую гипотезу против двусторонних и односторонних альтернатив. А на следующем видео мы поговорим про критерий Хи-квадрат, или критерий согласия Пирсона.

В этом видео мы потренируемся на практике применять критерии согласия Пирсона или критерий хи-квадрат. Напомню, что этот критерий используется для проверки того, что некоторая наблюдаемая случайная величина подчиняется тому или иному теоретическому закону распределения. Тренироваться мы будем на примере про исчерпанную рождаемость. Этот признак связан с количеством детей, родившихся у женщины на момент окончания репродуктивного возраста. Это приблизительно 45 лет. Для 1878 женщин старше 45, участвующих в социологическом опросе жителей Швейцарии, известно количество детей. Этот признак – типичный счётчик, поэтому его можно попробовать оценить с помощью распределения Пуассона. Таким образом, работать мы будем со следующей выборкой: это будет целочисленный вектор длины n, в данном случае длины 1878, где каждые компоненты вектора характеризуют количество детей, рожденных у женщины. В данном случае гипотеза H0 – это то, что наша наблюдаемая величина имеет распределение Пуассона. Для начала давайте загрузим данные. Сделаем это с помощью функции open, и так как мы с вами заранее знаем, какого вида наши данные, давайте сразу отрежем от каждой строчки все нечитаемые символы и преобразуем tip в int. Делаем это с помощью простой комбинации функции map и λ. Вот так, готово. Давайте посмотрим на данные. Мы видим, что, действительно, это просто список целых чисел. Давайте посмотрим на то, как наши данные распределены. Для того чтобы это сделать, нам нужно проссумировать сколько раз встречается каждое количество детей. Это очень легко сделать с помощью функции bincount из модуля NumPy. И построим график. Ну вот мы видим, что, в общем-то, количество детей меняется от 0 до 11. Чаще всего у женщины не более четырёх детей. Наиболее часто встречающееся количество детей – это два ребёнка. Кажется, что такие данные должны хорошо описываться распределением Пуассона. Давайте сразу оценим, какая λ должна быть в этом случае. Из предыдущих курсов вы помните, что лучшая оценка на параметр λ для распределения Пуассона, это просто выборочное среднее. Вот давайте его посчитаем и посмотрим, сколько же это. Получается приблизительно 2. Таким образом, давайте проверять следующую гипотезу. Наша с вами наблюдаемая случайная величина имеет распределение Пуассона с λ = 2. Делать это будем с помощью критерия согласия Пирсона. Мы с вами захотим применить критерий хи-квадрат с помощью функции Chi-square из модуля stats библиотеки SciPy. Для этого нам нужно будет подготовить данные. Первое, что нас будет интересовать, это наблюдённые частоты. В данном случае мы с вами знаем, сколько раз встретилось каждое количество детей в данных, поэтому давайте это рассчитаем. Это очень просто, мы уже сегодня применяли функцию bincount. Давайте это сделаем и сразу же увидим результат. Мы получили целочисленный вектор, где каждая компонента характеризует, сколько раз данное количество детей встретилось. То есть элемент вектора 0 говорит о том, сколько раз в нашей выборке встретилось количество детей, равное 0, в данном случае это 379, и последний 11 элемент означает, что 11 детей у нас встретилось всего лишь 1 раз. Это наблюдённые частоты. Теперь нам нужно построить так называемые ожидаемые частоты. Что же это такое? Если бы наши данные имели ровное распределение Пуассона с параметром λ2 и размер данных был бы таким же, сколько раз мы бы встретили каждое количество детей? Вот именно эту величину нам с вами нужно рассчитать. Это делается довольно просто. С помощью функции pmf stats.poisson.pmf мы можем с вами посчитать вероятность встретить некоторые значения, если данные распределены с распределением Пуассона. Давайте эти вероятности рассчитаем, они нас будут интересовать для значений от 0 до 11, а дальше просто умножим их на размер нашей выборки. Таким образом, мы получим то распределение, которое мы бы имели, если бы данные были порождены именно распределением Пуассона с оценённым нами параметром. Давайте это сделаем и посмотрим, какие же ожидаемые частоты мы бы получили. Видим, что они несколько отличаются от наблюдённых частот. В общем-то, какие-то, может быть, довольно близки. Вот теперь давайте посмотрим на то, как это выглядит, построим гистограмму наших наблюдённых частот, то есть то, что бы мы получили из распределения Пуассона. Интересно сравнить этот график с предыдущим. Давайте отмотаем назад. В общем-то, видим, что они значительно отличаются. Теперь давайте это оценим строго с помощью критерия хи-квадрат. Вызываем функцию Chi-square, передаём ей наблюдённые частоты, ожидаемые частоты, и также важно указать параметры ddof, то есть difference of degrees of freedom. Это разница между степенями свободы. Дело в том, что мы с вами уже израсходовали одну степень свободы, когда оценивали параметр λ. Мы сделали это здесь, оценив его, как среднее по нашим данным, поэтому нам нужно сказать, что у нас теперь разница степеней свободны составляет 1, единичку мы уже потратили. Вот теперь давайте применим данный критерий и посмотрим. Во-первых, мы получили значение статистики, 431,5, и также значение p-value. Мы видим, что значение p-value – оно практически 0, очень маленькое число. Это значит, что мы можем смело отвергнуть гипотезу H0. То есть это означает, что наши данные не имеют распределения Пуассона с параметром l = почти 2. Итак, мы на этом заканчиваем. На этом видео мы научились на практике применять критерий хи-квадрат. А на следующим уроке вы поговорите про связь между проверкой гипотез и доверительными интервалами.

[БЕЗ_ЗВУКА] В этом видео мы поговорим о том, как задача проверки гипотез связана с построением доверительных интервалов. Представьте, что у вас есть бинарный классификатор, который настроен на обучающие выборки, и тестовая выборка из 100 объектов. Ваш бинарный классификатор на 60 из этих 100 объектов верно предсказывает метку класса. Кажется, что 60 из 100 — это не очень много. С другой стороны, может быть, задача достаточно сложная, и лучше предсказать просто не получается. Давайте подумаем, какой классификатор самый плохой. Ясно, что это генератор случайных чисел. Если в вашей задаче классы сбалансированы, то генератор случайных чисел будет угадывать в среднем 50 объектов из 100, то есть вероятность угадать для него будет составлять 0,5. Можно ли считать, что классификатор, который угадывает 60 из 100 лучше, чем генератор случайных чисел? Для того чтобы ответить на этот вопрос, можно построить доверительный интервал для доли верно предсказанных меток. 95-процентный нормальный доверительный интервал составляет от 0,504 до 0,696. Этот доверительный интервал не содержит значение 0,5, которое соответствует плохому классификатору, генератору случайных чисел. Значит ли это, что наш классификатор значимо лучше, чем генератор случайных чисел? Да, действительно значит. Если у вас есть точечная нулевая гипотеза вида θ = θ₀, и вы её проверяете против двусторонней альтернативы θ ≠ θ₀, эту проверку можно делать с помощью построения доверительного интервала. Нулевая гипотеза отвергается на уровне значимости α, если доверительный интервал с уровнем доверия 1 − α для θ не содержит θ₀. С помощью доверительного интервала можно посчитать и достигаемый уровень значимости p. Это будет наибольшее значение α, при котором доверительный интервал с уровнем доверия 1 − α содержит θ₀. То есть перебирая разные значения α, можно численно найти достигаемый уровень значимости. Многие статистические критерии и методы построения доверительных интервалов явным образом эквивалентны. Например, нормальные доверительные интервалы для доли, которые мы уже умеем строить, эквивалентны z критерию для той же самой доли, которую мы будем разбирать на следующей неделе. Для таких пар необходимости в численном подсчёте достигаемого уровня значимости через вот такую инверсию доверительного интервала никакой нет, это всё можно сделать аналитически. Для других методов, например, для метода построения доверительных интервалов Уилсона, не существует явного выражения для статистического критерия, поскольку просто из доверительного интервала Уилсона аналитически статистику выразить нельзя. Для таких методов вот такой метод численного поиска достигаемых уровней значимости оказывается очень полезным. Например, в нашей задаче с бинарным классификатором доверительный интервал Уилсона для доли верно предсказанных меток составляет от 0,502 до 0,691. В этой задаче доверительный интервал Уилсона довольно похож на нормальный доверительный интервал, но в других задачах, особенно когда значение p близко к нулю или единице, доверительный интервал Уилсона может существенно отличаться, и он точнее, нужно пользоваться именно им. Вот численно инвертируя этот доверительный интервал, мы можем получить в таких задачах достигаемый уровень значимости, который будет существенно отличаться от того, что вы получите с помощью z критерия. В данном случае достигаемый уровень значимости составляет 0,045. То есть на уровне значимости 0,05 гипотеза о том, что наш классификатор не лучше, чем генератор случайных чисел, может быть отвергнута. Таким образом, мы научились проверять гипотезы с помощью доверительного интервала. Можно делать и наоборот — строить доверительные интервалы с помощью критерия, проверяющего гипотезу. Если у нас снова есть вот такая пара — точечная гипотеза относительно параметра θ и двусторонняя альтернатива, из этого механизма можно сконструировать доверительный интервал для θ. И доверительный интервал с уровнем доверия 1 − α будет состоять из всех значений θ₀, для которых вот такая нулевая гипотеза против двусторонней альтернативы не отвергается на уровне значимости α. Этот метод построения доверительных интервалов не слишком конструктивный, но иногда его можно применять, если под рукой нет никакого метода получше. Давайте теперь добавим к нашему исследованию качества классификатора второй. Этот второй классификатор на той же самой тестовой выборке из 100 объектов верно предсказывает метки для 75. Можно ли считать, что второй классификатор лучше? 75, конечно, больше, чем 60, но, с другой стороны, выборка из 100 объектов не очень большая. Может быть, эту разницу можно объяснить исключительно случайной ошибкой. Можно ли на этот вопрос ответить с помощью доверительных интервалов? Давайте сделаем так. Для первого классификатора доверительный интервал Уилсона для доли верных предсказаний составляет от 0,502 до 0,691. Мы это уже строили. Для второго классификатора такой же точно доверительный интервал составляет от 0,657 до 0,825. У этих доверительных интервалов есть общий кусок — они пересекаются по отрезку от 0,657 до 0,691. Если эти два доверительных интервала пересекаются, значит ли это, что классификаторы по качеству мы различить не можем? На самом деле нет. Если у нас есть нулевая гипотеза точечная относительно двух параметров θ₁ и θ₂, мы её проверяем против двусторонней альтернативы. Недостаточно просто построить доверительные интервалы отдельно для θ₁ и θ₂, если такие интервалы пересекаются, это ещё не значит, что нулевую гипотезу нельзя отвергнуть. Правильным решением в этой ситуации будет построить доверительный интервал непосредственно для разности наших параметров θ₁ и θ₂. Именно она полностью соответствует нашей нулевой гипотезе. Если θ₁ = θ₂, значит, их разность равна нулю. Вот такую нулевую гипотезу мы, по сути, проверяем. 95-процентный доверительный интервал для разности долей в данной задаче составляет от 0,022 до 0,278. Этот доверительный интервал не содержит ноль. То есть мы можем утверждать, что наш второй классификатор значимо лучше. Инвертируя этот доверительный интервал уже описанным способом, перебирая α и выбирая наибольшее значение α, при котором ноль в доверительный интервал попадает, мы получаем достигаемый уровень значимости, равный 0,022. То есть на уровне значимости 0,05 опять-таки нулевая гипотеза отвергается о том, что два классификатора по качеству одинаковы. Вообще говоря, в этой задаче выборки на самом деле связанные, поскольку качество мы считаем на одной и той же обучающей выборке, на одних и тех же 100 объектах. Поэтому правильнее использовать другой метод построения доверительных интервалов. Вот возьмём вот такую таблицу сопряжённости 2 x 2 и по ней посчитаем доверительный интервал, который будет рассчитываться не на количестве ошибок каждого из классификаторов отдельно, а на количестве объектов, на которых классификаторы дали разные ответы, то есть 20 и 5 из этой таблицы. Соответствующий доверительный интервал 95-процентный для разности долей в связанных выборках равен от 0,06 до 0,243. Обратите внимание, что этот доверительный интервал уже, и его левая граница дальше отстоит от нуля. То есть учитывая связанность, мы становимся более уверены в том, что наши классификаторы отличаются. Инвертируя этот интервал, мы получаем достигаемый уровень значимости, равный 0,002. Он почти в десять раз больше, чем в предыдущем случае, когда связанность между выборками мы не учитывали. Итак, в этом уроке мы с вами начали разбираться с проверкой гипотез. Мы поговорили о том, как устроен механизм проверки гипотез. Что нужно для того, чтобы проверять нулевую гипотезу против альтернативы? Статистика и нулевое распределение. Как выбираются нулевая гипотеза и альтернатива, и почему их нельзя в общем случае менять местами? Потому что ошибка первого рода для вас важнее, чем ошибка второго рода. Мы поговорили о том, что такое достигаемый уровень значимости и как его правильно интерпретировать. Обсудили, что важно при каждой проверке гипотез также строить и оценку для размера эффекта, потому что именно она представляет основной интерес. И важно, чтобы кроме статистической значимости, у вас была ещё и практическая. Также мы обсудили связь между проверкой гипотез и доверительным интервалом. А это последнее видео этого урока, дальше вас ждёт самостоятельная работа.
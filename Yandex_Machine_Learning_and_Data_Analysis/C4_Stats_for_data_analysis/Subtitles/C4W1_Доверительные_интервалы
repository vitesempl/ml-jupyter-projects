[БЕЗ_ЗВУКА] В течение этого урока мы с вами научимся строить интервальные оценки. Мы уже немного говорили об этом в первом курсе нашей специализации, когда разбирали некоторые частные случаи для построения доверительных интервалов, в частности, использование правила двух сигм. В этом виде нам предстоит уточнить правило двух сигм и разобраться с тем, что такое предсказательный интервал. Давайте вспомним, как выглядит правило двух сигм. Если у вас есть нормально распределённая случайная величина с матожиданием μ и дисперсией σ², то 95 % её вероятностной массы примерно приходится на интервал μ ± 2σ. То есть ваша случайная величина x принимает значения от μ − 2σ до μ + 2σ с вероятностью примерно 95 %. Во‐первых, это оценка неточная, во‐вторых, хочется такие оценки строить не только для 95 %‐ной вероятности, но и для произвольной. Вот именно это мы сейчас и научимся делать. Нам понадобится ещё одно определение из первого курса — определение квантиля. Давайте вспомним, что это такое. Квантилем порядка α, где α от 0 до 1, случайной величины x называется такая величина Xα, что наша X лежит слева от неё с вероятностью не меньше, чем α, и справа от неё с вероятностью не меньше, чем 1 − α. Для квантиля есть очень много эквивалентных определений. В частности, если наша величина X задана функцией распределения F(x), то квантилем будет значение обратной к функции распределения в точке α. То есть наименьшее X, такое, что наша функция распределения F(x) ≥ α. Давайте теперь определение квантиля используем для уточнения правила двух сигм. Мы хотим найти такие границы отрезка, что наша случайная величина X лежит внутри него с вероятностью ровно 95 %. Перед вами график плотности нормального распределения. Напомню, что плотность — это такая функция, интеграл от которой по всей числовой прямой равен 1, а по любому отрезку — вероятности попадания нашей случайной величины в этот отрезок. Интеграл — это площадь под кривой. Давайте отрежем на этом графике хвосты, левый и правый, так, чтобы площади этих хвостов были равны 2,5 %. Тогда площадь под центральным куском нашего графика будет равна 95 % — 0,95. По определению квантиля, границы таких хвостов задаются 2,5 %‐ным и 97,5 %‐ным квантилями. Всё. Искомый интервал найден. Вероятность того, что наша случайная величина лежит на отрезке от 2,5 %‐ного до 97,5 %‐ного квантилей, равна в точности 95 %. Такой трюк можно делать с произвольно распределённой случайной величиной. Если ваша случайная величина задаётся функцией распределения F(x), то вероятность того, что она принимает значения из отрезка от квантиля порядка α/2 до квантиля порядка 1 − α/2, равна 1 − α. Отрезок от Xα/2 до X1 − α/2 называется предсказательным интервалом для случайной величины X порядка 1 − α. Если мы имеем дело с нормально распределённой случайной величиной с матожиданием μ и дисперсией σ², её квантили можно выразить через μ, σ и квантили стандартного нормального распределения, то есть нормального распределения со средним 0 и дисперсией 1. Предсказательный интервал принимает вид интервала μ ± z порядка 1 − α/2 * σ. Нормальное распределение, стандартное, симметрично, поэтому z порядка α/2 равно −z1 − α/2. Квантиль стандартного нормального распределения порядка 1 − 0,05/2, то есть порядка 0,975, равен примерно 1,96. Или, если ещё сильнее округлять, — 2. Вот именно отсюда и берётся правило двух сигм. Итак, в этом видео мы узнали, как квантили используются для построения интервальных оценок. Мы узнали, что такое предсказательный интервал, а также с помощь аппарата квантилей уточнили правило двух сигм. В следующих видео мы начнём делать примерно то же самое с доверительными интервалами.

В этом видео мы перейдем от предсказательных интервалов к доверительным и поговорим о том, чем они отличаются, и как эти доверительные интервалы строить. Ну давайте сначала вернемся к более общей задаче. Пусть у нас есть некоторая случайная величина X с функцией распределения, зависящей от неизвестного параметра θ. Как что-то о значении параметра θ можно сказать? Мы собираем выборку X с верхним индексом n, и по этой выборке считаем значение какой-то статистики θ с крышкой. Если мы хорошо подобрали статистику, то она может служить оценкой для неизвестного параметра θ. Например, если θ — это математическое ожидание X, то ее хорошая выборочная оценка — это выборочное среднее, то есть среднее всех X, которые есть в нашей выборке. Кроме точечных оценок, нас интересует интервальные, то есть доверительные интервалы. Доверительным интервалом для параметра θ называется такая пара статистик CL, CU, что интервал, который эта пара образует, содержит наше неизвестное значение параметра с вероятностью не меньше, чем 1 − α. 1 − α — это уровень доверия нашего интервала. Как вот эти CL и CU (нижние и верхние доверительные пределы) оценивать по выборке? Если у нас есть оценка θ с крышкой для параметра θ и мы знаем распределение θ с крышкой — обозначим его за F с индексом θ с крышкой, — то по этому распределению мы можем очень легко найти доверительный интервал для θ. Мы просто возьмем квантили этого распределения порядка α / 2 и 1 − α / 2, и эти квантили будут образовывать доверительный интервал для θ с уровнем доверия 1 − α. Давайте построим доверительный интервал для матожидания нормальной распределенной случайной величины. Снова будем предполагать, что дисперсия известна. Оценкой для параметра μ является выборочное среднее, то есть X с чертой и с индексом n. Поскольку наша выборка взята из нормального распределения, ее выборочное среднее также имеет нормальное распределение, поскольку нормальное распределение замкнуто относительно суммирования. Распределение выборочного среднего — нормальное, с тем же матожиданием μ и с дисперсией в n раз меньше, то есть σ² / n. Таким образом, для выборочного среднего, которое является случайной величиной, мы знаем распределение, а значит, мы можем построить для нее предсказательный интервал, как мы научились делать в предыдущем видео. Предсказательный интервал для выборочного среднего имеет вид: μ ± z порядка 1 − α / 2 * (σ / √n). Вот это деление на √n здесь появляется, поскольку дисперсия случайной величины и выборочное среднее равна σ² / n. В таком интервале наше выборочное среднее лежит с вероятностью, в точности равной 1 − α. Теперь, чтобы построить доверительный интервал для μ, единственное, что нам нужно сделать — это в неравенствах, которые стоят под знаком вероятности, перенести через знаки неравенства μ и выборочное среднее. Мы получим, что вероятность того, что μ лежит на отрезке от выборочного среднего −z порядка 1 − α / 2 * (σ / √n), до выборочного среднего +z порядка 1 − α / 2 * σ / √n = точно так же в точности 1 − α. Таким образом, мы построили доверительный интервал для μ. Давайте поговорим об отличиях между этими двумя интервалами (предсказательном и доверительном). В предсказательном интервале границы не случайны, случайно то, что стоит между этих границ, то есть наша случайная величина — выборочное среднее. В доверительном интервале все ровно наоборот: то, что стоит в середине — это не случайный параметр. Параметр μ — это какая-то фиксированная константа, просто мы ее не знаем. А случайными являются как раз границы интервала. Для нормально распределенной случайной величины с матожиданием μ и дисперсией σ² предсказательный интервал имеет вид: μ ± z порядка 1 − α / 2 * σ. Если мы хотим этот предсказательный интервал как-то оценивать по выборке, нам нужно избавиться от μ в его границах, потому что μ нам не известно. Единственное, что мы можем сделать, и лучшее, что мы можем сделать — это заменить μ на выборочное среднее. Таким образом, наш предсказательный интервал для случайной величины X — это выборочное среднее ± z порядка 1 − α / 2 * σ. В свою очередь доверительный интервал для μ, который мы по той же самой выборке можем построить, имеет вид: выборочное среднее ±z порядка 1 − α / 2 * (σ / √n), то есть он в √n раз уже. Это неудивительно, поскольку предсказательный интервал оценивает диапазон, в котором меняется сама случайная величина, а доверительный интервал для среднего говорит, в каком диапазоне, мы предполагаем, лежит среднее этой случайной величины. Вообще говоря, этой техникой можно пользоваться для построения доверительных интервалов для матожидания не только нормально распределенных случайных величин, но и практически любых других. На помощь нам приходит центральная предельная теорема. Она говорит нам, что распределение выборочного среднего по достаточно большой выборке — если распределение исходной случайной величины не слишком скошено — может быть аппроксимировано нормальным с средним, равным среднему исходной случайной величины, и дисперсией, которая в n раз меньше. Таким образом, доверительный интервал для матожидания исходной случайной величины имеет вид: выборочное среднее ± z порядка 1 − α / 2, умноженное на дисперсию нашей случайной величины, если она известна, деленное на √n. Итак, в этом видео мы поговорили о доверительных интервалах, мы обсудили, чем они отличаются от предсказательных и как их можно строить, зная распределение статистик. Мы построили доверительные интервалы для выборочного среднего нормального распределения с известной дисперсией. Чтобы двигаться дальше, нам понадобится ввести еще несколько распределений. В следующем видео мы поговорим о трех распределениях, которые порождаются нормальным.

В этом видео мы введем несколько распределений, которые являются производными от нормального, и поговорим о том, как они возникают. А в следующих видео вы увидите, как эти распределения применяются. Давайте для начала быстренько вспомним про нормальное распределение. У нормально распределенной случайной величины два параметра: μ и σ, μ равна матожиданию, а сигма — квадрат дисперсии. Вот так выглядит ее плотность и функция распределения. Обратите внимание, что функция распределения не выражается аналитически, то есть вот этот интеграл не берется, а график плотности распределения похож на знакомую вам шляпу. Давайте теперь представим, что у нас есть k независимых одинаково распределенных нормальных случайных величин, то есть со средним 0 и дисперсией 1. Определим новую случайную величину X, равную сумме квадратов наших Xi. Распределение такой случайной величины называется распределением хи-квадрат с k степенями свобод. К сожалению, формулы для плотности и функции распределения хи-квадрат выглядят ужасно, поэтому мы даже не будем на них смотреть. Точно так же не будем смотреть на формулы для функции распределения и плотности следующих распределений. При k, равном 1 и 2, график для плотности хи-квадрат — это монотонно убывающая функция с максимумом в 0. При k, начиная с 3, у плотности появляется максимум, который с ростом k начинает постепенно уезжать вправо по числовой оси. Пусть теперь у нас есть случайная величина X1 из стандартного нормального распределения и X2 из распределения хи-квадрат с числом степеней свободы ν. Определим новую случайную величину X, равную отношению X1 к √X2 / ν. Такая случайная величина будет иметь распределение Стьюдента с числом степеней свободы ν. Перед вами графики плотности распределения Стьюдента при разных ν. На первый взгляд они кажутся похожими на плотности нормального распределения, а так у них более тяжелые хвосты, то есть для них более вероятны большие по модулю значения случайной величины. Кроме того, они всегда центрированы в 0, то есть они не могут никуда сдвигаться по числовой оси, в отличие от нормального распределения. Чем больше ν, тем меньше отличие распределения Стьюдента от нормального. При ν, начиная с 30, визуально практически невозможно отличить распределение Стьюдента и нормальное. Пусть теперь X1 имеет распределение хи-квадрат с числом степеней свободы d1, X2 — хи-квадрат с числом степеней свободы d2. X1, X2 — независимы. Отношение X1 и X2, нормированных на свои числа степеней свободы, имеет распределение, которое называется распределением Фишера с числом степеней свободы d1 и d2. Варьируя d1 и d2, можно получать очень разные виды для функции плотности распределения Фишера. Некоторые из них вы видите на рисунке. Зачем эти распределения нужны? Для того чтобы начать с этим разбираться, давайте возьмем выборку объема N из нормального распределения с математическим ожиданием μ и дисперсией σ². Про выборочное среднее такой выборки мы уже знаем, что оно распределено тоже нормально, с тем же самым математическим ожиданием μ и дисперсией в n раз меньше — σ² / n. Что мы можем сказать про выборочную дисперсию? Если мы внимательно посмотрим на выражение для выборочной диспресии, мы увидим, что оно представляет собой сумму квадратов чего-то. Вот это что-то — это независимые, одинаково распределенные нормальные случайные величины. Поэтому неудивительно, что распределение выборочной дисперсии имеет какое-то отношение к распределению хи-квадрат. Действительно, специальным образом нормировав выборочную дисперсию, поделив ее на истинную дисперсию σ² и умножив на n − 1, мы получим величину, которая имеет распределение хи-квадрат с числом степеней свободы n − 1. Рассмотрим теперь еще одну полезную статистику, которая называется T-статистикой. Она представляет собой отношение разности выборочного среднего и истинного математического ожидания μ к корню из выборочной дисперсии, деленной на n, то есть в знаменателе стоит S / √n. Такая статистика имеет распределение Стьюдента с числом степеней свободы n − 1. Наконец, пусть теперь у нас есть две выборки, объемов N1 и N2, каждая из своего нормального распределения. Параметры первого — μ1, σ1, параметры второго — μ2, σ2. Если мы возьмем отношение выборочных дисперсий этих двух выборок, поделим их каждая на свою истинную дисперсию — σ1², σ2², — то такая величина будет иметь распределение Фишера с числом степеней свободы, определяемых объемами наших выборок. Число степеней свободы распределения Фишера = (n1 − 1, n2 − 1). Итак, в этом видео мы поговорили о том, как выглядят распределения хи-квадрат Стьюдента и Фишера, как они связаны с нормальным расперделением, а также увидели, какие статистики могут иметь такие распределения. Начиная со следующих видео, мы начнем разбираться с тем, как эти распределения и эти полученные знания можно использовать для построения доверительных интервалов.

[БЕЗ_ЗВУКА] Привет. В этом видео мы научимся строить доверительные интервалы для оценки среднего. Часто нам недостаточно просто построить точечную оценку среднего по выборке, — выборочное среднее, — а нам хочется понять, в каких диапазонах, вообще говоря, это среднее может изменяться. Именно для этого используют доверительные интервалы для оценки среднего. Мы с вами будем решать следующую задачу. Мы сгенерируем некоторый игрушечный набор данных, будем решать задачу бинарной классификации. При этом на этом наборе данных мы обучим две линейные модели и будем сравнивать их качество. Причем качество мы будем сравнивать не в точке, а сравнивать его интервально с помощью интервальной оценки на среднее по некоторой метрике. Для начала давайте такой набор данных получим. Делать это будем с помощью функции make_blobs из модуля datasets из библиотеки sklearn. Ну давайте будем генерировать данные для задачи бинарной классификации, сгенерируем всего 300 точек, которые будут несколько накладываться друг на друга, два облака точек. Вот сгенерировали данные, теперь давайте их отрисуем и посмотрим, как это выглядит. Вот видим, что получили два облака точек, и они несколько накладываются друг на друга. Теперь давайте обучать модели. Как получить самую простую точечную оценку? Ну очень просто. Разбиваем данные на обучение и тест. На обучении строим наши модели, далее на тесте их оцениваем и сравниваем их качество. Вот давайте с этого начнем. Разбивать данные будем с помощью функции train_test_split из модуля cross_validation, снова библиотека sklearn. Делаем это. И теперь давайте строить две модели. Первая модель — это модель RidgeClassifier, Ridge-классификатор, и вторая модель — это SGDClassifier, классификатор на основе стохастического градиентного спуска. Вы с ними уже знакомы из второго курса. Итак, давайте построим первую модель. Сразу же создаем модель, далее обучаем ее с помощью meta_fit на обучающей части данных, train_data и train_labels, соответственно, признаки и метки классов. И далее, оцениваем качество. Качество оцениваем с помощью метрики roc_auc, в реализации модуля metrics.roc_auc_score, и давайте сразу же выведем на экран. Видим, что получили качество 0,89. Так, отлично. Теперь вторая модель. Точно так же создаем классификатор. Делаем это снова с параметрами по умолчанию. Конечно, это не самый лучший способ обучения модели, но в данном случае нам он подходит. Далее, с помощью метода fit обучаем модель и сразу же снова оцениваем метрику roc_auc. Видим, что качество получается такое же. Исходя из этого можно предположить, что модель работает абсолютно одинаково и, наверное, можно выбрать любую. Давайте попробуем нашу оценку уточнить. Как это можно было бы сделать? Ну понятно, что в данном случаем мы оценили наши модели только по одному разбиению, а на самом деле можно оценить их по нескольким разбиениям. Из предыдущих курсов вы уже знакомы с техникой под названием кросс-валидация, когда мы с вами разбиваем наши доступные данные сразу же на несколько пар обучение–тест и оцениваем качество на каждой такой паре. Вот давайте то же самое сделаем для нашей задачи. Для того чтобы это реализовать, можно воспользоваться функцией cross_val_score, она работает следующим образом. Она разбивает наши данные на обучение и тест в соответствии с той стратегией, которую мы с вами выберем, и далее возвращает нам список оценок качества нашей модели на тестовых подвыборках. Вот давайте в данном случае сделаем следующее. Будем разбивать наши данные по стратегии key fold на 20 фолдов, и оценим качество в каждом из них. Оценивать качество будем с помощью метрики roc_auc. Итак, для начала сделаем это для SGD-классификатора, и теперь для Ridge-классификатора. Итак, в результате мы с вами получили два массива, два списка оценок на тестах. Давайте выведем среднее и отклонение метрики roc_auc для каждой из моделей и сравним полученные результаты. Это очень просто делается с помощью функции mean.std, и далее с помощью метода print выводим результаты. Видим, что теперь уже наши оценки неодинаковы, то есть, вообще говоря, модели работают по-разному. Видим, что кажется в среднем модель Ridge-классификатор работает лучше и отклонение тоже меньше. Исходя из этого можно предположить, что, наверное, выбрать стоило бы эту модель. Ну давайте пойдем дальше. Тут мы получили точечную оценку среднего. Давайте посмотрим, в каких диапазонах это среднее может изменяться. Мы с вами рассмотрим два метода для построения доверительных интервалов для среднего. Первый метод — это так называемый z-интервал, формула перед вами. Для начала давайте импортируем необходимые функции. Мы с вами будем пользоваться методами zconfint_generic и чуть позже методом tconfint_generic для построения доверительных интервалов. Реализация находится в библиотеке statsmodels. И далее нам обязательно понадобится выборочное среднее, поэтому давайте сразу же его рассчитаем и запишем соответствующие переменные. Это тоже очень просто, делаем это с помощью метода mean. Итак, для начала z-интервал. Формула перед вами, и по формуле понятно, что для того, чтобы этот интервал построить, нам нужно откуда-то взять оценку дисперсии. Соответственно, для того чтобы строить z-интервал мы либо дисперсию должны знать, либо, раз мы ее не знаем, сделать некоторые предположения. Вот в данном случае давайте предположим, что дисперсия равняется 0,25. Понятно, что это предположение очень плохое, потому что оно фактически ни на чем не основано. Ну и давайте теперь этот интервал построить. Пользуемся методом zconfint _generic. Для начала передаем в него наше выборочное среднее, мы его рассчитали шагом ранее. Также указываем отклонение. Говорим, что мы используем уровень значимости 0,05 и двустороннюю альтернативу. Итак, строим наши оценки и видим, что интервалы получились достаточно широкими. Причем видно, что для второй модели Ridge-классификатор наш интервал находится весь несколько правее, поэтому, казалось бы, можно сделать предположение, что эта модель чуть лучше. Еще раз обращаю внимание, что здесь мы использовали дисперсию, которую мы фактически не знаем, поэтому доверие к этой оценке не очень большое. Давайте попробуем построить интервалы таким образом, чтобы не использовать никаких предположений, взявшихся ниоткуда. Для этого нам с вами подойдет t-интервал. Вместо гипотетической и теоретической дисперсии, которую мы на самом деле не знаем и взяли непонятно откуда, давайте для построения доверительного интервала использовать выборочную оценку дисперсии. Обратите внимание на формулы, видите, что здесь уже сигма квадрат не участвует, но зато участвует выборочная дисперсия. Вот давайте такую оценку сделаем. Для начала нам с вами дисперсию нужно рассчитать. Это совсем просто. И теперь давайте воспользуемся методом tconfint_generic для построения доверительного интервала. Также передаем туда наше выборочное среднее, передаем туда дисперсию. И теперь смотрите: нужно указать количество степеней свободы, которые у нас есть, так как мы уже использовали одну степень свободы для того, чтобы рассчитать выборочную дисперсию, вот давайте оценим количество степеней свободы как размер выборки минус 1. И остальные параметры остаются без изменения. Уровень значимости и тип альтернативы. Итак, давайте посмотрим на оценки. Видим, что в данном случае наши интервалы сильно уже, то есть наша оценка получилась более точной. И из этой оценки снова следует, что модель RidgeClassifier немножечко лучше. А на этом мы с вами заканчиваем. На этом видео мы научились строить доверительные интервалы для среднего, а на следующем уроке поговорим об очень интересной теме — доверительный интервал для доли.

[БЕЗ ЗВУКА] В этом видео мы научимся строить доверительные интервалы для доли. Работать мы будем с генеральной совокупностью, состоящей из бинарных событий. Это такие события, каждое из которых можно связать с 0 или с 1, или по-другому, с успехом или с неудачей. В жизни довольно много примеров таких событий. Например, это проигрыш или выигрыш в лотерею, покупка или не покупка товара, клик или не клик на рекомендацию. Мы с вами рассмотрим следующий пример. Предположим, что мы работаем с некоторой рекламной сетью и у нас есть возможность откручивать баннер на нескольких рекламных площадках. В этом случае нам хочется измерять качество открутки наших баннеров и понимать — достаточно ли прекрасен каждый из тех баннеров, которые мы показываем, то есть, нравятся они пользователям или нет? Для того чтобы это понять, мы можем померить, как часто пользователи кликают на эти баннеры, а как часто они их просто игнорируют. Такой показатель называется click through rate, или «доля кликов по баннеру». В нашем случае это как раз и есть доля успехов в нашей генеральной совокупности. Чтобы оценить эту долю точно нам нужно дождаться конца открутки нашего баннера, далее, собрать все данные, данные с каждой из площадок, на которых мы его откручивали, и честно эту метрику посчитать. Понятно, что это занимает существенное время и часто нам хочется делать вывод о качестве баннера сильно раньше, чем заканчивается открутка. Например, это может помочь нам прекратить показывать неудачные баннеры. Таким образом, мы приходим к задаче оценки доли успехов по выборке. Ровно этим мы с вами сегодня и займемся. Давайте для начала сгенерируем такие данные. Импортируем необходимые библиотеки. И теперь делаем следующее. Понятно, что в рамках предложенной задачи мы работаем с конечной генеральной совокупностью. Вот давайте такую сгенерируем, делать это будем с помощью модуля random из библиотеки NumPy и будем использовать функцию randint. Скажем, что нам интересует два значения^ 0 и 1, и выборка размера 100 000. Дальше давайте сразу же сгенерируем случайную подвыборку из нашей генеральной совокупности, сделаем это с помощью random.choice. Сгенерируем подвыборку размером 1000. Именно по ней мы будем оценивать долю успехов. Итак, готово. Теперь давайте посмотрим истинное значение доли. Это можно сделать, оценив среднее по генеральной совокупности. В данном случае мы видим, что наше истинное значение – 0,498. Теперь давайте попробуем получить оценку истинного значения доли по нашей выборке. Из предыдущих уроков вы знаете, что самая лучшая оценка среднего – это выборочная средняя. Ну почему она лучшая? Эта оценка является несмещенной, асимптотически нормальной, эффективной. Вот давайте эту оценку посчитаем. Это делается очень просто — с помощью метода mean. Видим, что мы получили 0,502 — в общем, это очень хорошее продвижение. Однако часто такой оценки недостаточно. Например, в тех случаях, когда мы хотим знать, в каких диапазонах меняется настоящая доля, то есть какое минимальное и максимальное значение на нашу оценку среднего. Вот для того чтобы такую оценку получить, нужно построить доверительный интервал на среднее. Для того чтобы такой интервал получить, мы с вами будем использовать библиотеку Statsmodels. Чаще всего доверительные интервалы строятся на основе нормального распределения с использованием центральной предельной теоремы. Формула прямо перед вами. Давайте и мы начнем с этого. Для того чтобы такие интервалы получить, мы будем использовать функцию proportion confint. Она принимает несколько аргументов. Первый аргумент — это количество успехов в нашей подвыборке. Второй аргумент — это количество событий, то есть размер нашей подвыборки. И метод, с помощью которого мы хотим это оценивать. Мы работаем с нормальным распределением, поэтому и пишем метод normal. Итак, давайте построим интервал, очень просто. И теперь давайте выведем заданные границы на экран. Помимо самих границ интервала нас также будет интересовать его ширина. Понятно, это довольно важная характеристика, потому что чем уже получился наш интервал, тем более точную оценку диапазона мы с вами получили. Давайте посмотрим. Видим, что интервал получился неплохой. Помним, наше настоящее среднее 0,498, оно в этот интервал попадает. Ширина интервала 0,06 — в общем-то, довольно узкий интервал. А теперь давайте попробуем эту оценку улучшить. Следующий метод, который очень часто используют, это доверительный интервал Уилсона. Это некоторое улучшение предыдущего метода, которое позволяет получать качественные оценки в крайних случаях. То есть тогда, когда наша доля очень близка к 0 или очень близка к 1. Более того, этот интервал получается неплохим в случае, когда наша случайная подвыборка довольно мала, то есть включает в себя очень мало событий. Формула для расчета перед вами и давайте строить интервал. Это делается с помощью той же самой функции, видите, что первые два параметра не меняются. Однако нам нужно изменить метод, с помощью которого мы будем строить интервал. В данном случае мы будем пользоваться методом Уилсона, поэтому давайте это явно напишем. Итак, получаем интервал. Теперь давайте выведем результаты на экран. И сравним с предыдущим. Видим, что наши границы практически не изменились, видим, что изменения у нас только в пятом знаке после запятой, ну и с данной точностью мы даже не можем увидеть разницу в ширине интервала, то есть фактически они одинаковые. Ну почему так получается? Здесь мы не видим явных преимуществ, потому что наша случайная подвыборка довольно хороша. Значение доли у нас не является крайним. Объектов целых событий, вернее целых 1000. Поэтому, в общем-то, мы и так можем довольно не плохо это оценить. Теперь давайте посмотрим еще раз на ширину интервала. В данном случае наш интервал имеет ширину 0,6. Часто мы с вами можем хотеть задать некоторое ограничение на ширину интервала. Например, мы хотим знать более точную оценку и получить интервал меньшей ширины. Таким образом, возникает вопрос: сколько же событий нам нужно знать для того, чтобы оценить долю с достаточной точностью? Для того чтобы этот вопрос решить, существует очень удобный метод под названием sample size confint proportion. Он позволяет нам явно задать ограничение на ширину нашего интервала и получить количество событий, которое необходимо для того, чтобы получить оценку заданной ширины. Вот давайте это сделаем. Сначала импортируем нужную функциональность. И вот давайте для разнообразия получим интервал в 3 раза у́же, то есть интервал ширины 0,02. Для этого сначала указываем среднее выборочное по нашей выборке и давайте теперь укажем ширину интервала. На самом деле нам нужно указать половину ширины этого интервала для того, чтобы в дальнейшем получить интервал заданной ширины. Вот давайте получим количество объектов n samples и сразу же на него посмотрим. Вот оказывается, что чтобы получить оценку заданной точности, то есть в 3 раза, чтобы получить ширину в 3 раза у́же, нам нужно взять почти в 10 раз больше событий. Ну вот давайте это сделаем. Перегенерируем нашу случайную выборку, снова будем использовать метод random choice, однако теперь скажем, что количество объектов будет равняться переменной n samples – тому количеству, которое мы рассчитали шагом выше. Итак, перестраиваем выборку. Теперь давайте снова получим интервал на долю с помощью метода proportion confint. Итак, получили наш интервал. И теперь смотрим, нас интересует, получился ли у нас интервал заданной ширины. Итак, мы видим, что все получилось. Интервал по-прежнему достаточно хороший. Наше истинное значение входит в заданный интервал и при этом он стал в 3 раза у́же. Мы получили оценку интервала шириной 0,002. На этом мы с вами заканчиваем. Мы научились строить доверительные интервалы на долю с помощью нормального распределения, а так же с помощью метода Уилсона. В следующем уроке мы с вами продолжим строить интервальные оценки и научимся делать это с помощью такого понятия, как Bootstrap.

Привет! В этом видео мы научимся строить доверительный интервал для двух долей, вернее, для разности двух долей. Давайте рассмотрим следующую задачу. Предположим, что у нас есть некоторый товар или услуга, которую мы хотим рекламировать. При этом у нас уже есть некоторый рекламный баннер, который мы используем для этих целей. Предположим также, что наши дизайнеры нарисовали для нас новый баннер, более красивый и с котиками, и нам с вами хочется проверить, какой же из них лучше, какой же из них больше нравится людям. Для этой задачи мы можем поступить следующим образом: прежде чем везде показыать новый баннер, давайте сделаем какую-нибудь простенькую веб-формочку и загрузим туда два наших баннера. Попросим некоторое количество людей, например, 1000 человек, посмотреть на них и нажать на кнопку «лайк», если баннер им понравился. Таким образом мы соберем статистику по «лайкам» на каждый из этих двух баннеров и сравним. Тот баннер, который окажется значимо лучше, и будем показывать. Вот давайте проведем следующие измерения. Загрузим такие данные, давайте посмотрим, как они выглядят. Ну, мы видим, что данные достаточно простые. У нас всего два столбца, каждый столбец соответствует кликам или не-кликам по одному из баннеров, и соответственно, 0 означает, что человеку баннер не понравился и он не стал нажимать на кнопку «лайк», 1 означает обратное — баннер понравился. Ну давайте с помощью метода describe посмотрим на статистику по кликам. Видим, что количество наблюдений у нас одинаково: и в том, и в другом случае мы показали баннер 1000 человек. Мы видим, что по баннеру A — это более старый баннер — кликов несколько меньше. Ну вот мы видим, что доля меньше. Соответственно, минимальное и максимальное значения — 0 и 1, потому что у нас с вами всего два значения присутствует, ну и различные перцентили нам не очень интересны. Давайте для начала интервально оценим баннеры. Мы видим, что доля кликов (или доля успехов) у нас относительно небольшая, поэтому для того, чтобы построить интервальную оценку доли, нам подойдет метод Уилсона. Из предыдущих лекции вы помните, что он хорошо работает в случае крайних значений на вероятность. Итак, давайте построим доверительные интервалы, делаем мы это с помощью метода proportion_confint из библиотеки StatsModels, и сразу же выведем их на экран. Видим, что мы получили интервалы. Интервалы достаточно узкие, но тем не менее они пересекаются. Это не очень удобно, потому что если бы один интервал лежал, например, полностью левее, чем другой, тогда нам было бы легко понять, что один баннер действительно лучше. А сейчас они пересекаются и не очень понятно, как их сравнить. Для того, чтобы их сравнить, давайте поступим следующим образом: давайте построим доверительный интервал на разность двух долей. Для того, чтобы это сделать, нам нужно сначала построить следующую табличку: давайте выпишем статистику по кликам на первый баннер и на второй, соответственно, посчитаем, сколько у нас было кликов — сколько было 1 в выборке, и сколько было не-кликов, или сколько было 0. На основе этого давайте рассчитаем статистики p1 и p2 и по формуле ниже оценим интервально разность долей. Давайте эту формулу реализуем, она достаточно простая. Смотрите, на реализации здесь всё просто. Сначала мы с вами честно рассчитываем все те слагаемые, которые входят в формулу, а дальше просто по формуле выписываем левую и правую границы интервала. Вот давайте это запустим и выведем на экран получившийся интервал. Ну, что можно сказать? Мы видим, что относительно 0 наш интервал более сильно сдвинут влево, большая часть его лежит все-таки в отрицательной плоскости, но тем не менее 0 внутри и не очень понятно, действительно ли старый баннер хуже, чем новый. Давайте рассмотрим следующую ситуацию. Предположим, что мы показывали баннер одним и тем же людям, то есть одни и те же люди оценивали как баннер A, старый баннер, так и баннер B. В этом случае мы с вами можем сказать, что речь идет уже о связанных выборках, они уже не являются независимыми. В этом случае мы можем использовать другую оценку разности долей. Для того, чтобы такую оценку получить, сначала нам нужно выписать таблицу сопряженности. Это очень простая таблица, у которой по строкам и по столбцам написаны значения наших случайных величин, в данном случае это 1 и 0, и в ячейках написано количество наблюдений, соответствующих данным значениям величин. Для того, чтобы получить доверительный интервал, нам с вами нужно по формулам рассчитать p1 и p2, дальше рассчитать их разность и подставить всё это для того, чтобы получить левую и правую границу. Давайте эту функцию реализуем, здесь всё довольно просто и также похоже на предыдущий случай. Сначала мы с вами оцениваем z, дальше оцениваем f и g и подставляем их в формулу для получения интервалов. Итак, давайте эту функцию построим и оценим интервал. Отлично, смотрите: здесь мы видим, что весь наш интервал лежит полностью левее нуля. Из этого можно сделать вывод, что действительно наш новый баннер лучше, чем старый, и выбрать нужно именно его. На этом мы с вами заканчиваем. Мы научились строить доверительный интервал на разность двух долей, а в следующем видео вы познакомитесь с новой технологией для оценки доверительных интервалов. Технология называется bootstrap.

[БЕЗ ЗВУКА] В этом видео мы научимся строить интервальные оценки на основе методологии Bootstrap. Часто нам нужно построить интервальную оценку для некоторой не очень удобной статистики, при распределении которой нам просто ничего не известно. Это могут быть такие статистики, как квантили, например, медиана, или некоторое сочетание известных статистик, например, отношение долей. В принципе, это может быть любая функция, которую вы можете посчитать от выборки. Как же быть в этом случае? Ну вообще, для того чтобы оценить интервально некоторую статистику, нам нужно знать её распределение. Возникает вопрос: как же его получить? Ну, вообще говоря, первое, что приходит в голову — это породить много случайных выборок из генеральной совокупности. Дальше на каждой из этих выборок оценить нужную нам статистику и таким образом установить эмпирическую функцию распределения. Казалось бы, неплохой способ, однако он скорее теоретический, чем практический, потому что, если мы можем неограниченно генерировать выборки из генеральной совокупности, то, получается, и посчитать саму статистику на генеральной совокупности нам не так уж и сложно. А если мы можем это сделать, нам уже не нужна никакая интервальная оценка, мы сами знаем настоящее значение нужной статистики. Получается, этот способ на практике практически не применим. Другой способ, который мы можем предложить, — это так называемый параметрический подход. Здесь мы должны предположить, что наша статистика имеет некоторое распределение, и далее по выборке оценить его параметры. Ну на самом деле это тоже не самый лучший способ, потому что непонятно, из каких соображений мы должны выбирать семейство распределений. Мы ничего про данные не знаем, вернее, мы ничего не знаем про распределение, поэтому ну неочевидно, как его выбрать. Единственное, что нам доступно для анализа — это некоторая выборка, и это приводит нас к идее Bootstrap. Что если мы будем сэмплировать данные из известной нам выборки с возвращениями, то есть из известной выборки получать выборки такой же длины путём сэмплирования с возвращением? В этом случае мы с вами будем сэмплировать уже не из теоретической функции распределения, а из эмпирической функции распределения, и таким образом, посчитав статистику на каждой из этих выборок, мы с вами оценим эмпирическую функцию распределения. Собственно, в этом и заключается идея Bootstrap. Давайте попробуем применить её на практике. Решать мы с вами будем следующую задачу. Существует такая американская компания под названием Verizon, которая является основной телефонной компанией на западе Соединённых Штатов. Это означает то, что данная компания должна предоставлять услуги по ремонту телекоммуникаций не только для своих клиентов, но также для клиентов других местных локальных компаний. В этом случае кажется, что у этой компании есть некоторая заинтересованность предоставлять сервис для своих клиентов несколько лучше. Ну, например, ремонтировать их оборудование быстрее. Для того чтобы за этим следить и контролировать ситуацию, используется статистика. Строятся интервальные оценки на время ремонта оборудования для клиентов этой компании и для остальных клиентов. Давайте загрузим доступную нам выборку и проанализируем среднее время ремонта оборудования для клиентов компании Verizon и среднее время ремонта оборудования для клиентов других компаний. Для этого давайте создадим DataFrame на основе наших данных. Сразу же увидим его размер, мы видим, что в DataFrame примерно 1700 записей и всего два столбца. Вот давайте выведем начало нашего DataFrame и посмотрим, что же там. Ну структура довольно простая. Мы видим, что в первом столбце у нас указан Time. Это время ремонта оборудования. А во втором столбце указана группа клиентов. ILEC означает, что это клиент самой компании, CLEC означает, что это клиент другой компании. Вот теперь давайте посмотрим, как много информации у нас известно про клиентов разных типов. Да, видим, что про клиентов компании Verizon у нас гораздо больше информации. Практически все данные относятся к клиентам этой компании. Но тем не менее нам с вами хочется каким-то образом сравнить, насколько же отличается среднее время ремонта. Ну сравнивать среднее время ремонта не очень сложно, мы с вами это уже умеем. Мы умеем строить доверительные интервалы на средние, поэтому давайте возьмём какую-нибудь другую статистику. Давайте сравним, как же соотносится между собой медианное время ремонта. Для начала давайте построим распределение времени ремонта оборудования для клиентов разного типа. Это делается очень просто с помощью метода hist из pylab. Ну давайте посмотрим и попробуем проанализировать гистограмму. Но если посмотреть на распределение, то есть предположение, что, кажется, клиенты местных компаний получают услугу лучше. Виден явный пик вблизи нуля в самой левой части диаграммы. А вот про клиентов остальных компаний такое не скажешь — видно, что здесь довольно много точек находится правее, ну то есть время ремонта чаще бывает дольше. Конечно же, оценивать глазами такие вещи неправильно. Давайте попробуем получить строгую формальную оценку. Итак, будем это делать с помощью методологии Bootstrap. Это довольно простой метод, поэтому его реализовать совсем несложно. Нам понадобятся две вспомогательные функции. Первую функцию назовём get bootstrap samples. Эта функция будет принимать на вход данные. И количество подвыборок, количество сэмплов, которые мы хотим получить. Реализация предельно простая. Для начала давайте получим наборы индексов из range 0 размер наших данных с повторением. Это можно сделать с помощью модуля np. random функции rand Int. Указываем ей в качестве аргументов начало и конец нашего диапазона, соответственно, это ноль и размер входных данных. И теперь говорим сколько выборок нам нужно. Ну вот нам нужно выборок ровно n samples. Этот аргумент мы передаём. Ну и мы говорим, что эти выборки должны быть такого же размера, как и размер наших исходных данных. Вот получаем эти индексы, дальше получаем выборки, применяя эти индексы к исходному набору данных, и возвращаем выборки. Следующая функция, которая нам понадобится, stat intervals. Она реализована очень просто. Так как мы хотим оценивать наш интервал на некотором уровне значимости, вот просто давайте создадим функцию, которая на вход получает нужные статистики, уровень доверия, который нас интересует, и возвращает нам левую и правую границы интервала. Функция очень простая, передаём ей статистики, передаём ей α, а дальше берём наши статистики и упорядочиваем их по возрастанию, и говорим, что мы просто отрезаем слева и справа по кусочку равному α / 2 (слева) и (1 − α) / 2 (справа). Давайте начнём с того, что получим независимые интервальные оценки медианы для клиентов двух типов. Для этого давайте создадим два массива. В первый массив запишем время ремонта для клиентов компании Verizon, во второй массив запишем время ремонта для клиентов других компаний. Это делается очень просто с помощью сравнения групп с нужными константами. Соответственно, записываем только время. Теперь дальше. Нам нужно применить функцию get bootstrap samples, то есть сгенерировать набор данных. В данном случае я хочу генерировать тысячу выборок для каждого… для каждой группы клиентов. И давайте сразу же посчитаем нашу статистику. Это очень просто, мы можем посчитать медиану с помощью метода np. median, поэтому давайте сразу создадим массивы, состоящие из оценки медианы на наших подвыборках. Это делается с помощью метода map, то есть получаем сэмплы, применяем медиану и записываем результат в массив. Делаем это дважды для клиентов разных компаний. Ну и давайте сразу посчитаем статистику. Выведем результаты работы функции stat intervals на экран. Рассчитываем статистику на уровне доверия 0,05 и видим, что ну, кажется, весь интервал для клиентов компании Verizon расположен левее интервала для клиентов внешних компаний. Кажется, интерес помогать своим клиентам всё-таки есть. Итак, мы с вами получили независимые интервальные оценки медианы времени ремонта оборудования для клиентов из разных групп, и теперь давайте немножечко усложним. Давайте оценим разность медиан времени ремонта оборудования для этих клиентов. Но кажется, если нам нужно получить точечную оценку, то это очень просто. Независимо оцениваем медианы времени ремонта для клиентов одной группы, потом для клиентов второй группы и просто строим разность. Давайте это сделаем. Ну вот видим, что дельта медиан равняется 11. Кажется, что это неплохо, но что если нам хочется получить интервальную оценку для разности медиан? Тут уже несколько сложнее. Ну, во-первых, эти интервалы получились сильно разной длины, ну и, вообще, у нас нет никаких теоретических оснований для того, чтобы просто взять и, скажем, посчитать разность левых и правых границ этого интервала. Кажется, что так не пройдёт, нужно действовать чуть более хитро. Давайте поступим следующим образом. Снова с помощью Bootstrap сгенерируем выборки для клиентов разных групп и посчитаем на этих выборках медианы независимо. Далее, по полученным данным рассчитаем следующую статистику. Посчитаем разность полученных медиан. Это делается довольно просто. Сначала рассчитываем медианы независимо, далее, с помощью функции zip объединяем их в один список. Ну и с помощью функции map просто считаем попарные разности, это легко. Итак, посчитали разности, а теперь снова пользуемся функцией stat intervals, которую мы определили ранее, и рассчитываем интервал для этой статистики на уровне доверия 0,05. Итак, видим, что мы получили довольно неплохую оценку для этого интервала. Мы видим, что разница во времени работы составляет от 2 до 16,06 разницы в медиане. Итак, на этом мы заканчиваем знакомство с методологией Bootstrap. Мы научились строить интервальные оценки с ее помощью. А на следующем уроке мы перейдем к очень интересной теме — проверке статистических гипотез.